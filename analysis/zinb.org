#+TITLE: ZINB estimation
#+SETUPFILE: setup.org

* Introduction

  The simplest approach to call mean/variance QTLs is to estimate a mean and a
  dispersion for each individual, treat them as continuous phenotypes, and plug
  into standard QTL mapping software.

  Here, we find maximum likelihood estimates of a zero-inflated negative
  binomial model for the dropout, mean, and dispersion per individual per gene.

* Setup                                                            :noexport:

  #+BEGIN_SRC emacs-lisp
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(venv="scqtl", memory="16G") :dir /scratch/midway2/aksarkar/singlecell

  #+RESULTS:
  : Submitted batch job 42124986

  #+BEGIN_SRC ipython :tangle zinb.py
    import numpy as np
    import os
    import pandas as pd
    import tensorflow as tf
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

* Quality control

  Filter out cells on percent spike-in and gene detection rate, and filter out
  genes on individual detection rate.

  #+NAME: umi-qc
  #+BEGIN_SRC ipython
    keep_cells = functools.reduce(
      np.logical_and,
      [
        annotations['reads_ercc'] / annotations.filter(like='reads_', axis=1).agg(np.sum, axis=1) < 0.5,
        annotations['detect_hs'] > 4000,
        annotations['chip_id'] != 'NA19092',
      ]).values
    keep_genes = functools.reduce(
      np.logical_and,
      [
        (umi.groupby(annotations['chip_id'].values, axis=1).agg(np.sum) > 0).apply(lambda x: x.mean() > 0.5, axis=1)
      ]).values
    umi_qc = umi.loc[keep_genes, keep_cells]
    annotations_qc = annotations.loc[keep_cells]
    umi_qc.mask(umi_qc == 0)
    umi_qc.shape
  #+END_SRC

  #+RESULTS: umi-qc
  :RESULTS:
  : (15636, 1810)
  :END:

  #+NAME: onehot-qc
  #+BEGIN_SRC ipython
    individuals = sorted(annotations_qc['chip_id'].unique())
    onehot = np.zeros((umi_qc.shape[1], len(individuals)), dtype=np.float32)
    onehot[np.arange(onehot.shape[0]),annotations_qc['chip_id'].apply(lambda x: individuals.index(x))] = 1
  #+END_SRC

  #+RESULTS: onehot-qc
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython :async t
    umi_qc.to_csv('/scratch/midway2/aksarkar/singlecell/umi-qc.txt.gz', sep=' ', compression='gzip')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython
    onehot = pd.DataFrame(onehot, columns=individuals, index=umi_qc.columns)
    onehot.to_csv('/scratch/midway2/aksarkar/singlecell/onehot-qc.txt.gz', sep=' ', compression='gzip')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

* Read the data

  #+BEGIN_SRC ipython :tangle zinb.py
    umi = pd.read_table('/scratch/midway2/aksarkar/singlecell/umi-qc.txt.gz', sep=' ', index_col=0, nrows=4000)
    onehot = pd.read_table('/scratch/midway2/aksarkar/singlecell/onehot-qc.txt.gz', sep=' ', index_col=0)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

* Maximum likelihood estimation

  Use gradient descent to maximize the likelihood of the zero-inflated negative
  binomial model for the data.

  \[ r_{ijk} = \text{number of reads for individual \(i\), cell \(j\), gene
  \(k\)} \]

  \[ r_{ijk} = \pi_j \delta_0(r_{ijk}) + (1 - \pi_j) \mathcal{NB}(r_{ijk};
  \mu_{ik}, \phi_{ik}) \]

  #+BEGIN_SRC ipython :tangle zinb.py
    def log_zinb_positive(x, mu, theta, pi, eps=1e-8):
      """Log likelihood of x according to ZINB model

      Lopez et al. "A deep generative model for gene expression profiles
      from single-cell RNA sequencing"

      c.f. Hilbe 2012, eq. 11.12, 11.13

      mu: mean (>0)
      theta: inverse dispersion parameter (>0)
      pi:logit of the dropout parameter

      """
      case_zero = tf.nn.softplus(- pi + theta * tf.log(theta + eps) - theta * tf.log(theta + mu + eps)) \
                  - tf.nn.softplus( - pi)
      case_non_zero = - pi - tf.nn.softplus(- pi) \
                      + theta * tf.log(theta + eps) - theta * tf.log(theta + mu + eps) \
                      + x * tf.log(mu + eps) - x * tf.log(theta + mu + eps) \
                      + tf.lgamma(x + theta) - tf.lgamma(theta) - tf.lgamma(x + 1)
      mask = tf.cast(tf.less(x, eps), tf.float32)
      res = tf.multiply(mask, case_zero) + tf.multiply(1 - mask, case_non_zero)
      return tf.reduce_sum(res)
      return tf.reduce_sum(tf.multiply(mask, case_zero) + tf.multiply(1 - mask, case_non_zero))

    def fit(umi, onehot, learning_rate=1e-2, max_epochs=1000):
      """Return estimated dropout log odds, log mean, and log dispersion

      umi - count matrix (n x p; float32)
      onehot - mapping of individuals to cells (m x n; float32)

      Returns:

      llik - log likelihood
      dropout - spike log odds (n x 1)
      log_mean - log mean parameter (m x p)
      log_disp - log dispersion parameter (m x p)

      """
      n, p = umi.shape
      _, m = onehot.shape

      umi = tf.Variable(umi, trainable=False)
      onehot = tf.Variable(onehot, trainable=False)

      index = tf.placeholder(tf.int32)

      dropout = tf.Variable(tf.zeros([n, 1]))
      mean = tf.exp(tf.Variable(tf.zeros([m, p])))
      dispersion = tf.exp(tf.Variable(tf.zeros([m, p])))

      llik = log_zinb_positive(
        umi,
        tf.matmul(onehot, mean),
        tf.matmul(onehot, dispersion),
        dropout)

      train = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(-llik)

      opt = [tf.log(mean), tf.log(dispersion), dropout]
      curr = float('-inf')
      with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for i in range(max_epochs):
          _, update = sess.run([train, llik], feed_dict={index: i % p})
          if not np.isfinite(update):
            raise tf.train.NanLossDuringTrainingError
          if not i % 100:
            print(i, update)
        return sess.run(opt)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython :tangle zinb.py
    mean, dispersion, dropout = fit(
      umi.values.T.astype(np.float32),
      onehot.values.astype(np.float32),
      learning_rate=1e-2)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython :tangle zinb.py
    pd.DataFrame(mean.T, index=umi.index, columns=onehot.columns).to_csv('/scratch/midway2/aksarkar/singlecell/mean.txt.gz', sep=' ', compression='gzip')
    pd.DataFrame(dispersion.T, index=umi.index, columns=onehot.columns).to_csv('/scratch/midway2/aksarkar/singlecell/dispersion.txt.gz', sep=' ', compression='gzip')
    pd.DataFrame(dropout, index=umi.columns).to_csv('/scratch/midway2/aksarkar/singlecell/dropout.txt.gz', sep=' ', compression='gzip')
  #+END_SRC

  This estimation problem takes too long to run interactively, so [[https://orgmode.org/manual/Extracting-source-code.html][tangle]] it
  from this file and run it through ~sbatch~.

  #+BEGIN_SRC emacs-lisp
    (org-babel-tangle)
  #+END_SRC

  #+BEGIN_SRC sh :eval never-export
    sbatch --partition=broadwl --mem=8G --time=120 --job-name=zinb --output=zinb.out --error=zinb.err
    #!/bin/bash
    source activate scqtl
    python zinb.py
  #+END_SRC

  #+RESULTS:
  : Submitted batch job 42072360

* Mean-QTL calling

  Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~QTLtools~.

  #+NAME: get-gene-info
  #+BEGIN_SRC ipython
    gene_info = (pd.read_table('/home/aksarkar/projects/singlecell-qtl/data/scqtl-genes.txt.gz')
                 .set_index('gene')
                 .query('source == "H. sapiens"')
                 .query('chr != "hsX"')
                 .query('chr != "hsY"')
                 .query('chr != "hsMT"'))
    gene_info.head()
  #+END_SRC

  #+RESULTS: get-gene-info
  :RESULTS:
  #+BEGIN_EXAMPLE
                    chr      start        end      name strand      source
    gene                                                                    
    ENSG00000000419  hs20   49551404   49575092      DPM1      -  H. sapiens
    ENSG00000000457   hs1  169818772  169863408     SCYL3      -  H. sapiens
    ENSG00000000460   hs1  169631245  169823221  C1orf112      +  H. sapiens
    ENSG00000000938   hs1   27938575   27961788       FGR      -  H. sapiens
    ENSG00000000971   hs1  196621008  196716634       CFH      +  H. sapiens
  #+END_EXAMPLE
  :END:

  #+RESULTS:
  :RESULTS:
  #+BEGIN_EXAMPLE
                    chr      start        end      name strand      source
    gene                                                                    
    ENSG00000000419  hs20   49551404   49575092      DPM1      -  H. sapiens
    ENSG00000000457   hs1  169818772  169863408     SCYL3      -  H. sapiens
    ENSG00000000460   hs1  169631245  169823221  C1orf112      +  H. sapiens
    ENSG00000000938   hs1   27938575   27961788       FGR      -  H. sapiens
    ENSG00000000971   hs1  196621008  196716634       CFH      +  H. sapiens
  #+END_EXAMPLE
  :END:

  #+NAME: write-pheno-def
  #+BEGIN_SRC ipython
    def qtltools_format(row):
      row['#Chr'] = 'chr{}'.format(row['chr'][2:])
      row['gid'] = row.name
      row['pid'] = row.name
      return row

    def write_pheno_file(pheno, gene_info, output_file):
      (gene_info
       .apply(qtltools_format, axis=1)
       .merge(pheno, left_index=True, right_index=True)
       .to_csv(output_file,
               sep='\t',
               columns=['#Chr', 'start', 'end', 'pid', 'gid', 'strand'] + list(pheno.columns),
               header=True,
               index=False,
               index_label=False)
      )
  #+END_SRC

  #+RESULTS: write-pheno-def
  :RESULTS:
  :END:

  #+RESULTS:
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython
    mean = pd.read_table('/scratch/midway2/aksarkar/singlecell/mean.txt.gz', sep=' ', index_col=0)
    mean.head()
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  #+BEGIN_EXAMPLE
                    NA18489   NA18498   NA18499   NA18501   NA18502   NA18505  \
    gene                                                                          
    ENSG00000000003  2.132201  1.862085  1.994689  2.203277  1.994263  1.873698   
    ENSG00000000005 -1.304971 -1.137107 -2.085783 -1.440596 -2.309412 -1.127515   
    ENSG00000000419  1.408769  1.332950  1.690473  1.656058  1.669314  1.605577   
    ENSG00000000457 -0.993338 -2.940411 -0.788445 -0.932689 -0.906488 -0.360301   
    ENSG00000000460  0.403482 -0.106141  0.520277  0.567161  0.443905  0.670071   

                      NA18507   NA18508   NA18519   NA18520    ...      NA19119  \
    gene                                                       ...                
    ENSG00000000003  2.185227  1.984693  2.175263  1.960210    ...     2.228055   
    ENSG00000000005 -1.499075 -3.047421 -1.563732 -2.949254    ...    -2.113694   
    ENSG00000000419  1.834280  1.659502  1.692899  1.579187    ...     1.806168   
    ENSG00000000457 -0.763892 -0.913251 -1.235485 -0.913332    ...    -1.210785   
    ENSG00000000460  0.474492  0.521287  0.653763  0.439643    ...     0.771924   

                      NA19128   NA19153   NA19159   NA19190   NA19193   NA19203  \
    gene                                                                          
    ENSG00000000003  2.316742  2.286229  1.866834  2.146526  2.011522  1.547072   
    ENSG00000000005 -2.109344 -0.943781 -3.445312 -2.083898 -2.493103 -1.347846   
    ENSG00000000419  2.015950  1.903451  1.413075  1.730209  1.968157  1.188535   
    ENSG00000000457 -0.705963 -0.792029 -0.870194 -0.492704 -1.142365 -2.031550   
    ENSG00000000460  0.898602  0.601947  0.173087  0.454041  0.562179  0.153599   

                      NA19207   NA19210   NA19257  
    gene                                           
    ENSG00000000003  2.275138  2.277549  2.068974  
    ENSG00000000005 -1.550304 -1.269496 -2.731949  
    ENSG00000000419  1.865725  2.116240  2.024805  
    ENSG00000000457 -0.965920 -0.678640 -0.859062  
    ENSG00000000460  0.797515  0.873859  0.751235  

    [5 rows x 32 columns]
  #+END_EXAMPLE
  :END:

  #+BEGIN_SRC ipython
    write_pheno_file(mean, gene_info, '/scratch/midway2/aksarkar/singlecell/mean.bed')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  Index the phenotype file.

  #+NAME: tabix
  #+BEGIN_SRC sh :var input="mean.bed" :var partition="broadwl" :dir /scratch/midway2/aksarkar/singlecell :eval never-export
    export input=$input
    sbatch --partition=$partition --wait
    #!/bin/bash
    sort -k1,1 -k2,2n -k3,3n $input | bgzip >$input.gz
    tabix -p bed $input.gz
  #+END_SRC

  #+RESULTS: tabix
  : Submitted batch job 42125468

  Run the QTL mapping.

  #+NAME: qtltools
  #+BEGIN_SRC sh :var pheno="mean" :var partition="broadwl" :dir /scratch/midway2/aksarkar/singlecell :eval never-export 
    export pheno=$pheno
    sbatch --partition=$partition -N1 -c4 -J $pheno-qtl -o $pheno-qtl.log
    #!/bin/bash
    source activate scqtl
    module load parallel
    parallel -j4 qtltools cis --vcf /project2/gilad/singlecell-qtl/bulk/genotypes.vcf.gz --bed $pheno.bed.gz --nominal=0.01 --chunk {#} 100 --out $pheno-qtl.{#}.txt ::: $(seq 1 100)
  #+END_SRC

  #+RESULTS: qtltools
  : Submitted batch job 42125616

  Read the results.

  #+BEGIN_SRC ipython
    file_names = ['mean-qtl.{}.txt'.format(i) for i in range(1, 101)]
    mean_qtls = (pd.concat([pd.read_table(f, header=None, sep=' ') for f in file_names if os.path.exists(f) and os.path.getsize(f) > 0])
                 .rename(columns={i: x for i, x in enumerate(['gene', 'chr', 'start', 'end', 'strand', 'num_vars', 'distance', 'id', 'var_chr', 'var_start', 'var_end', 'p', 'beta', 'top'])})
                 .sort_values('p')
                 .set_index('gene'))
    mean_qtls[mean_qtls['top'] == 1].head()
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  #+BEGIN_EXAMPLE
                     chr   start     end strand  num_vars  distance id var_chr  \
    gene                                                                           
    ENSG00000239857   chr7  916190  936073      +      7763   -916190  C    chr7   
    ENSG00000169026   chr4  675619  683230      -      4952    675619  C    chr4   
    ENSG00000101282  chr20  939096  982907      -      6734    939096  G   chr20   
    ENSG00000186777   chr4  264465  299110      -      3531    264465  A    chr4   
    ENSG00000116014  chr19  917288  921015      +      6659   -917288  G   chr19   

                     var_start  var_end             p     beta  top  
    gene                                                             
    ENSG00000239857     986498        0  1.273710e-16 -4.71915    1  
    ENSG00000169026     810152        0  2.231630e-15 -4.74142    1  
    ENSG00000101282    1025679        0  3.021520e-15 -5.27573    1  
    ENSG00000186777     897103        0  4.407960e-15 -4.66579    1  
    ENSG00000116014     619338        0  1.081230e-14 -5.08811    1  
  #+END_EXAMPLE
  :END:

  *TODO:* Permutation testing within QTLtools? lfsr estimation by ~ashr~?

* Dispersion-QTL calling

  #+BEGIN_SRC ipython
    disp = pd.read_table('/scratch/midway2/aksarkar/singlecell/dispersion.txt.gz', sep=' ', index_col=0)
    disp.head()
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  #+BEGIN_EXAMPLE
                    NA18489   NA18498   NA18499   NA18501   NA18502   NA18505  \
    gene                                                                          
    ENSG00000000003  1.092216  1.349166  1.376199  1.151147  1.597304  1.619764   
    ENSG00000000005  1.245627  7.247635 -0.062590  1.342859 -1.007912  0.411424   
    ENSG00000000419  1.913491  2.318849  1.598213  1.189439  1.753222  2.410088   
    ENSG00000000457 -0.699626  5.044208  0.099977 -0.107983 -0.469346  4.960834   
    ENSG00000000460  1.130231  6.989872  1.317161  1.452350  0.750685  7.235482   

                      NA18507   NA18508   NA18519   NA18520    ...      NA19119  \
    gene                                                       ...                
    ENSG00000000003  1.129030  1.115463  1.833903  1.555660    ...     1.315700   
    ENSG00000000005 -0.469625  4.921400 -0.688780  5.141915    ...     6.322920   
    ENSG00000000419  1.036118  0.865517  1.408871  1.298325    ...     3.754308   
    ENSG00000000457 -0.108463  0.456174 -0.609740 -0.225618    ...     0.740946   
    ENSG00000000460  0.996670  0.676970  2.453142  1.251912    ...     0.717296   

                      NA19128   NA19153   NA19159   NA19190   NA19193   NA19203  \
    gene                                                                          
    ENSG00000000003  0.693213  1.513592  1.016362  1.539210  1.417464  1.459843   
    ENSG00000000005 -0.657682 -0.084881  4.429851  0.978749  5.818314  0.995584   
    ENSG00000000419  0.771990  1.453221  1.603899  1.464751  1.067739  4.966578   
    ENSG00000000457 -0.268748  0.060874 -0.039906  0.009648  0.003913  6.323813   
    ENSG00000000460  0.866060  0.424351  7.455638  0.493674  1.032298  0.203354   

                      NA19207   NA19210   NA19257  
    gene                                           
    ENSG00000000003  1.296685  1.494707  1.368400  
    ENSG00000000005  0.493389 -1.198948  5.263945  
    ENSG00000000419  1.536127  1.775915  1.279451  
    ENSG00000000457 -0.081436  0.800806 -0.193967  
    ENSG00000000460  1.145072  1.669772  1.276706  

    [5 rows x 32 columns]
  #+END_EXAMPLE
  :END:

  #+BEGIN_SRC ipython
    write_pheno_file(disp, gene_info, '/scratch/midway2/aksarkar/singlecell/disp.bed')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  Index the phenotype file

  #+CALL: tabix(input="disp.bed")

  #+RESULTS:
  : Submitted batch job 42125661

  Run ~qtltools~

  #+CALL: qtltools(pheno="disp")

  #+RESULTS:
  : Submitted batch job 42125670

  There are no detected dispersion QTLs, so the following code raises an exception.

  #+BEGIN_SRC ipython
    file_names = ['disp-qtl.{}.txt'.format(i) for i in range(1, 101)]
    disp_qtls = (pd.concat([pd.read_table(f, header=None, sep=' ') for f in file_names if os.path.exists(f) and os.path.getsize(f) > 0])
                 .rename(columns={i: x for i, x in enumerate(['gene', 'chr', 'start', 'end', 'strand', 'num_vars', 'distance', 'id', 'var_chr', 'var_start', 'var_end', 'p', 'beta', 'top'])})
                 .sort_values('p')
                 .set_index('gene'))
    disp_qtls[disp_qtls['top'] == 1].head()
  #+END_SRC
