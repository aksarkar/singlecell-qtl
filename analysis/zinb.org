#+TITLE: ZINB estimation
#+SETUPFILE: setup.org

* Introduction

  The simplest approach to call mean/variance QTLs is to estimate a mean and a
  dispersion for each individual, treat them as continuous phenotypes, and plug
  into standard QTL mapping software.

  Here, we find maximum likelihood estimates of a zero-inflated negative
  binomial model for the dropout, mean, and dispersion per individual per gene.

* Setup                                                            :noexport:

  #+BEGIN_SRC emacs-lisp
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(venv="scqtl", partition="gpu2 --gres=gpu:1", memory="16G") :dir /scratch/midway2/aksarkar/singlecell

  #+RESULTS:
  : Submitted batch job 42150495

  #+BEGIN_SRC ipython :tangle zinb.py
    import functools
    import numpy as np
    import os
    import pandas as pd
    import tensorflow as tf
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  #+NAME: list-local-devices
  #+BEGIN_SRC ipython
    from tensorflow.python.client import device_lib as dl
    dl.list_local_devices()
  #+END_SRC

  #+RESULTS: list-local-devices
  :RESULTS:
  #+BEGIN_EXAMPLE
  [name: "/cpu:0"
     device_type: "CPU"
     memory_limit: 268435456
     locality {
     }
     incarnation: 3101117888233869158, name: "/gpu:0"
     device_type: "GPU"
     memory_limit: 11324823962
     locality {
       bus_id: 1
     }
     incarnation: 4298943332142850272
     physical_device_desc: "device: 0, name: Tesla K80, pci bus id: 0000:08:00.0"]
  #+END_EXAMPLE
  :END:

* Quality control                                                  :noexport:

  Filter out cells on percent spike-in and gene detection rate, and filter out
  genes on individual detection rate.

  #+NAME: umi-qc
  #+BEGIN_SRC ipython
    keep_cells = functools.reduce(
      np.logical_and,
      [
        annotations['reads_ercc'] / annotations.filter(like='reads_', axis=1).agg(np.sum, axis=1) < 0.5,
        annotations['detect_hs'] > 4000,
        annotations['chip_id'] != 'NA19092',
      ]).values
    keep_genes = functools.reduce(
      np.logical_and,
      [
        (umi.groupby(annotations['chip_id'].values, axis=1).agg(np.sum) > 0).apply(lambda x: x.mean() > 0.5, axis=1)
      ]).values
    umi_qc = umi.loc[keep_genes, keep_cells]
    annotations_qc = annotations.loc[keep_cells]
    umi_qc.mask(umi_qc == 0)
    umi_qc.shape
  #+END_SRC

  #+RESULTS: umi-qc
  :RESULTS:
  : (15636, 1810)
  :END:

  #+NAME: onehot-qc
  #+BEGIN_SRC ipython
    individuals = sorted(annotations_qc['chip_id'].unique())
    onehot = np.zeros((umi_qc.shape[1], len(individuals)), dtype=np.float32)
    onehot[np.arange(onehot.shape[0]),annotations_qc['chip_id'].apply(lambda x: individuals.index(x))] = 1
  #+END_SRC

  #+RESULTS: onehot-qc
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython :async t
    umi_qc.to_csv('/scratch/midway2/aksarkar/singlecell/umi-qc.txt.gz', sep=' ', compression='gzip')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython
    onehot = pd.DataFrame(onehot, columns=individuals, index=umi_qc.columns)
    onehot.to_csv('/scratch/midway2/aksarkar/singlecell/onehot-qc.txt.gz', sep=' ', compression='gzip')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

* Read the data

  #+BEGIN_SRC ipython :tangle zinb.py
    umi = pd.read_table('/scratch/midway2/aksarkar/singlecell/umi-qc.txt.gz', sep=' ', index_col=0, nrows=4000)
    onehot = pd.read_table('/scratch/midway2/aksarkar/singlecell/onehot-qc.txt.gz', sep=' ', index_col=0)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

* Maximum likelihood estimation

  Let \(\mathcal{NB}\) denote the negative binomial log-likelihood,
  parameterized by mean \(\mu\) and dispersion \(\phi\):

  \[ \(\mathcal{NB}(x; \mu, \phi) = x \ln\left(\frac{\mu}{\mu + \phi})\) + \phi
  \ln\left(\frac{\phi}{\mu + \phi}) + \ln\Gamma(x + \phi) - \ln\Gamma(\phi) -
  \ln\Gamma(x + 1) \]

  Let \(r_{ijk}\) denote the number of reads for individual \(i\), cell \(j\),
  gene \(k\). Let \(\pi_j\) denote the probability of a "technical zero" (i.e.,
  not arising from the negative-binomial).

  Then, the log-likelihood of the data is:

  \[ r_{ijk} \mid r_{ijk} = 0 = -\ln(\pi_j + (1 - \pi_j) \mathcal{NB}(r_{ijk}; \mu_{ik},
  \phi_{ik})) \]

  \[ r_{ijk} \mid r_{ijk} > 0 = \ln(1 - \pi_j) + \mathcal{NB}(r_{ijk}; \mu_{ik},
  \phi_{ik})) \]

  The main challenge in optimizing the log likelihood of the data is that the
  parameters \(\pi\) are shared between genes, and the parameters \((\mu,
  \phi)\) are shared between cells, so we must (1) operate on the entire count
  matrix, (2) estimate a number of parameters which grows linearly with the
  number of individuals and the number of cells.

  We use automatic differentation and gradient descent to optimize the log
  likelihood.

  *Open question: Do we need to regularize the parameter estimation?* We have
  multiple data points (30-200 cells) per mean/dispersion parameter, so it
  seems this strategy could be reasonable.

  #+BEGIN_SRC ipython :tangle zinb.py
    def sigmoid(x):
      return tf.clip_by_value(tf.sigmoid(x), -13, 13)

    def log(x):
      """Numerically safe log"""
      return tf.log(x + 1e-8)

    def nb_llik(x, mean, disp):
      """Log likelihood of x distributed as NB

      mean - mean (> 0)
      disp - dispersion (> 0)

      """
      return (disp * log(disp) -
              disp * log(disp + mean) +
              x * log(mean) -
              x * log(disp + mean) +
              tf.lgamma(x + disp) -
              tf.lgamma(disp) -
              tf.lgamma(x + 1))

    def zinb_llik(x, mean, disp, logodds, eps=1e-8):
      """Log likelihood of x distributed as ZINB

      See Hilbe 2012, eq. 11.12, 11.13

      mean - mean (> 0)
      disp - dispersion (> 0)
      logodds - dropout log odds

      """
      case_zero = -log(sigmoid(-logodds) + sigmoid(logodds) * nb_llik(x, mean, disp))
      case_non_zero = -tf.nn.softplus(logodds) + nb_llik(x, mean, disp)
      return tf.reduce_sum(tf.where(tf.less(x, 1e-8), case_zero, case_non_zero))

    def fit(umi, onehot, learning_rate=1e-2, max_epochs=1000):
      """Return estimated dropout log odds, log mean, and log dispersion

      umi - count matrix (n x p; float32)
      onehot - mapping of individuals to cells (m x n; float32)

      Returns:

      llik - log likelihood
      dropout - spike log odds (n x 1)
      log_mean - log mean parameter (m x p)
      log_disp - log dispersion parameter (m x p)

      """
      n, p = umi.shape
      _, m = onehot.shape

      graph = tf.Graph()
      with graph.as_default(), graph.device('/gpu:*'):
        umi = tf.Variable(umi, trainable=False)
        onehot = tf.Variable(onehot, trainable=False)

        dropout = tf.Variable(tf.zeros([n, 1]))
        mean = tf.exp(tf.Variable(tf.zeros([m, p])))
        dispersion = tf.exp(tf.Variable(tf.zeros([m, p])))

        llik = zinb_llik(
          umi,
          tf.matmul(onehot, mean),
          tf.matmul(onehot, dispersion),
          dropout)

        train = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(-llik)

        opt = [tf.log(mean), tf.log(dispersion), dropout]
        curr = float('-inf')
        with tf.Session() as sess:
          sess.run(tf.global_variables_initializer())
          for i in range(max_epochs):
            _, update = sess.run([train, llik])
            if not np.isfinite(update):
              raise tf.train.NanLossDuringTrainingError
            if not i % 100:
              print(i, update)
          return sess.run(opt)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython :tangle zinb.py
    mean, dispersion, dropout = fit(
      umi.values.T.astype(np.float32),
      onehot.values.astype(np.float32),
      learning_rate=1e-4,
      max_epochs=2000)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython :tangle zinb.py
    pd.DataFrame(mean.T, index=umi.index, columns=onehot.columns).to_csv('/scratch/midway2/aksarkar/singlecell/mean.txt.gz', sep=' ', compression='gzip')
    pd.DataFrame(dispersion.T, index=umi.index, columns=onehot.columns).to_csv('/scratch/midway2/aksarkar/singlecell/dispersion.txt.gz', sep=' ', compression='gzip')
    pd.DataFrame(dropout, index=umi.columns).to_csv('/scratch/midway2/aksarkar/singlecell/dropout.txt.gz', sep=' ', compression='gzip')
  #+END_SRC

  This estimation problem takes too long to run interactively, so [[https://orgmode.org/manual/Extracting-source-code.html][tangle]] it
  from this file and run it through ~sbatch~.

  #+BEGIN_SRC emacs-lisp
    (org-babel-tangle)
  #+END_SRC

  #+RESULTS:
  | zinb.py |

  #+BEGIN_SRC sh :eval never-export :var partition="gpu2 --gres=gpu:1"
    sbatch --partition=$partition --mem=8G --time=12:00:00 --job-name=zinb --output=zinb.out --error=zinb.err
    #!/bin/bash
    source activate scqtl
    python zinb.py
  #+END_SRC

  #+RESULTS:
  : Submitted batch job 42157421

* Mean-QTL calling

  Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~QTLtools~.

  #+NAME: get-gene-info
  #+BEGIN_SRC ipython
    gene_info = (pd.read_table('/home/aksarkar/projects/singlecell-qtl/data/scqtl-genes.txt.gz')
                 .set_index('gene')
                 .query('source == "H. sapiens"')
                 .query('chr != "hsX"')
                 .query('chr != "hsY"')
                 .query('chr != "hsMT"'))
    gene_info.head()
  #+END_SRC

  #+RESULTS: get-gene-info
  :RESULTS:
  #+BEGIN_EXAMPLE
                    chr      start        end      name strand      source
    gene                                                                    
    ENSG00000000419  hs20   49551404   49575092      DPM1      -  H. sapiens
    ENSG00000000457   hs1  169818772  169863408     SCYL3      -  H. sapiens
    ENSG00000000460   hs1  169631245  169823221  C1orf112      +  H. sapiens
    ENSG00000000938   hs1   27938575   27961788       FGR      -  H. sapiens
    ENSG00000000971   hs1  196621008  196716634       CFH      +  H. sapiens
  #+END_EXAMPLE
  :END:

  #+NAME: write-pheno-def
  #+BEGIN_SRC ipython
    def qtltools_format(row):
      row['#Chr'] = 'chr{}'.format(row['chr'][2:])
      row['gid'] = row.name
      row['pid'] = row.name
      return row

    def write_pheno_file(pheno, gene_info, output_file):
      (gene_info
       .apply(qtltools_format, axis=1)
       .merge(pheno, left_index=True, right_index=True)
       .to_csv(output_file,
               sep='\t',
               columns=['#Chr', 'start', 'end', 'pid', 'gid', 'strand'] + list(pheno.columns),
               header=True,
               index=False,
               index_label=False)
      )
  #+END_SRC

  #+RESULTS: write-pheno-def
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython
    mean = pd.read_table('/scratch/midway2/aksarkar/singlecell/mean.txt.gz', sep=' ', index_col=0)
    mean.head()
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  #+BEGIN_EXAMPLE
                    NA18489   NA18498   NA18499   NA18501   NA18502   NA18505  \
    gene                                                                          
    ENSG00000000003  0.100813  0.100826  0.100818  0.100820  0.100813  0.100820   
    ENSG00000000005  0.101706  0.101708  0.101714  0.101709  0.101715  0.101699   
    ENSG00000000419  0.100818  0.100830  0.100832  0.100831  0.100826  0.100833   
    ENSG00000000457  0.101690  0.101715  0.101686  0.101692  0.101687  0.101648   
    ENSG00000000460  0.101443  0.101600  0.101394  0.101376  0.101434  0.101242   

                      NA18507   NA18508   NA18519   NA18520    ...      NA19119  \
    gene                                                       ...                
    ENSG00000000003  0.100812  0.100826  0.100808  0.100813    ...     0.100808   
    ENSG00000000005  0.101707  0.101718  0.101707  0.101718    ...     0.101712   
    ENSG00000000419  0.100821  0.100845  0.100807  0.100848    ...     0.100800   
    ENSG00000000457  0.101684  0.101693  0.101700  0.101690    ...     0.101696   
    ENSG00000000460  0.101435  0.101443  0.101296  0.101440    ...     0.101312   

                      NA19128   NA19153   NA19159   NA19190   NA19193   NA19203  \
    gene                                                                          
    ENSG00000000003  0.100813  0.100815  0.100817  0.100818  0.100806  0.100851   
    ENSG00000000005  0.101714  0.101692  0.101717  0.101715  0.101717  0.101704   
    ENSG00000000419  0.100827  0.100823  0.100885  0.100822  0.100812  0.101016   
    ENSG00000000457  0.101679  0.101684  0.101686  0.101664  0.101699  0.101714   
    ENSG00000000460  0.101267  0.101386  0.101514  0.101459  0.101406  0.101548   

                      NA19207   NA19210   NA19257  
    gene                                           
    ENSG00000000003  0.100809  0.100809  0.100811  
    ENSG00000000005  0.101710  0.101697  0.101718  
    ENSG00000000419  0.100808  0.100813  0.100814  
    ENSG00000000457  0.101693  0.101681  0.101686  
    ENSG00000000460  0.101324  0.101236  0.101293  

    [5 rows x 32 columns]
  #+END_EXAMPLE
  :END:

  #+BEGIN_SRC ipython
    write_pheno_file(mean, gene_info, '/scratch/midway2/aksarkar/singlecell/mean.bed')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  Index the phenotype file.

  #+NAME: tabix
  #+BEGIN_SRC sh :var input="mean.bed" :var partition="broadwl" :dir /scratch/midway2/aksarkar/singlecell :eval never-export
    export input=$input
    sbatch --partition=$partition --wait
    #!/bin/bash
    sort -k1,1 -k2,2n -k3,3n $input | bgzip >$input.gz
    tabix -p bed $input.gz
  #+END_SRC

  #+RESULTS: tabix
  : Submitted batch job 42125468

  Run the QTL mapping.

  #+NAME: qtltools
  #+BEGIN_SRC sh :var pheno="mean" :var partition="broadwl" :dir /scratch/midway2/aksarkar/singlecell :eval never-export 
    export pheno=$pheno
    sbatch --partition=$partition -N1 -c4 -J $pheno-qtl -o $pheno-qtl.log
    #!/bin/bash
    source activate scqtl
    module load parallel
    parallel -j4 qtltools cis --vcf /project2/gilad/singlecell-qtl/bulk/genotypes.vcf.gz --bed $pheno.bed.gz --nominal=0.01 --chunk {#} 100 --out $pheno-qtl.{#}.txt ::: $(seq 1 100)
  #+END_SRC

  #+RESULTS: qtltools
  : Submitted batch job 42125616

  Read the results.

  #+BEGIN_SRC ipython
    file_names = ['mean-qtl.{}.txt'.format(i) for i in range(1, 101)]
    mean_qtls = (pd.concat([pd.read_table(f, header=None, sep=' ') for f in file_names if os.path.exists(f) and os.path.getsize(f) > 0])
                 .rename(columns={i: x for i, x in enumerate(['gene', 'chr', 'start', 'end', 'strand', 'num_vars', 'distance', 'id', 'var_chr', 'var_start', 'var_end', 'p', 'beta', 'top'])})
                 .sort_values('p')
                 .set_index('gene'))
    mean_qtls[mean_qtls['top'] == 1].head()
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  #+BEGIN_EXAMPLE
                     chr   start     end strand  num_vars  distance id var_chr  \
    gene                                                                           
    ENSG00000239857   chr7  916190  936073      +      7763   -916190  C    chr7   
    ENSG00000169026   chr4  675619  683230      -      4952    675619  C    chr4   
    ENSG00000101282  chr20  939096  982907      -      6734    939096  G   chr20   
    ENSG00000186777   chr4  264465  299110      -      3531    264465  A    chr4   
    ENSG00000116014  chr19  917288  921015      +      6659   -917288  G   chr19   

                     var_start  var_end             p     beta  top  
    gene                                                             
    ENSG00000239857     986498        0  1.273710e-16 -4.71915    1  
    ENSG00000169026     810152        0  2.231630e-15 -4.74142    1  
    ENSG00000101282    1025679        0  3.021520e-15 -5.27573    1  
    ENSG00000186777     897103        0  4.407960e-15 -4.66579    1  
    ENSG00000116014     619338        0  1.081230e-14 -5.08811    1  
  #+END_EXAMPLE
  :END:

  *TODO:* Permutation testing within QTLtools? lfsr estimation by ~ashr~?

* Dispersion-QTL calling

  #+BEGIN_SRC ipython
    disp = pd.read_table('/scratch/midway2/aksarkar/singlecell/dispersion.txt.gz', sep=' ', index_col=0)
    disp.head()
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  #+BEGIN_EXAMPLE
                    NA18489   NA18498   NA18499   NA18501   NA18502   NA18505  \
    gene                                                                          
    ENSG00000000003 -0.100763 -0.100675 -0.100734 -0.100760 -0.100741 -0.100702   
    ENSG00000000005  0.101651  0.101593  0.101689  0.101660  0.101696  0.101641   
    ENSG00000000419 -0.100343 -0.099360 -0.100608 -0.100609 -0.100612 -0.100522   
    ENSG00000000457  0.101657  0.101686  0.101628  0.101641  0.101646  0.101546   
    ENSG00000000460  0.101485  0.101431  0.101470  0.101459  0.101525  0.101312   

                      NA18507   NA18508   NA18519   NA18520    ...      NA19119  \
    gene                                                       ...                
    ENSG00000000003 -0.100767 -0.100724 -0.100767 -0.100730    ...    -0.100771   
    ENSG00000000005  0.101672  0.101706  0.101674  0.101704    ...     0.101657   
    ENSG00000000419 -0.100702 -0.100601 -0.100672 -0.100502    ...    -0.100691   
    ENSG00000000457  0.101634  0.101633  0.101662  0.101643    ...     0.101613   
    ENSG00000000460  0.101509  0.101579  0.101383  0.101489    ...     0.101503   

                      NA19128   NA19153   NA19159   NA19190   NA19193   NA19203  \
    gene                                                                          
    ENSG00000000003 -0.100779 -0.100769 -0.100712 -0.100753 -0.100751 -0.100396   
    ENSG00000000005  0.101691  0.101639  0.101703  0.101687  0.101694  0.101638   
    ENSG00000000419 -0.100731 -0.100705 -0.099557 -0.100658 -0.100740  0.100554   
    ENSG00000000457  0.101635  0.101627  0.101626  0.101613  0.101649  0.101667   
    ENSG00000000460  0.101771  0.101616  0.101374  0.101582  0.101523  0.101548   

                      NA19207   NA19210   NA19257  
    gene                                           
    ENSG00000000003 -0.100776 -0.100776 -0.100754  
    ENSG00000000005  0.101666  0.101671  0.101700  
    ENSG00000000419 -0.100721 -0.100756 -0.100744  
    ENSG00000000457  0.101641  0.101602  0.101637  
    ENSG00000000460  0.101644  0.101577  0.101550  

    [5 rows x 32 columns]
  #+END_EXAMPLE
  :END:

  #+BEGIN_SRC ipython
    write_pheno_file(disp, gene_info, '/scratch/midway2/aksarkar/singlecell/disp.bed')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  Index the phenotype file

  #+CALL: tabix(input="disp.bed")

  #+RESULTS:
  : Submitted batch job 42125661

  Run ~qtltools~

  #+CALL: qtltools(pheno="disp")

  #+RESULTS:
  : Submitted batch job 42125670

  There are no detected dispersion QTLs, so the following code raises an exception.

  #+BEGIN_SRC ipython
    file_names = ['disp-qtl.{}.txt'.format(i) for i in range(1, 101)]
    disp_qtls = (pd.concat([pd.read_table(f, header=None, sep=' ') for f in file_names if os.path.exists(f) and os.path.getsize(f) > 0])
                 .rename(columns={i: x for i, x in enumerate(['gene', 'chr', 'start', 'end', 'strand', 'num_vars', 'distance', 'id', 'var_chr', 'var_start', 'var_end', 'p', 'beta', 'top'])})
                 .sort_values('p')
                 .set_index('gene'))
    disp_qtls[disp_qtls['top'] == 1].head()
  #+END_SRC
