#+TITLE: Diminishing returns of sequencing depth
#+SETUPFILE: setup.org

* Introduction

  As we sequence to greater depth, we expect that the number of UMIs which can
  be identified will plateau. Any other measure of sensitivity we are
  interested in (number of genes detected, minimum expression level detected)
  likely depends on the number of UMIs detected, so we use that number as the
  metric to quantify.

* Setup                                                            :noexport:

  #+BEGIN_SRC emacs-lisp
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(memory="16G",venv="scqtl") :dir /scratch/midway2/aksarkar/singlecell

  #+BEGIN_SRC ipython
    import colorcet
    import gzip
    import re
    import matplotlib.pyplot as plt
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[45]:
  :END:

* Method

  The idea of our approach is that randomly ordering the aligned reads allows
  us to quickly get subsamples of cumulatively increasing sizes. Although the
  different subsamples are not drawn iid., this approach will still give a
  rough idea of the relationship between the number of UMIs detected and the
  sequencing depth.

  The algorithm is:

  1. Shuffle the aligned reads
  2. For each read:
     1. If the UMI has a missing bases (~N~), ignore it. 

        We need to do this because we ignore which gene the UMI mapped to, so
        we can't use e.g. edit distance to merge the error-containing UMI with
        the closest UMI mapped to the same gene.

     2. If the UMI has been seen before, ignore it
     3. Otherwise, increment the number of UMIs seen by 1
     4. Output the count every \(10^4\) reads
  
  #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell
    sbatch --partition=broadwl -N1 -c16 --job-name="umi-vs-depth" --mem=8G --out umi-vs-depth.txt --err umi-vs-depth.err
    #!/bin/bash
    module load parallel
    function umi_vs_depth () {
        samtools view $1 | shuf | awk '{split($1, a, "_"); if (!index(a[2], "N") && !(a[2] in seen)) {seen[a[2]] = 1; n += 1}} !(NR % 10000) {print "'"$(basename $1 -sort.bam)"'", NR, n}'
    }
    export -f umi_vs_depth
    find /project2/gilad/singlecell-qtl/bam -name "*.bam" | parallel --tmpdir=/scratch/midway2/aksarkar umi_vs_depth
  #+END_SRC

  #+RESULTS:
  : Submitted batch job 42998029

  #+BEGIN_SRC ipython
    umi_vs_depth = pd.read_table('/scratch/midway2/aksarkar/singlecell/umi-vs-depth.txt', header=None, sep=' ')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[78]:
  :END:

  #+BEGIN_SRC ipython
    percentiles = [5, 50, 95]
    vals = np.nanpercentile(umi_vs_depth.pivot(index=0, columns=1).values, percentiles, interpolation='higher', axis=0)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[113]:
  :END:

  For each experiment, we have the empirical curve of number of UMIs detected
  versus number of reads considered. Plot the 5th, 50th (median), and 95th
  percentile of the curves (black), ignoring missing values (past the maximum
  number of reads in each experiment). Also plot the theoretical maximum number
  of detectable UMIs \(4^6\) (red) and 90% of the maximum (dotted red).

  #+BEGIN_SRC ipython :ipyfile figure/umi-saturation.org/cumulative-umi.png
    wells = set(umi_vs_depth[0])
    grid = np.array(sorted(set(umi_vs_depth[1]))).reshape(-1, 1)
    linestyles = ['dotted', 'solid', 'dotted']
    plt.clf()
    plt.axhline(y=4096, c='r')
    plt.axhline(y=.9 * 4096, c='r', ls='dotted')
    for v, p, ls in zip(vals, percentiles, linestyles):
      plt.plot(grid, v.reshape(-1, 1), c='k', ls=ls)
    plt.xlabel('Sequencing depth')
    plt.ylabel('Number of UMIs detected')
    plt.semilogx(basex=10)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[156]:
  : []
  [[file:figure/umi-saturation.org/cumulative-umi.png]]
  :END:
