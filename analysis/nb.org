#+TITLE: NB estimation
#+SETUPFILE: setup.org

* Setup

  #+BEGIN_SRC emacs-lisp
    (org-babel-lob-ingest "/home/aksarkar/projects/singlecell-qtl/analysis/qtl-mapping.org")
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(venv="scqtl", partition="gpu2")

  #+RESULTS:
  : Submitted batch job 41382582

  #+BEGIN_SRC ipython
    %matplotlib inline

    import edward as ed
    import functools
    import numpy as np
    import pandas as pd
    import pickle
    import tensorflow as tf
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

* Data

  #+BEGIN_SRC ipython
    with open('test_data.pkl', 'rb') as f:
      data = pickle.load(f)
    data.keys()
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  : dict_keys(['onehot', 'genotypes', 'counts', 'normalizers'])
  :END:

* Model specification and inference

  #+BEGIN_SRC ipython
    n, p = data['genotypes'].shape
    m, _ = data['onehot'].shape

    onehot = tf.placeholder(tf.float32, [m, n])
    genotypes = tf.placeholder(tf.float32, [n, p])
    normalizers = tf.placeholder(tf.float32, [m, 1])

    mean_bias = ed.models.Normal(loc=tf.zeros([n, 1]), scale=tf.ones([n, 1]))
    disp_bias = ed.models.Normal(loc=tf.zeros([1, 1]), scale=tf.ones([1, 1]))
    rate = ed.models.Gamma(
      concentration=tf.exp(tf.matmul(onehot, mean_bias)),
      rate=tf.exp(disp_bias))
    counts = ed.models.Poisson(rate=rate)

    q_mean_bias = ed.models.NormalWithSoftplusScale(
      loc=tf.Variable(tf.random_normal([n, 1])),
      scale=tf.Variable(tf.random_normal([n, 1])))
    q_disp_bias = ed.models.NormalWithSoftplusScale(
      loc=tf.Variable(tf.random_normal([1, 1])),
      scale=tf.Variable(tf.random_normal([1, 1])))

    inf = ed.ReparameterizationKLqp(
      latent_vars={mean_bias: q_mean_bias, disp_bias: q_disp_bias},
      data={globals()[k]: v for k, v in data.items()})
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython :async t
    inf.run(n_samples=10, optimizer=tf.train.AdamOptimizer(learning_rate=5e-3))
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython
    ed.get_session().run(mean_bias)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  #+BEGIN_EXAMPLE
  array([[-0.56121451],
           [-0.13816464],
           [ 0.79100668],
           [ 1.39567852],
           [-0.3465212 ],
           [-1.5193845 ],
           [-0.3371914 ],
           [-1.73874974],
           [ 1.25905216],
           [-0.43997651],
           [ 0.22527261],
           [ 0.03913439],
           [ 2.49046302],
           [ 0.70775157],
           [ 0.88101679],
           [-1.8379662 ],
           [ 0.20100313],
           [-1.25099945],
           [ 0.68994594],
           [ 0.11357166],
           [-0.2316011 ]], dtype=float32)
  #+END_EXAMPLE
  :END:

  #+BEGIN_SRC ipython
    ed.get_session().run(disp_bias)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  : array([[-0.33581865]], dtype=float32)
  :END:
