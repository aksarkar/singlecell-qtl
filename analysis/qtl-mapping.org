#+TITLE: QTL mapping pipeline
#+SETUPFILE: setup.org

* Introduction

  We take a modular approach to call QTLs:

  1. Estimate a mean and a dispersion for each individual
  2. Treat the mean/dispersion as continuous phenotypes and perform QTL mapping

  Here, we solve (2).

  1. [[*Reproduce bulk eQTL calls][We reproduce eQTLs]] called on the bulk RNA-Seq
  2. [[*Analysis using sample moments][We call mean/variance/CV/Fano QTLs]] using sample moments
  3. [[*Analysis using ZINB][We call mean/variance/CV/Fano QTLs]] using ZINB parameters
  4. [[*QTL overlap][We test replication/overlap]] between different QTL calls

* Setup                                                            :noexport:

  #+BEGIN_SRC emacs-lisp
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(memory="4G", venv="scqtl") :dir /scratch/midway2/aksarkar/singlecell

  #+RESULTS:
  : Submitted batch job 44974754

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])

    import colorcet
    import matplotlib.pyplot as plt
    import numpy as np
    import os.path
    import pandas as pd
    import rpy2.robjects.packages
    import rpy2.robjects.pandas2ri
    import rpy2.robjects.numpy2ri
    import scipy.stats as st
    import sklearn.decomposition as skd
    import sqlite3
    import tabix

    pandas2ri = rpy2.robjects.pandas2ri
    numpy2ri = rpy2.robjects.numpy2ri.numpy2ri
    edger = rpy2.robjects.packages.importr('edgeR')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[1]:
  :END:

* Implementation

  #+NAME: r-wrappers
  #+BEGIN_SRC ipython
    def cpm(x):
      return pd.DataFrame(pandas2ri.ri2py(edger.cpm(numpy2ri(x.values), log=True)),
                          columns=x.columns,
                          index=x.index)

    def qqnorm(x):
      """Wrap around R qqnorm"""
      return np.asarray(rpy2.robjects.r['qqnorm'](numpy2ri(x))[0])

    def bh(x):
      """Wrap around p.adjust(..., method='fdr')"""
      return np.asarray(rpy2.robjects.r['p.adjust'](numpy2ri(x), method='fdr'))
  #+END_SRC

  #+RESULTS: r-wrappers
  :RESULTS:
  # Out[127]:
  :END:

  #+NAME: get-gene-info
  #+BEGIN_SRC ipython
    gene_info = (pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-genes.txt.gz')
                 .set_index('gene')
                 .query('source == "H. sapiens"')
                 .query('chr != "hsX"')
                 .query('chr != "hsY"')
                 .query('chr != "hsMT"'))
  #+END_SRC

  #+RESULTS: get-gene-info
  :RESULTS:
  # Out[128]:
  :END:

  #+RESULTS:
  :RESULTS:
  # Out[40]:
  :END:

  #+NAME: write-gene-info
  #+BEGIN_SRC ipython
    with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
      gene_info.to_sql('gene_info', conn, index=True, if_exists='replace')
  #+END_SRC

  #+RESULTS: write-gene-info
  :RESULTS:
  # Out[4]:
  :END:

  #+RESULTS:
  :RESULTS:
  # Out[45]:
  :END:

  #+NAME: write-pheno-def
  #+BEGIN_SRC ipython
    def qtltools_format(row, prefix='chr'):
      row['#Chr'] = '{}{}'.format(prefix, row['chr'][2:])
      row['gid'] = row.name
      row['pid'] = row.name
      # Important: qtltools expects TSS start/end
      if row['strand'] == '+':
        row['end'] = row['start']
      else:
        row['start'] = row['end']
      return row.loc[['#Chr', 'start', 'end', 'pid', 'gid', 'strand']]

    def write_pheno_file(pheno, gene_info, output_file, holdout=True, **kwargs):
      if holdout:
        genes = gene_info.loc[gene_info.apply(lambda x: bool(int(x['chr'][2:]) % 2), axis=1)]
      else:
        genes = gene_info
      (genes
       .apply(qtltools_format, **kwargs, axis=1)
       .merge(pheno, left_index=True, right_index=True)
       .to_csv(output_file,
               sep='\t',
               header=True,
               index=False,
               index_label=False))
  #+END_SRC

  #+RESULTS: write-pheno-def
  :RESULTS:
  # Out[129]:
  :END:

  #+NAME: tabix
  #+BEGIN_SRC sh :var input="test.bed" :var partition="broadwl" :dir /scratch/midway2/aksarkar/singlecell :eval never-export
    export input=$input
    sbatch --partition=$partition --wait
    #!/bin/bash
    module load bedtools
    bedtools sort -header -i $input | bgzip >$input.gz
    tabix -f -p bed $input.gz
  #+END_SRC

  #+NAME: qtltools
  #+BEGIN_SRC sh :var pheno="test" :var geno="geuvadis-chr1.vcf.gz" :var partition="broadwl" :var op="--permute 100000" :dir /scratch/midway2/aksarkar/singlecell :eval never-export 
    export pheno=$pheno
    export geno=$geno
    export op=$op
    sbatch --partition=$partition -a 1-100 -J $pheno-qtl --wait
    #!/bin/bash
    source activate scqtl
    qtltools cis --vcf $geno --bed $pheno.bed.gz $op --chunk $SLURM_ARRAY_TASK_ID 100 --out $pheno-qtl.$SLURM_ARRAY_TASK_ID.txt --seed 0
  #+END_SRC

  #+NAME: read-qtltools-def
  #+BEGIN_SRC ipython
    def _read_helper(pheno, columns):
      file_names = ['{}-qtl.{}.txt'.format(pheno, i) for i in range(1, 101)]
      res = (pd.concat([pd.read_table(f, header=None, sep=' ')
                         for f in file_names if os.path.exists(f) and
                         os.path.getsize(f) > 0])
              .rename(columns={i: x for i, x in enumerate(columns)})
              .dropna()
              .sort_values('p_beta'))
      res['p_adjust'] = bh(res['p_beta'])
      res['fdr_pass'] = res['p_adjust'] < 0.1
      return res


    def read_fastqtl_output(pheno):
      columns = ['gene', 'num_snps', 'a', 'b', 'dummy', 'id',
                 'distance', 'p', 'beta', 'p_empirical', 'p_beta']
      res = _read_helper(pheno, columns)
      # Drop the gene version number
      res['gene'] = res['gene'].apply(lambda x: x.split('.')[0])
      res['chr'] = res['id'].apply(lambda x: x.split('.')[1])
      res['pos'] = res['id'].apply(lambda x: x.split('.')[2])
      res['id'] = res['id'].apply(lambda x: x.split('.')[0])
      return res

    def read_qtltools_output(pheno):
      columns = ['gene', 'chr', 'start', 'end', 'strand', 'num_vars',
                 'distance', 'id', 'var_chr', 'var_start', 'var_end', 'df',
                 'dummy', 'a', 'b', 'p_nominal', 'beta', 'p_empirical', 'p_beta']
      res = _read_helper(pheno, columns)
      res['chr'] = res['var_chr']
      res['pos'] = res['var_start']
      res['id'] = res['id'].apply(lambda x: x.split('.')[0])
      return res
  #+END_SRC

  #+RESULTS: read-qtltools-def
  :RESULTS:
  # Out[5]:
  :END:

  #+RESULTS:
  :RESULTS:
  # Out[79]:
  :END:

  #+NAME: plot-approx-perm-def
  #+BEGIN_SRC ipython
    def plot_approx_permutation(df):
      plt.clf()
      plt.gcf().set_size_inches(6, 6)
      plt.scatter(df['p_empirical'], df['p_beta'], s=1, c='k')
      plt.plot([0, 1], [0, 1], c='r', ls='--')
      plt.xlabel('Empirical p-value')
      plt.ylabel('Approximate p-value')
  #+END_SRC

  #+RESULTS: plot-approx-perm-def
  :RESULTS:
  # Out[131]:
  :END:

  #+NAME: qqplot-def
  #+BEGIN_SRC ipython
    def qqplot(qtls):
      N = qtls.shape[0]
      # 95% bootstrap CI
      ci = -np.log10(np.percentile(np.sort(np.random.uniform(size=(100, N)), axis=1), [5, 95], axis=0))

      grid = -np.log10(np.arange(1, 1 + N) / N)
      plt.clf()
      plt.gcf().set_size_inches(6, 6)
      plt.scatter(grid, -np.log10(qtls['p_beta']), s=1, c='k')
      plt.plot([0, np.log10(qtls.shape[0])], [0, np.log10(qtls.shape[0])], c='r', ls='--')
      plt.plot(grid, ci[0], c='r', ls=':')
      plt.plot(grid, ci[1], c='r', ls=':')
      plt.xlabel('Expected $-\log_{10}(p)$')
      _ = plt.ylabel('Observed $-\log_{10}(p)$')
  #+END_SRC

  #+RESULTS: qqplot-def
  :RESULTS:
  # Out[132]:
  :END:

  #+NAME: replication-tests-def
  #+BEGIN_SRC ipython
    def parse_vcf_dosage(record):
      geno = [float(g) for g in record[9:]]
      return pd.Series(geno)

    def extract_qtl_gene_pair(qtl_gene_df, pheno_df, dosages):
      """Return aligned genotype and phenotype matrix for each QTL-gene pair in qtl_gene_df"""
      common_phenos, common_qtls = pheno_df.align(qtl_gene_df.set_index('gene'), join='inner', axis=0)
      # Important: individual IDs do not have the NA prefix in the VCF
      header = ['NA{}'.format(x) for x in pd.read_table(dosages, nrows=1, header=0).columns[9:]]
      genotypes = tabix.open(dosages)
      X, Y = (common_qtls
              .apply(lambda x: parse_vcf_dosage(next(genotypes.query(x['chr'], int(x['var_start']) - 1, int(x['var_start'])))), axis=1)
              .rename(columns={i: ind for i, ind in enumerate(header)})
              .align(common_phenos, join='inner', axis=None))
      return X, Y

    def replication_tests(X, Y, C=None):
      """Return a DataFrame containing replication p-values

      X - centered dosage matrix (num_genes, num_individuals)
      Y - phenotype matrix (num_genes, num_individuals)
      C - confounder matrix (num_confounders, num_individuals)

      """
      p, n = X.shape
      assert Y.shape == (p, n)
      if C is not None:
        assert C.shape[1] == n
        C = np.array(C).T
        C = C - C.mean(axis=0)
        # Construct the annihilator matrix I - X X^+
        M = np.eye(n) - C.dot(np.linalg.pinv(C))
      result = []
      _sf = st.chi2(1).sf
      for (_, x), (name, y) in zip(X.iterrows(), Y.iterrows()):
        if np.isclose(x.std(), 0):
          print('Skipping {}'.format(name))
          continue
        x = x.values.copy().reshape(-1, 1)
        x -= x.mean()
        y = y.values.copy().ravel()
        y -= y.mean()
        if C is not None:
          y = M.dot(y)
          y -= y.mean()
        beta, rss, *_ = np.linalg.lstsq(x, y, rcond=-1)
        sigma2 = rss / y.shape[0]
        se = sigma2 / x.T.dot(x).ravel()
        pval = _sf(np.square(beta / se))
        result.append({'gene': name, 'beta': beta[0], 'se': se[0], 'p': pval.ravel()[0]})
      return pd.DataFrame.from_dict(result)

    def pairwise_replication(qtls, phenos, ticks):
      repl_rate = np.ones((len(phenos), len(phenos)))
      for i, ki in enumerate(phenos):
        for j, kj in enumerate(phenos):
          if i == j:
            continue
          q, p = qtls[ki][0], qtls[kj][1]
          X, Y = extract_qtl_gene_pair(q[q['fdr_pass']], p,
                                       dosages='/scratch/midway2/aksarkar/singlecell/reproduce-yang/YRI_SNPs_2_IPSC.txt.gen.gz')
          if X.empty:
            continue
          replication = q.merge(
            replication_tests(X, Y),
            on='gene',
            suffixes=['_1', '_2'])[['gene', 'id', 'beta_1', 'beta_2', 'p']]
          replication['fdr_pass'] = bh(replication['p']) < .1
          replication['replicated'] = replication.apply(lambda x: x['fdr_pass'] and x['beta_1'] * x['beta_2'] > 0, axis=1)
          repl_rate[i, j] = replication['replicated'].sum() / replication.shape[0]
      return pd.DataFrame(100 * repl_rate, columns=ticks, index=ticks)
  #+END_SRC

  #+RESULTS: replication-tests-def
  :RESULTS:
  # Out[133]:
  :END:
  :END:

* Preliminaries
** Test validity of approximate permutation test

   ~qtltools~ tries to calibrate false discovery rates using the following
   procedure:

   1. For each gene, permute the genotype data to estimate the null distribution
      of the p-values
   2. Fit a beta distribution to the permuted p-values via ML
   3. Compute the lower tail probability of the observed p-value, assuming it
      was generated from the fitted beta distribution
   4. Apply FDR correction on the set of lower tail probabilities (across all
      genes)

   Test whether the beta approximation is appropriate for our sample size by
   subsetting GEUVADIS. Take all genes on chromosome 1.

   #+BEGIN_SRC ipython
    geuvadis = []
    for chunk in pd.read_table('/project/compbio/geuvadis/analysis_results/GD462.GeneQuantRPKM.50FN.samplename.resk10.txt.gz', chunksize=100):
      geuvadis.append(chunk.query('Chr == "1"'))
    geuvadis = pd.concat(geuvadis)
    geuvadis = geuvadis.set_index(geuvadis['Gene_Symbol'].apply(lambda x: x.split('.')[0]))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[34]:
   :END:

   First, replicate the result in [[https://www.nature.com/articles/ncomms15452][Delaneau et al 2017]] by using all 462
   individuals from GEUVADIS.

   #+BEGIN_SRC ipython
    pd.Series(geuvadis.columns).sort_values().to_csv('/scratch/midway2/aksarkar/singlecell/geuvadis/geuvadis-subset.txt', header=None, index=None)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[35]:
   :END:

   Write out the phenotype file for ~qtltools~. Important: GEUVADIS VCFs code
   chromosome without ~chr~.

   #+BEGIN_SRC ipython
     write_pheno_file(geuvadis, gene_info, '/scratch/midway2/aksarkar/singlecell/geuvadis/test.bed', prefix='')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[39]:
   :END:

   Index the phenotype file. Important: ~#~ sorts before ~c~, but after ~1~.

   #+CALL: tabix() :dir /scratch/midway2/aksarkar/singlecell/geuvadis

   #+RESULTS:
   : Submitted batch job 44542169

   Perform SNP QC in ~plink~.

   #+NAME: geuvadis-qc
   #+BEGIN_SRC sh :eval never-export :dir /scratch/midway2/aksarkar/singlecell/geuvadis
     sbatch --partition=broadwl --mem=2G --wait
     #!/bin/bash
     plink --memory 2000 --geno 0.01 --maf 0.05 --keep-fam /scratch/midway2/aksarkar/singlecell/geuvadis-subset.txt --vcf /project/compbio/geuvadis/genotypes/GEUVADIS.chr1.PH1PH2_465.IMPFRQFILT_BIALLELIC_PH.annotv2.genotypes.vcf.gz --recode vcf-iid --out geuvadis-chr1
     bgzip -f geuvadis-chr1.vcf
     tabix -f -p vcf geuvadis-chr1.vcf.gz
   #+END_SRC

   #+RESULTS: geuvadis-qc
   : Submitted batch job 44541229

   Run ~qtltools~.

   #+CALL: qtltools() :dir /scratch/midway2/aksarkar/singlecell/geuvadis

   #+RESULTS:
   : Submitted batch job 44685856

   Read the results.

   #+BEGIN_SRC ipython
    geuvadis_qtls = read_qtltools_output('geuvadis/test')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[23]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/geuvadis-beta-approx.png
    plot_approx_permutation(geuvadis_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[41]:
   [[file:figure/qtl-mapping.org/geuvadis-beta-approx.png]]
   :END:

   Plot the QQ plot

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/geuvadis-qq.png
     qqplot(geuvadis_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[24]:
   [[file:figure/qtl-mapping.org/geuvadis-qq.png]]
   :END:

   Repeat the analysis after subsetting to 54 individuals.

   #+BEGIN_SRC ipython
    np.random.seed(0)
    subset = np.random.choice([x for x in geuvadis.columns], size=54, replace=False)
    pd.Series(subset).sort_values().to_csv('/scratch/midway2/aksarkar/singlecell/geuvadis-subset.txt', header=None, index=None)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[42]:
   :END:

   #+BEGIN_SRC ipython
     write_pheno_file(geuvadis[subset], gene_info, '/scratch/midway2/aksarkar/singlecell/geuvadis/test.bed', prefix='')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[44]:
   :END:

   #+CALL: tabix() :dir /scratch/midway2/aksarkar/singlecell/geuvadis

   #+RESULTS:
   : Submitted batch job 44544326

   #+CALL: geuvadis-qc() :dir /scratch/midway2/aksarkar/singlecell/geuvadis

   #+RESULTS:
   : Submitted batch job 44544018

   #+CALL: qtltools() :dir /scratch/midway2/aksarkar/singlecell/geuvadis

   #+RESULTS:
   : Submitted batch job 44544375

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/geuvadis-54-beta-approx.png
     geuvadis_54_qtls = read_qtltools_output('geuvadis/test')
     plot_approx_permutation(geuvadis_54_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[47]:
   [[file:figure/qtl-mapping.org/geuvadis-54-beta-approx.png]]
   :END:

** Reproduce bulk eQTL calls

   The iPSC bulk eQTLs were called in [[https://genome.cshlp.org/content/28/1/122.long][Banovich et al 2018]].

   #+BEGIN_EXAMPLE
     eQTLs in iPSCs and LCLs: We transformed expression levels to a standard normal
     within each individual. We next accounted for unknown confounders by removing
     principal components from the LCL (15 PCs) and iPSC (10 PCs) data. Genotypes
     were obtained using impute2 as described previously (Li et al. 2016). We only
     considered variants within 50 kb of genes. To identify association between
     genotype and gene expression, we used FastQTL (Ongen et al. 2016). After the
     initial regression, a variable number of permutations were performed to obtain
     a gene-wise adjusted P-value (Ongen et al. 2016). To identify significant
     eQTLs, we used Storey's q-value (Storey and Tibshirani 2003) on the adjusted
     P-values. Genes with a q-value less than 0.1 are considered significant.
   #+END_EXAMPLE

   *Important notes:*

   1. The text doesn't state how expression level was quantified (it was the
      ratio of mapped reads to total reads after correction by
      ~WASP~).

      ~WASP~ ([[https://www.nature.com/articles/nmeth.3582][de Geijin et al 2015]]) fits quartic polynomials \(f, g\) which
      predict the total read count per region \(T^*_{ij}\) from the observed
      read count \(x_{ij}\) and GC content \(w_j\) by maximizing the likelihood
      of the observed read counts:

      \[ x_{ij} \sim \mathrm{Pois}(T^*_{ij}) \]

      \[ T^*_{ij} = \exp\left(f\left(\sum_i x_{ij}\right)\right) g(w_j) \]

      [[*Recall bulk eQTLs from log CPM][Using log CPM]] (under the assumption that we never compare genes to each
      other) yields 1279 eQTLs (89%).

   2. ~fastqtl~ expects gene start/end, and only takes /cis/-SNPs around the
      start ignoring strand. The code uses GENCODE v19 exons to define the
      start/end.

      ~qtltools~ expects TSS and strand, but doesn't use strand information in
      /cis/-eQTL mapping. Using the start coordinate of the provided expression
      matrix as TSS yields 1265 eQTLs (87%).

   3. The methods section of [[https://www.nature.com/articles/nature10808][Degner et al 2012]] states data is standardized
      across individuals, and quantile normalized within individuals. The
      equation contradicts the text, but the code follows the text.

   4. The code analyzes 100kb windows, contradicting the text.

   5. Not every gene in the input appears in the output, and changing the number
      of chunks changes the number of genes lost.

   6. QTL-gene pairs passed the Benjamini-Hochberg procedure, not Storey's
      procedure.

   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/reproduce-yang
     sbatch --partition=broadwl -a 1-25
     #!/bin/bash
     source activate scqtl
     fastqtl -V YRI_SNPs_2_IPSC.txt.gen.gz -B fastqtl_qqnorm_RNAseq_run.fixed.txt.gz -C fasteqtl_PC_RNAseq_run.fixed.txt -O bulk-qtl.$SLURM_ARRAY_TASK_ID.txt --exclude-samples file_IPSC.excl --window 1e5 --permute 1000 10000 --chunk $SLURM_ARRAY_TASK_ID 25 --seed 1475098497
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 44546060

   Read ~fastqtl~ output.

   #+BEGIN_SRC ipython
     bulk_qtls = read_fastqtl_output('reproduce-yang/bulk')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[19]:
   :END:

   Write out the summary stats with headers.

   #+BEGIN_SRC ipython
     bulk_qtls.to_csv('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-mapping/bulk.txt.gz', sep='\t', index=None, compression='gzip')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[21]:
   :END:

   Compare ~qtltools~ to ~fastqtl~. The input files need to be modified.

   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/reproduce-yang/
     sbatch --partition=broadwl --wait
     #!/bin/bash
     zcat fastqtl_qqnorm_RNAseq_run.fixed.txt.gz | awk -vOFS='\t' 'NR == 1 {$4 = "pid" OFS "gid" OFS "strand"; for (i = 5; i <= NF; i++) {$i = "NA"$i} print} NR > 1 {$4 = $4 OFS $4 OFS "+"; $3 = $2; print}' >test.bed
     awk 'NR == 1 {for (i = 2; i <= NF; i++) {$i = "NA"$i}} {print}' fasteqtl_PC_RNAseq_run.fixed.txt >covars.txt
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 44979838

   Check whether the FDR is properly controlled by permuting.
   
   #+BEGIN_SRC ipython
     np.random.seed(0)
     permutation = bulk_expr.columns.values.copy()
     np.random.shuffle(permutation[5:])
     bulk_expr.columns = permutation

     covars = (pd.read_table('/scratch/midway2/aksarkar/singlecell/reproduce-yang/covars.txt', sep=' ')
               .rename(columns={k: v for k, v in zip(bulk_expr.columns, permutation)}))
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/reproduce-yang/covars.txt', sep=' ', index=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[121]:
   :END:

   Fix the TSS by rewriting the phenotype file.

   #+BEGIN_SRC ipython
     bulk_expr = pd.read_table('/scratch/midway2/aksarkar/singlecell/reproduce-yang/test.bed', index_col=3)
     bulk_expr.index = [x.split('.')[0] for x in bulk_expr.index]
     write_pheno_file(bulk_expr.iloc[:,5:], gene_info, '/scratch/midway2/aksarkar/singlecell/reproduce-yang/test.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[152]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="test.bed") :dir /scratch/midway2/aksarkar/singlecell/reproduce-yang/

   #+RESULTS:
   : Submitted batch job 44683584

   Run ~qtltools~.

   #+CALL: qtltools(pheno="test", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/reproduce-yang/

   #+RESULTS:
   : Submitted batch job 44683586

   Read ~qtltools output~

   #+BEGIN_SRC ipython
     bulk_qtls = read_qtltools_output('reproduce-yang/test')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[130]:
   :END:

   Check the beta approximation.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/qqnorm-beta-approx.png
     plot_approx_permutation(bulk_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[134]:
   [[file:figure/qtl-mapping.org/qqnorm-beta-approx.png]]
   :END:

   Plot a QQ plot of adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/qqnorm-qq.png
     qqplot(bulk_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[135]:
   [[file:figure/qtl-mapping.org/qqnorm-qq.png]]
   :END:

   Take QTLs with \(\mathrm{FDR} < 0.1\).

   #+BEGIN_SRC ipython
     bulk_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[136]:
   : 1441
   :END:

** Recall bulk eQTLs from log CPM

   Read the counts matrix.

   #+BEGIN_SRC ipython
     bulk_counts = (pd.read_table('/project2/gilad/singlecell-qtl/bulk/counts_RNAseq_iPSC.txt', sep=' ', index_col=0)
                    .rename(columns=lambda x: 'NA{}'.format(x))
                    .rename(index=lambda x: x.split('.')[0]))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[34]:
   :END:

   Throw out individuals.

   #+BEGIN_SRC ipython
     with open('/scratch/midway2/aksarkar/singlecell/reproduce-yang/file_IPSC.excl') as f:
       for line in f:
         k = 'NA{}'.format(line.strip())
         if k in bulk_counts:
           del bulk_counts[k]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[35]:
   :END:

   Normalize the counts matrix by computing log CPM. Normalizing by length is
   unnecessary because we only ever compare counts for the same gene across
   individuals.

   #+BEGIN_SRC ipython
     bulk_log_cpm = (cpm(bulk_counts)
                     .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                     .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[36]:
   :END:

   Compute expression PCs.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=10).fit(bulk_log_cpm).components_, columns=bulk_log_cpm.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/recall-bulk/log-cpm-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[37]:
   :END:

   Check whether the false discovery rate is properly controlled by permuting
   the data.

   Write the phenotype matrix in ~qtltools~ format.  Use the annotation data
   (ENSEMBL 75) in this repository to be consistent with the single cell
   data. *Important: this loses 1716 genes (are they pseudogenes?)*

   #+BEGIN_SRC ipython
     write_pheno_file(
       bulk_log_cpm,
       gene_info,
       holdout=False,
       output_file='/scratch/midway2/aksarkar/singlecell/recall-bulk/bulk-log-cpm.bed')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[38]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="bulk-log-cpm.bed") :dir /scratch/midway2/aksarkar/singlecell/recall-bulk

   #+RESULTS:
   : Submitted batch job 44681764

   Ensure the dosage file follows the VCF standard. Add the prefix ~NA~ to sample IDs.

   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/reproduce-yang
     sbatch --partition=broadwl
     #!/bin/bash
     zcat YRI_SNPs_2_IPSC.txt.gen.gz | awk -vOFS='\t' 'BEGIN {print "##fileformat=VCFv4.2"; print "##FORMAT=<ID=DS,Number=1,Type=Float>"} NR == 1 {for (i = 10; i <= NF; i++) {$i = "NA"$i}} {print}' | bgzip >yri-dosages.vcf.gz
     tabix yri-dosages.vcf.gz
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 44546926

   Run ~qtltools~

   #+CALL: qtltools(pheno="bulk-log-cpm", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov log-cpm-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/recall-bulk

   #+RESULTS:
   : Submitted batch job 44681768

   Read the output. *Important: this loses 201 genes (is this a bug in
   ~qtltools~)?*

   #+BEGIN_SRC ipython
     bulk_cpm_qtls = read_qtltools_output('recall-bulk/bulk-log-cpm')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[137]:
   :END:

   Check the beta approximation.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/bulk-cpm-beta-approx.png
     plot_approx_permutation(bulk_cpm_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[40]:
   [[file:figure/qtl-mapping.org/bulk-cpm-beta-approx.png]]
   :END:

   Plot a QQ plot of adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/bulk-cpm-qq.png
     qqplot(bulk_cpm_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[138]:
   [[file:figure/qtl-mapping.org/bulk-cpm-qq.png]]
   :END:

   Take QTLs with \(\mathrm{FDR} < 0.1\).

   #+BEGIN_SRC ipython
     bulk_cpm_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[139]:
   : 1276
   :END:

** Recall bulk eQTLs from log TPM

   We [[file:kallisto.org][reprocessed the bulk RNA-Seq data]] using ~kallisto~. Read the TPM
   matrix.

   #+BEGIN_SRC ipython
     bulk_log_tpm = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/kallisto/bulk-ipsc-tpm.txt.gz', header=None, sep=' ')
     bulk_log_tpm = np.log(bulk_log_tpm.pivot(columns=0, index=1, values=2) + 1)
     bulk_log_tpm.index = [x.split('.')[0] for x in bulk_log_tpm.index]
     # Important: need to throw out all zero rows because they blow up
     # standardization
     bulk_log_tpm = (bulk_log_tpm[bulk_log_tpm.apply(lambda x: x.sum() > 0, axis=1)]
                     .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                     .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[140]:
   :END:

   To quantify how much power we expect to lose going from 58 to 49 individuals
   (in our scRNA-Seq data), perform QTL mapping on a random subset of 49
   individuals.

   #+BEGIN_SRC ipython
     np.random.seed(0)
     keep_inds = np.random.choice(bulk_log_tpm.columns, size=49, replace=False)
     bulk_log_tpm = bulk_log_tpm.filter(items=keep_inds, axis='columns')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[37]:
   :END:

   Check whether the false discovery rate is properly controlled by permuting
   the data.

   #+BEGIN_SRC ipython
     np.random.seed(0)
     permutation = bulk_log_tpm.columns.values
     np.random.shuffle(permutation)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[67]:
   :END:

   Get the TSS information. Use the annotation data (ENSEMBL 75) in this
   repository to be consistent with the single cell data.

   Write the phenotype matrix in ~qtltools~ format. *Important: this loses 1034
   genes*

   #+BEGIN_SRC ipython
     write_pheno_file(
       bulk_log_tpm,
       gene_info,
       holdout=False,
       output_file='/scratch/midway2/aksarkar/singlecell/recall-bulk/bulk-log-tpm.bed')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[141]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="bulk-log-tpm.bed") :dir /scratch/midway2/aksarkar/singlecell/recall-bulk

   #+RESULTS:
   : Submitted batch job 44686635

   Compute principal components.

   #+BEGIN_SRC ipython
    covars = pd.DataFrame(skd.PCA(n_components=6).fit(bulk_log_tpm).components_, columns=bulk_log_tpm.columns)
    covars.index.name = 'id'
    covars.to_csv('/scratch/midway2/aksarkar/singlecell/recall-bulk/log-tpm-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[142]:
   :END:

   Run ~qtltools~

   #+CALL: qtltools(pheno="bulk-log-tpm", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov log-tpm-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/recall-bulk

   #+RESULTS:
   : Submitted batch job 44686640

   Read the output. *Important: this loses 201 genes (is this a bug in
   ~qtltools~)?*

   #+BEGIN_SRC ipython
     bulk_tpm_qtls = read_qtltools_output('recall-bulk/bulk-log-tpm')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[143]:
   :END:

   Check the beta approximation to the permuted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/bulk-tpm-beta-approx.png
     plot_approx_permutation(bulk_tpm_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[144]:
   [[file:figure/qtl-mapping.org/bulk-tpm-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/bulk-log-tpm-qtl-qq.png
     qqplot(bulk_tpm_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[145]:
   [[file:figure/qtl-mapping.org/bulk-log-tpm-qtl-qq.png]]
   :END:

   Take QTLs with \(\mathrm{FDR} < 0.1\).

   #+BEGIN_SRC ipython
     bulk_tpm_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[146]:
   : 1020
   :END:

* Analysis using sample moments

  The simplest possible way to estimate means/variances/dispersions to use as
  quantitative phenotypes is to use the sample moments.

  Intuitively, the phenotypes defined this way will be confounded by
  differential proportion of zeros between individuals, but we need to quantify
  the resulting loss in power.

** Call eQTLs from pooled scRNA-Seq

   Read the QC filters.

   #+NAME: qc-filters
   #+BEGIN_SRC ipython
     annotation = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-annotation.txt')
     keep_samples = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/quality-single-cells.txt', index_col=0, header=None)
     keep_genes = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/genes-pass-filter.txt', index_col=0, header=None)
     annotation = annotation.loc[keep_samples.values.ravel()]
     keep_inds = annotation.groupby('chip_id').apply(lambda x: len(x) >= 50)
   #+END_SRC

   #+RESULTS: qc-filters
   :RESULTS:
   # Out[16]:
   :END:

   Read and pool the UMI data.

   #+BEGIN_SRC ipython
     pooled_counts = pd.concat(
       [(chunk
         .filter(items=keep_genes[keep_genes.values].index, axis='index')
         # Important: this can't be done by filter because sample names are
         # different in the QC file
         .loc[:,keep_samples.values.ravel()]
         .groupby(annotation['chip_id'].values, axis=1)
         .agg(np.sum))
        for chunk in
        pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-counts.txt.gz',
                      chunksize=1000, index_col=0)])
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[17]:
   :END:

   Normalize the pooled counts.

   #+BEGIN_SRC ipython
     pooled_cpm = (cpm(pooled_counts).loc[:,keep_inds]
                   .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                   .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[18]:
   :END:

   Compute principal components and write out the covariate file.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=10).fit(pooled_cpm).components_, columns=pooled_cpm.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/pooled-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[19]:
   :END:

   Write out the phenotype file.

   #+BEGIN_SRC ipython
     write_pheno_file(pooled_cpm, gene_info, holdout=False, output_file='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/pooled.bed')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[13]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="pooled.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45127968

   Run ~qtltools~

   #+CALL: qtltools(pheno="pooled", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov pooled-covars.txt  --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45127969

   Read the output. *Important: this loses 200 genes (is this a bug in
   ~qtltools~)?*

   #+BEGIN_SRC ipython
     pooled_qtls = read_qtltools_output('scqtl-mapping/pooled')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[14]:
   :END:

   Check the beta approximation.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/pooled-cpm-beta-approx.png
     plot_approx_permutation(pooled_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[15]:
   [[file:figure/qtl-mapping.org/pooled-cpm-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/pooled-qtl-qq.png
     qqplot(pooled_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[16]:
   [[file:figure/qtl-mapping.org/pooled-qtl-qq.png]]
   :END:

   Take QTLs with \(\mathrm{FDR} < 0.1\).

   #+BEGIN_SRC ipython
    pooled_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[17]:
   : 240
   :END:

** Call mean-QTLs

   Throw out individuals with fewer than 50 cells.

   #+CALL: qc-filters()

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   :END:

   Read the count matrix.

   #+NAME: read-umi
   #+BEGIN_SRC ipython
     umi = pd.concat(
       [(chunk
         .filter(items=keep_genes[keep_genes.values].index, axis='index')
         # Important: this can't be done by filter because sample names are
         # different in the QC file
         .loc[:,keep_samples.values.ravel()])
        for chunk in
        pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-counts.txt.gz',
                      chunksize=1000, index_col=0)])
   #+END_SRC

   Compute the sample mean log CPM per individual, then normalize.

   #+BEGIN_SRC ipython
     sample_mean = (cpm(umi)
                    .groupby(annotation['chip_id'].values, axis=1)
                    .agg(np.mean)
                    .loc[:,keep_inds]
                    .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                    .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[14]:
   :END:

   Compute principal components and write out the covariate file.

   #+BEGIN_SRC ipython
    covars = pd.DataFrame(skd.PCA(n_components=10).fit(sample_mean).components_, columns=sample_mean.columns)
    covars.index.name = 'id'
    covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-mean-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[15]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(
       sample_mean,
       gene_info,
       output_file='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-mean.bed',
       holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[16]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="sample-mean.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45128520

   Run ~qtltools~.

   #+CALL: qtltools(pheno="sample-mean", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov sample-mean-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45128522

   Read the output.

   #+BEGIN_SRC ipython
     sample_mean_qtls = read_qtltools_output('scqtl-mapping/sample-mean')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[17]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-mean-qtl-beta-approx.png
     plot_approx_permutation(sample_mean_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[18]:
   [[file:figure/qtl-mapping.org/sample-mean-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-mean-qtl-qq.png
     qqplot(sample_mean_qtls)
   #+end_SRC

   #+RESULTS:
   :RESULTS:
   # Out[19]:
   [[file:figure/qtl-mapping.org/sample-mean-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
    sample_mean_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[20]:
   : 176
   :END:

** Call variance-QTLs

   Throw out individuals with fewer than 50 cells.

   #+CALL: qc-filters()

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   :END:

   Read the UMI matrix.

   #+CALL: read-umi()

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   :END:

   Compute the sample variance of log CPM per individual, then normalize.

   #+BEGIN_SRC ipython
     sample_var = (cpm(umi)
                    .groupby(annotation['chip_id'].values, axis=1)
                    .agg(np.var)
                    .loc[:,keep_inds]
                    .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                    .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   :END:

   Compute principal components and write out the covariate file.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=2).fit(sample_var).components_, columns=sample_var.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-var-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[21]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(sample_var, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-var.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[22]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="sample-var.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45128698

   Run ~qtltools~.

   #+CALL: qtltools(pheno="sample-var", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov sample-var-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45128699

   Read the output.

   #+BEGIN_SRC ipython
     sample_var_qtls = read_qtltools_output('scqtl-mapping/sample-var')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[23]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-var-qtl-beta-approx.png
     plot_approx_permutation(sample_var_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[24]:
   [[file:figure/qtl-mapping.org/sample-var-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-var-qtl-qq.png
     qqplot(sample_var_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[25]:
   [[file:figure/qtl-mapping.org/sample-var-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     sample_var_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[26]:
   : 3
   :END:

** Call CV-QTLs

   Throw out individuals with fewer than 50 cells.

   #+CALL: qc-filters()

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   :END:

   Read the UMI matrix.

   #+CALL: read-umi()

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   :END:

   Compute the sample CV of log CPM per individual, then normalize.

   #+BEGIN_SRC ipython
     sample_cv = (cpm(umi)
                    .groupby(annotation['chip_id'].values, axis=1)
                    .agg(lambda x: np.std(x, axis=1) / (np.mean(x, axis=1) + 1e-8))
                    .loc[:,keep_inds]
                    .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                    .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[30]:
   :END:

   Normalize the CV matrix.

   #+BEGIN_SRC ipython
     sample_cv = sample_cv.loc[:,keep_inds].transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=0)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[31]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(sample_cv, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-cv.bed', holdout=True)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[32]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="sample-cv.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45128842

   Run ~qtltools~.

   #+CALL: qtltools(pheno="sample-cv", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45128843

   Read the output.

   #+BEGIN_SRC ipython
    sample_cv_qtls = read_qtltools_output('scqtl-mapping/sample-cv')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[33]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-cv-qtl-beta-approx.png
     plot_approx_permutation(sample_cv_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[34]:
   [[file:figure/qtl-mapping.org/sample-cv-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-cv-qtl-qq.png
    qqplot(sample_cv_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[35]:
   [[file:figure/qtl-mapping.org/sample-cv-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
    sample_cv_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[36]:
   : 0
   :END:

** Call Fano-QTLs

   Throw out individuals with fewer than 50 cells.

   #+CALL: qc-filters()

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   :END:

   Read the UMI matrix.

   #+CALL: read-umi()

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   :END:

   Fisher's index of dispersion is defined as \(V[x] / E[x]\). The Fano factor
   is Fisher's index of dispersion over a fixed window (in our case, the total
   number of reads).

   Compute the sample Fano factor of log CPM per individual, then normalize.

   #+BEGIN_SRC ipython
     sample_fano = (cpm(umi)
                    .groupby(annotation['chip_id'].values, axis=1)
                    .agg(lambda x: np.var(x, axis=1) / (np.mean(x, axis=1)))
                    .loc[:,keep_inds]
                    .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                    .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[38]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(sample_fano, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample_fano.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[40]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="sample_fano.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45129160

   Compute principal components and write out the covariate file.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=2).fit(sample_fano).components_, columns=sample_fano.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-fano-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[41]:
   :END:

   Run ~qtltools~.

   #+CALL: qtltools(pheno="sample_fano", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov sample-fano-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45129161

   Read the output.

   #+BEGIN_SRC ipython
     sample_fano_qtls = read_qtltools_output('scqtl-mapping/sample_fano')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[42]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-fano-qtl-beta-approx.png
     plot_approx_permutation(sample_fano_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[43]:
   [[file:figure/qtl-mapping.org/sample-fano-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-fano-qtl-qq.png
     qqplot(sample_fano_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[44]:
   [[file:figure/qtl-mapping.org/sample-fano-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     sample_fano_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[45]:
   : 2
   :END:

* Analysis using ZINB
** Call \mu-QTLs

   Throw out individuals with fewer than 50 cells.

   #+CALL: qc-filters()

   #+RESULTS:
   :RESULTS:
   # Out[63]:
   :END:

   Read the estimated parameters \(\log \mu_{ik}\). Exclude individuals with
   fewer than 50 cells.

   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       log_mu = (pd.read_sql(
         """select gene, ind, log_mu from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn)
                   .pivot(index='gene', columns='ind', values='log_mu'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   :END:

   Normalize the mean matrix analagous to the bulk data. In our estimation
   procedure, we now return \(\ln\mu = -\infty\) for individuals with only zero
   observations. Clip this to \(\ln\epsilon\), where \(\epsilon\) is the
   smallest representable floating point number.

   #+BEGIN_SRC ipython
     log_mu = np.clip(log_mu.loc[keep_genes.values.ravel()].dropna(), np.log(np.finfo(np.float).eps), 0).transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=0)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[12]:
   :END:

   Compute principal components of the mean matrix.

   #+BEGIN_SRC ipython
    covars = pd.DataFrame(skd.PCA(n_components=10).fit(log_mu).components_, columns=log_mu.columns)
    covars.index.name = 'id'
    covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/log_mu-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[13]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(log_mu, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/log_mu.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[20]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="log_mu.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45074749

   Run ~qtltools~.

   #+CALL: qtltools(pheno="log_mu", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov log_mu-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45074760

   Read the output.

   #+BEGIN_SRC ipython
     log_mu_qtls = read_qtltools_output('scqtl-mapping/log_mu')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[21]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/mu-qtl-beta-approx.png
     plot_approx_permutation(log_mu_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[22]:
   [[file:figure/qtl-mapping.org/mu-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/mu-qtl-qq.png
     qqplot(log_mu_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[23]:
   [[file:figure/qtl-mapping.org/mu-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     log_mu_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[24]:
   : 211
   :END:

** Call \phi-QTLs

   Read the estimated parameters. Exclude individuals with fewer than 50 cells.

   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       log_phi = (pd.read_sql(
         """select gene, ind, log_phi from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn)
                  .pivot(index='gene', columns='ind', values='log_phi'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[14]:
   :END:

   Normalize the dispersion matrix. Again, we have infinite values, but
   dispersions are not restricted to be in \([0, 1]\), so we have to change the
   clipping bounds.

   #+BEGIN_SRC ipython
     log_phi = np.clip(log_phi.loc[keep_genes.values.ravel()].dropna(), -300, 300).transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=1)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[206]:
   :END:

   Write out the phenotype file.

   #+BEGIN_SRC ipython
     write_pheno_file(log_phi, gene_info, holdout=False, output_file='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/log_phi.bed')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[27]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="log_phi.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45075315

   Run ~qtltools~.

   #+CALL: qtltools(pheno="log_phi", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45075319

   Read the output.

   #+BEGIN_SRC ipython
    log_phi_qtls = read_qtltools_output('scqtl-mapping/log_phi')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[22]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/phi-qtl-beta-approx.png
    plot_approx_permutation(log_phi_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[29]:
   [[file:figure/qtl-mapping.org/phi-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/phi-qtl-qq.png
    qqplot(log_phi_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[30]:
   [[file:figure/qtl-mapping.org/phi-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     log_phi_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[31]:
   : 0
   :END:

** Call \pi-QTLs

   For each gene \(k\), fit a linear model:

   \[ \mathrm{logit}(\pi_k) = X\beta + \epsilon \]

   Read the estimated parameters. Exclude individuals with fewer than 50 cells.

   #+BEGIN_SRC ipython
    with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
      logodds = (pd.read_sql(
        """select gene, ind, logodds from params where ind in 
        (select chip_id from annotation group by chip_id 
        having count(distinct sample) >= 50);""", conn)
                 .pivot(index='gene', columns='ind', values='logodds'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[32]:
   :END:

   Normalize the log odds matrix.

   #+BEGIN_SRC ipython
     logodds = np.clip(logodds.loc[keep_genes.values.ravel()].dropna(), -300, 300)
     logodds = logodds.loc[(logodds.agg(np.std, axis=1) > 0).values]
     logodds = logodds.transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=1)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[33]:
   :END:

   Write out the phenotype file.

   #+BEGIN_SRC ipython
     write_pheno_file(logodds, gene_info, holdout=False, output_file='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/logodds.bed')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[34]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="logodds.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45075744

   Run ~qtltools~.

   #+CALL: qtltools(pheno="logodds", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45075760

   Read the output.

   #+BEGIN_SRC ipython
     logodds_qtls = read_qtltools_output('scqtl-mapping/logodds')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[23]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/logodds-qtl-beta-approx.png
     plot_approx_permutation(logodds_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[36]:
   [[file:figure/qtl-mapping.org/logodds-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/logodds-qtl-qq.png
     qqplot(logodds_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[37]:
   [[file:figure/qtl-mapping.org/logodds-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     logodds_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[38]:
   : 0
   :END:

** Call mean-QTLs

   We have \(r_{ijk} \sim g_{ijk}(\cdot)\), where \(g\) is the ZINB density [[file:zinb.org][as
   previously defined]].

   Fixing individual \(i\), gene \(k\), we can estimate a
   zero-inflation--corrected mean as:

   \[ E[r_{ijk}] = R_{ijk} \mu_{ik} \]

   Read the estimated corrected means.

   #+NAME: read-mean
   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       mean = (pd.read_sql(
         """select gene, ind, mean from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn)
                  .pivot(index='gene', columns='ind', values='mean'))
   #+END_SRC

   #+RESULTS: read-mean
   :RESULTS:
   # Out[16]:
   :END:

   #+RESULTS:
   :RESULTS:
   # Out[207]:
   :END:

   Normalize the mean matrix.

   #+NAME: normalize-mean
   #+BEGIN_SRC ipython
     mean = mean.loc[keep_genes.values.ravel()].transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=0)
   #+END_SRC

   #+RESULTS: normalize-mean
   :RESULTS:
   # Out[17]:
   :END:

   #+RESULTS:
   :RESULTS:
   # Out[208]:
   :END:

   Compute principal components of the mean matrix.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=10).fit(mean).components_, columns=mean.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/mean-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[41]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
    write_pheno_file(mean, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/mean.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[42]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="mean.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45076054

   Run ~qtltools~.

   #+CALL: qtltools(pheno="mean", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov mean-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45076062

   Read the output.

   #+BEGIN_SRC ipython
     mean_qtls = read_qtltools_output('scqtl-mapping/mean')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[135]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/mean-qtl-beta-approx.png
     plot_approx_permutation(mean_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[44]:
   [[file:figure/qtl-mapping.org/mean-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/mean-qtl-qq.png
    qqplot(mean_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[45]:
   [[file:figure/qtl-mapping.org/mean-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     mean_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[46]:
   : 199
   :END:

** Call variance-QTLs

   We have \(r_{ijk} \sim g_{ijk}(\cdot)\), where \(g\) is the ZINB density [[file:zinb.org][as
   previously defined]].

   Fixing individual \(i\), gene \(k\), we can estimate a
   zero-inflation--corrected variance as:

   \[ E[r_{ijk}] = R_{ijk} \mu_{ik} \]

   \[ V[r_{ijk}] = E[r_{ijk}] + \left(E[r_{ijk}]\right)^2 \phi_{ik} \]

   Read the estimated corrected variances.

   #+NAME: read-variance
   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       variance = (pd.read_sql(
         """select gene, ind, var from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn)
                  .pivot(index='gene', columns='ind', values='var'))
   #+END_SRC

   #+RESULTS: read-variance
   :RESULTS:
   # Out[61]:
   :END:

   #+RESULTS:
   :RESULTS:
   # Out[47]:
   :END:

   Normalize the variance matrix.

   #+NAME: normalize-variance
   #+BEGIN_SRC ipython
     variance = variance.loc[keep_genes.values.ravel()].transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=0)
   #+END_SRC

   #+RESULTS: normalize-variance
   :RESULTS:
   # Out[64]:
   :END:

   #+RESULTS:
   :RESULTS:
   # Out[48]:
   :END:

   Compute principal components of the variance matrix.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=2).fit(variance).components_, columns=variance.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/variance-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[65]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~.

   #+BEGIN_SRC ipython
     write_pheno_file(variance, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/variance.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[66]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="variance.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45224226

   Run ~qtltools~.

   #+CALL: qtltools(pheno="variance", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov variance-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45224227

   Read the output.

   #+BEGIN_SRC ipython
     variance_qtls = read_qtltools_output('scqtl-mapping/variance')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[67]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/variance-qtl-beta-approx.png
     plot_approx_permutation(variance_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[68]:
   [[file:figure/qtl-mapping.org/variance-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/variance-qtl-qq.png
     qqplot(variance_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[69]:
   [[file:figure/qtl-mapping.org/variance-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     variance_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[70]:
   : 100
   :END:

** Call CV-QTLs

   Estimate the coefficient of variation using the corrected moments.

   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       params = (pd.read_sql(
         """select gene, ind, mean, var from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn))
       params['cv'] = np.sqrt(params['var']) / (params['mean'] + 1e-8)
       cv = params.pivot(index='gene', columns='ind', values='cv')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[55]:
   :END:

   Normalize the CV matrix.

   #+BEGIN_SRC ipython
     cv = cv.loc[keep_genes.values.ravel()].transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=0)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[56]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(cv, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/cv.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[57]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="cv.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45076903

   Run ~qtltools~.

   #+CALL: qtltools(pheno="cv", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45076906

   Read the output.

   #+BEGIN_SRC ipython
     cv_qtls = read_qtltools_output('scqtl-mapping/cv')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[26]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/cv-qtl-beta-approx.png
     plot_approx_permutation(cv_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[59]:
   [[file:figure/qtl-mapping.org/cv-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/cv-qtl-qq.png
     qqplot(cv_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[60]:
   [[file:figure/qtl-mapping.org/cv-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     cv_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[61]:
   : 4
   :END:

** Call Fano-QTLs

   Estimate the coefficient of variation using the corrected moments.

   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       params = (pd.read_sql(
         """select gene, ind, mean, var from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn))
       params['fano'] = params['var'] / (params['mean'] + 1e-8)
       fano = params.pivot(index='gene', columns='ind', values='fano')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[211]:
   :END:

   Normalize the Fano matrix.

   #+BEGIN_SRC ipython
     fano = fano.loc[keep_genes.values.ravel()].transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=0)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[212]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(fano, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/fano.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[64]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="fano.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45077183

   Run ~qtltools~.

   #+CALL: qtltools(pheno="fano", geno="", op="--window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45077190

   Read the output.

   #+BEGIN_SRC ipython
     fano_qtls = read_qtltools_output('scqtl-mapping/fano')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[27]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/fano-qtl-beta-approx.png
     plot_approx_permutation(fano_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[66]:
   [[file:figure/qtl-mapping.org/fano-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/fano-qtl-qq.png
     qqplot(fano_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[67]:
   [[file:figure/qtl-mapping.org/fano-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     fano_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[68]:
   : 9
   :END:

* Write out the QTLs

  #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping
    sbatch --partition=broadwl
    #!/bin/bash
    cat >.rsync-filter <<EOF
    + */
    + *.bed.gz
    + *.txt.gz
    + *covars*
    - *
    EOF
    function z { test $1-qtl.1.txt -nt $1.txt.gz && cat $1-qtl.*.txt | awk 'BEGIN {print "gene", "chr", "start", "end", "strand", "num_vars", "distance", "id", "var_chr", "var_start", "var_end", "df", "dummy", "a", "b", "p_nominal", "beta", "p_empirical", "p_beta"} {print}' | gzip >$1.txt.gz; }
    export -f z
    parallel -j1 z ::: cv fano log-mean logodds mean phi pooled variance
    rsync -FFau . /project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-mapping/
  #+END_SRC

  #+RESULTS:
  : Submitted batch job 45224360

* QTL overlap
** Replication rates

  Read the QTLs and normalized expression matrices.

  #+BEGIN_SRC ipython
    prefix = '/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-mapping/'
    qtls = {pheno: (pd.read_table('{}/{}.txt.gz'.format(prefix, pheno), sep=' '),
                    pd.read_table('{}/{}.bed.gz'.format(prefix, pheno)).set_index('pid').filter(like='NA', axis='columns'))
            for pheno in ['pooled', 'log_mu', 'log_phi', 'mean', 'variance', 'fano']}
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[123]:
  :END:

  The bulk QTLs are in ~fastqtl~ format and need some munging.

  #+BEGIN_SRC ipython
    bulk_qtls = pd.read_table('{}/bulk.txt.gz'.format(prefix))
    bulk_qtls['var_start'] = bulk_qtls['pos']
    # Important: this collides with the field we're going to add in
    # replication_tests
    del bulk_qtls['p']
    bulk_expr = pd.read_table('{}/bulk.bed.gz'.format(prefix)).set_index('pid').filter(like='NA', axis='columns')
    bulk_expr.index = [x.split('.')[0] for x in bulk_expr.index]
    qtls['bulk'] = (bulk_qtls, bulk_expr)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[124]:
  :END:

  Compute the gene-level FDR filter.

  #+BEGIN_SRC ipython
    for k in qtls:
      qtls[k][0]['fdr_pass'] = bh(qtls[k][0]['p_beta']) < 0.1
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[136]:
  :END:

  Estimate replication rates for mean QTLs.

  #+BEGIN_SRC ipython
    pd.options.display.float_format = '{:.3g}'.format
    pairwise_replication(qtls, phenos=['bulk', 'pooled', 'log_mu', 'mean'], ticks=['Bulk', 'Pooled', '$\log(\mu)$', 'ZI mean'])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[88]:
  #+BEGIN_EXAMPLE
    Bulk  Pooled  $\log(\mu)$  ZI mean
    Bulk          100    80.1         77.2     77.1
    Pooled         82     100          100     99.6
    $\log(\mu)$  80.6    99.5          100      100
    ZI mean      80.1    99.5          100      100
  #+END_EXAMPLE
  :END:

  Estimate the rate at which variance QTLs replicate as mean QTLs (and vice versa).

  #+BEGIN_SRC ipython
    pairwise_replication(qtls,
                         phenos=['bulk', 'pooled', 'log_mu', 'mean', 'log_phi', 'variance', 'fano'],
                         ticks=['Bulk', 'Pooled', '$\log(\mu)$', 'ZI mean', '$\log(\phi)$', 'ZI variance', 'ZI Fano'])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[104]:
  #+BEGIN_EXAMPLE
    $\log(\mu)$  ZI mean  $\log(\phi)$  ZI variance  ZI Fano
    $\log(\mu)$           100      100          43.3         99.5     83.3
    ZI mean               100      100          41.9          100     81.8
    $\log(\phi)$          100      100           100          100      100
    ZI variance           100      100          84.1          100      100
    ZI Fano               100      100           100          100      100
  #+END_EXAMPLE
  :END:


  #+BEGIN_SRC ipython
    with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
      fano_qtls[['gene', 'id', 'beta', 'p_beta', 'fdr_pass']].to_sql('fano_qtls', conn, index=False, if_exists='replace')
      conn.execute('create index ix_fano_qtls on fano_qtls(gene);')
      X, Y = extract_qtl_gene_pair(fano_qtls[fano_qtls['fdr_pass']], fano, dosages='/scratch/midway2/aksarkar/singlecell/reproduce-yang/YRI_SNPs_2_IPSC.txt.gen.gz')
      X.reset_index().melt(id_vars='gene', var_name='ind').to_sql('fano_qtl_geno', conn, index=False, if_exists='replace')
      conn.execute('create index ix_fano_qtl_geno on fano_qtl_geno(gene, ind);')
      Y.reset_index().melt(id_vars='gene', var_name='ind').to_sql('fano', conn, index=False, if_exists='replace')
      conn.execute('create index ix_fano on fano(gene, ind);')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[185]:
  :END:

