#+TITLE: QTL mapping pipeline
#+SETUPFILE: setup.org

* Introduction

  We take a modular approach to call QTLs:

  1. Estimate a mean and a dispersion for each individual
  2. Treat the mean/dispersion as continuous phenotypes and perform QTL mapping

  Here, we solve (2).

  1. [[*Reproduce bulk eQTL calls][We reproduce eQTLs]] called on the bulk RNA-Seq
  2. [[*Analysis using sample moments][We call mean/variance/CV/Fano QTLs]] using sample moments
  3. [[*Analysis using ZINB][We call mean/variance/CV/Fano QTLs]] using ZINB parameters
  4. [[*QTL overlap][We test replication/overlap]] between different QTL calls
  5. We [[*Multivariate adaptive shrinkage][find genes likely to have variance-effects]] using multivariate adaptive shrinkage

* Setup                                                            :noexport:

  #+BEGIN_SRC emacs-lisp
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(memory="16G", venv="scqtl") :dir /scratch/midway2/aksarkar/singlecell

  #+RESULTS:
  : Submitted batch job 45523151

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])

    import colorcet
    import gzip
    import matplotlib.pyplot as plt
    import numpy as np
    import os.path
    import pandas as pd
    import pathlib
    import pickle
    import rpy2.robjects.packages
    import rpy2.robjects.pandas2ri
    import rpy2.robjects.numpy2ri
    import scipy.special as sp
    import scipy.stats as st
    import sklearn.decomposition as skd
    import sklearn.metrics
    import sqlite3
    import tabix

    ashr = rpy2.robjects.packages.importr('ashr')
    edger = rpy2.robjects.packages.importr('edgeR')
    mashr = rpy2.robjects.packages.importr('mashr')

    pandas2ri = rpy2.robjects.pandas2ri
    numpy2ri = rpy2.robjects.numpy2ri.numpy2ri
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[55]:
  :END:

* Implementation

  #+NAME: r-wrappers
  #+BEGIN_SRC ipython
    def cpm(x):
      return pd.DataFrame(pandas2ri.ri2py(edger.cpm(numpy2ri(x.values), log=True)),
                          columns=x.columns,
                          index=x.index)

    def qqnorm(x):
      """Wrap around R qqnorm"""
      return np.asarray(rpy2.robjects.r['qqnorm'](numpy2ri(x))[0])

    def bh(x):
      """Wrap around p.adjust(..., method='fdr')"""
      return np.asarray(rpy2.robjects.r['p.adjust'](numpy2ri(x), method='fdr'))
  #+END_SRC

  #+RESULTS: r-wrappers
  :RESULTS:
  # Out[56]:
  :END:

  #+NAME: get-gene-info
  #+BEGIN_SRC ipython
    gene_info = (pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-genes.txt.gz')
                 .set_index('gene')
                 .query('source == "H. sapiens"')
                 .query('chr != "hsX"')
                 .query('chr != "hsY"')
                 .query('chr != "hsMT"'))
  #+END_SRC

  #+RESULTS: get-gene-info
  :RESULTS:
  # Out[57]:
  :END:

  #+RESULTS:
  :RESULTS:
  # Out[40]:
  :END:

  #+NAME: write-gene-info
  #+BEGIN_SRC ipython
    with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
      gene_info.to_sql('gene_info', conn, index=True, if_exists='replace')
  #+END_SRC

  #+RESULTS: write-gene-info
  :RESULTS:
  # Out[4]:
  :END:

  #+RESULTS:
  :RESULTS:
  # Out[45]:
  :END:

  #+NAME: write-pheno-def
  #+BEGIN_SRC ipython
    def qtltools_format(row, prefix='chr'):
      row['#Chr'] = '{}{}'.format(prefix, row['chr'][2:])
      row['gid'] = row.name
      row['pid'] = row.name
      # Important: qtltools expects TSS start/end
      if row['strand'] == '+':
        row['end'] = row['start']
      else:
        row['start'] = row['end']
      return row.loc[['#Chr', 'start', 'end', 'pid', 'gid', 'strand']]

    def write_pheno_file(pheno, gene_info, output_file, holdout=True, **kwargs):
      if holdout:
        genes = gene_info.loc[gene_info.apply(lambda x: bool(int(x['chr'][2:]) % 2), axis=1)]
      else:
        genes = gene_info
      (genes
       .apply(qtltools_format, **kwargs, axis=1)
       .merge(pheno, left_index=True, right_index=True)
       .to_csv(output_file,
               sep='\t',
               header=True,
               index=False,
               index_label=False))
  #+END_SRC

  #+RESULTS: write-pheno-def
  :RESULTS:
  # Out[58]:
  :END:

  #+NAME: tabix
  #+BEGIN_SRC sh :var input="test.bed" :var partition="broadwl" :dir /scratch/midway2/aksarkar/singlecell :eval never-export
    export input=$input
    sbatch --partition=$partition --wait
    #!/bin/bash
    module load bedtools
    bedtools sort -header -i $input | bgzip >$input.gz
    tabix -f -p bed $input.gz
  #+END_SRC

  #+NAME: qtltools
  #+BEGIN_SRC sh :var pheno="test" :var geno="geuvadis-chr1.vcf.gz" :var partition="broadwl" :var op="--permute 100000" :dir /scratch/midway2/aksarkar/singlecell :eval never-export :results output
    export pheno=$pheno
    export geno=$geno
    export op=$op
    sbatch --partition=$partition -a 1-100 -J $pheno-qtl --wait
    #!/bin/bash
    source activate scqtl
    qtltools cis --vcf $geno --bed $pheno.bed.gz $op --chunk $SLURM_ARRAY_TASK_ID 100 --out $pheno-qtl.$SLURM_ARRAY_TASK_ID.txt --seed 0
  #+END_SRC

  #+NAME: read-qtltools-def
  #+BEGIN_SRC ipython
    def _read_helper(pheno, columns):
      file_names = ['{}-qtl.{}.txt'.format(pheno, i) for i in range(1, 101)]
      res = (pd.concat([pd.read_table(f, header=None, sep=' ')
                         for f in file_names if os.path.exists(f) and
                         os.path.getsize(f) > 0])
              .rename(columns={i: x for i, x in enumerate(columns)})
              .dropna()
              .sort_values('p_beta'))
      res['p_adjust'] = bh(res['p_beta'])
      res['fdr_pass'] = res['p_adjust'] < 0.1
      return res


    def read_fastqtl_output(pheno):
      columns = ['gene', 'num_snps', 'a', 'b', 'dummy', 'id',
                 'distance', 'p', 'beta', 'p_empirical', 'p_beta']
      res = _read_helper(pheno, columns)
      # Drop the gene version number
      res['gene'] = res['gene'].apply(lambda x: x.split('.')[0])
      res['chr'] = res['id'].apply(lambda x: x.split('.')[1])
      res['pos'] = res['id'].apply(lambda x: x.split('.')[2])
      res['id'] = res['id'].apply(lambda x: x.split('.')[0])
      return res

    def read_qtltools_output(pheno):
      columns = ['gene', 'chr', 'start', 'end', 'strand', 'num_vars',
                 'distance', 'id', 'var_chr', 'var_start', 'var_end', 'df',
                 'dummy', 'a', 'b', 'p_nominal', 'beta', 'p_empirical', 'p_beta']
      res = _read_helper(pheno, columns)
      res['chr'] = res['var_chr']
      res['pos'] = res['var_start']
      res['id'] = res['id'].apply(lambda x: x.split('.')[0])
      return res

    def read_nominal_pass(f):
      isf = st.chi2(1).isf
      result = pd.read_table(f, sep=' ', header=None)
      result.columns = ['gene', 'chr', 'start', 'end', 'strand', 'n', 'distance', 'id', 'var_chr', 'var_start', 'var_end', 'p_nominal', 'beta', 'top']
      result['z'] = np.sign(result['beta']) * np.sqrt(isf(result['p_nominal']))
      return result
  #+END_SRC

  #+RESULTS: read-qtltools-def
  :RESULTS:
  # Out[59]:
  :END:

  #+RESULTS:
  :RESULTS:
  # Out[79]:
  :END:

  #+NAME: plot-approx-perm-def
  #+BEGIN_SRC ipython
    def plot_approx_permutation(df):
      plt.clf()
      plt.gcf().set_size_inches(6, 6)
      plt.scatter(df['p_empirical'], df['p_beta'], s=1, c='k')
      plt.plot([0, 1], [0, 1], c='r', ls='--')
      plt.xlabel('Empirical p-value')
      plt.ylabel('Approximate p-value')
  #+END_SRC

  #+RESULTS: plot-approx-perm-def
  :RESULTS:
  # Out[60]:
  :END:

  #+NAME: qqplot-def
  #+BEGIN_SRC ipython
    def qqplot(qtls):
      N = qtls.shape[0]
      # 95% bootstrap CI
      ci = -np.log10(np.percentile(np.sort(np.random.uniform(size=(100, N)), axis=1), [5, 95], axis=0))

      grid = -np.log10(np.arange(1, 1 + N) / N)
      plt.clf()
      plt.gcf().set_size_inches(6, 6)
      plt.scatter(grid, -np.log10(qtls['p_beta']), s=1, c='k')
      plt.plot([0, np.log10(qtls.shape[0])], [0, np.log10(qtls.shape[0])], c='r', ls='--')
      plt.plot(grid, ci[0], c='r', ls=':')
      plt.plot(grid, ci[1], c='r', ls=':')
      plt.xlabel('Expected $-\log_{10}(p)$')
      _ = plt.ylabel('Observed $-\log_{10}(p)$')
  #+END_SRC

  #+RESULTS: qqplot-def
  :RESULTS:
  # Out[61]:
  :END:

  #+NAME: replication-tests-def
  #+BEGIN_SRC ipython
    def parse_vcf_dosage(record):
      geno = [float(g) for g in record[9:]]
      return pd.Series(geno)

    def extract_qtl_gene_pair(qtl_gene_df, pheno_df, dosages):
      """Return aligned genotype and phenotype matrix for each QTL-gene pair in qtl_gene_df"""
      common_phenos, common_qtls = pheno_df.align(qtl_gene_df.set_index('gene'), join='inner', axis=0)
      # Important: assume individual IDs are prefixed by "NA". This isn't true in
      # the original VCF
      header = pd.read_table(dosages, skiprows=2, nrows=1, header=0).columns[9:]
      genotypes = tabix.open(dosages)
      X, Y = (common_qtls
              .apply(lambda x: parse_vcf_dosage(next(genotypes.query(x['chr'], int(x['var_start']) - 1, int(x['var_start'])))), axis=1)
              .rename(columns={i: ind for i, ind in enumerate(header)})
              .align(common_phenos, join='inner', axis=None))
      return X, Y

    def replication_tests(X, Y, C=None):
      """Return a DataFrame containing replication p-values

      X - centered dosage matrix (num_genes, num_individuals)
      Y - phenotype matrix (num_genes, num_individuals)
      C - confounder matrix (num_confounders, num_individuals)

      """
      p, n = X.shape
      assert Y.shape == (p, n)
      if C is not None:
        assert C.shape[1] == n
        C = np.array(C).T
        C = C - C.mean(axis=0)
        # Construct the annihilator matrix I - X X^+
        M = np.eye(n) - C.dot(np.linalg.pinv(C))
      result = []
      _sf = st.chi2(1).sf
      for (_, x), (name, y) in zip(X.iterrows(), Y.iterrows()):
        if np.isclose(x.std(), 0):
          print('Skipping {}'.format(name))
          continue
        x = x.values.copy().reshape(-1, 1)
        x -= x.mean()
        y = y.values.copy().ravel()
        y -= y.mean()
        if C is not None:
          y = M.dot(y)
          y -= y.mean()
        beta, rss, *_ = np.linalg.lstsq(x, y, rcond=-1)
        sigma2 = rss / y.shape[0]
        se = sigma2 / x.T.dot(x).ravel()
        pval = _sf(np.square(beta / se))
        result.append({'gene': name, 'beta': beta[0], 'se': se[0], 'p': pval.ravel()[0]})
      return pd.DataFrame.from_dict(result)

    def pairwise_replication(qtls, phenos, ticks, covars=None):
      if covars is not None:
        assert len(covars) == len(phenos)
      assert len(phenos) == len(ticks)
      repl_rate = np.ones((len(phenos), len(phenos)))
      for i, ki in enumerate(phenos):
        for j, kj in enumerate(phenos):
          if i == j:
            continue
          q, p = qtls[ki][0], qtls[kj][1]
          X, Y = extract_qtl_gene_pair(q[q['fdr_pass']], p,
                                       dosages='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz')
          if X.empty:
            continue
          C = covars[j] if covars is not None else None
          replication = q.merge(
            replication_tests(X, Y, C),
            on='gene',
            suffixes=['_1', '_2'])[['gene', 'id', 'beta_1', 'beta_2', 'p']]
          replication['fdr_pass'] = bh(replication['p']) < .1
          replication['replicated'] = replication.apply(lambda x: x['fdr_pass'] and x['beta_1'] * x['beta_2'] > 0, axis=1)
          repl_rate[i, j] = replication['replicated'].sum() / replication.shape[0]
      return pd.DataFrame(100 * repl_rate, columns=ticks, index=ticks)
  #+END_SRC

  #+RESULTS: replication-tests-def
  :RESULTS:
  # Out[62]:
  :END:

  #+NAME: bootstrap-def
  #+BEGIN_SRC ipython
    def bootstrap_se(X, Y, C=None, num_bootstraps=100, seed=0):
      np.random.seed(seed)
      beta = {}
      for i in range(num_bootstraps):
        b = np.random.choice(X.shape[1], size=X.shape[1], replace=True)
        if C is not None:
          beta[i] = replication_tests(X.iloc[:,b], Y.iloc[:,b], C.iloc[:,b]).set_index('gene')['beta']
        else:
          beta[i] = replication_tests(X.iloc[:,b], Y.iloc[:,b]).set_index('gene')['beta']
      return pd.DataFrame.from_dict(beta).agg(np.std, axis=1)
  #+END_SRC

  #+RESULTS: bootstrap-def
  :RESULTS:
  # Out[63]:
  :END:

  #+NAME: bootstrap-betahat-se-def
  #+BEGIN_SRC ipython
    def _fit_lm(x, y):
      n, p = x.shape
      assert y.shape == (n, 1)
      y -= y.mean()
      x -= x.mean(axis=0)
      beta = x.T.dot(y) / np.var(x, axis=0).values.reshape(-1, 1)
      return beta

    def estimate_beta_se(genes, dosages, gene_info, covars=None, window=100000, n_bootstrap=100, seed=0):
      """Estimate beta via OLS and SE via bootstrap

      genes - dataframe (num_genes, num_individuals)
      dosages - VCF file name
      gene_info - dataframe (see read_gene_info)
      covars - dataframe (num_covars, num_individuals)

      """
      with gzip.open(dosages, 'rt') as f:
        for line in f:
          if line.startswith('#CHROM'):
            header = line.split()[9:]
            break
      dosages = tabix.open(dosages)
      if covars is not None:
        covars, genes = covars.align(genes, axis='columns', join='inner')
        _, n = covars.shape
        covars = covars.values.T
        M = np.eye(n) - covars.dot(np.linalg.pinv(covars))
      result = []
      for gene, Y in genes.iterrows():
        if gene in gene_info.index:
          record = gene_info.loc[gene]
          if record['strand'] == '+':
            X = dosages.query('chr{}'.format(record['chr'][2:]), record['start'] - window, record['start'] + window)
          else:
            X = dosages.query('chr{}'.format(record['chr'][2:]), record['end'] - window, record['end'] + window)
          X = list(X)
          meta = [row[2] for row in X]
          X = pd.DataFrame([parse_vcf_dosage(row) for row in X])
          X.index = meta
          X.columns = header
          X, Y = X.align(Y, axis='columns', join='inner')
          if covars is not None:
            Y = M.dot(Y - Y.mean())
          X = X.transform(lambda x: x - x.mean(), axis=1)

          beta = [_fit_lm(X.T, Y.reshape(-1, 1))]
          np.random.seed(seed)
          for _ in range(n_bootstrap):
            B = np.random.choice(n, size=n, replace=True)
            beta.append(_fit_lm(X.iloc[:,B].T, Y[B].reshape(-1, 1)))
          result.append(pd.DataFrame({'gene': gene, 'snp': meta, 'beta': beta[0].values.ravel(), 'se': np.std(np.ma.masked_invalid(np.hstack(beta[1:])), axis=1)}))
      return pd.concat(result)
  #+END_SRC

  #+RESULTS: bootstrap-betahat-se-def
  :RESULTS:
  # Out[64]:
  :END:

* Preliminaries
** Test validity of approximate permutation test

   ~qtltools~ tries to calibrate false discovery rates using the following
   procedure:

   1. For each gene, permute the genotype data to estimate the null distribution
      of the p-values
   2. Fit a beta distribution to the permuted p-values via ML
   3. Compute the lower tail probability of the observed p-value, assuming it
      was generated from the fitted beta distribution
   4. Apply FDR correction on the set of lower tail probabilities (across all
      genes)

   Test whether the beta approximation is appropriate for our sample size by
   subsetting GEUVADIS. Take all genes on chromosome 1.

   #+BEGIN_SRC ipython
    geuvadis = []
    for chunk in pd.read_table('/project/compbio/geuvadis/analysis_results/GD462.GeneQuantRPKM.50FN.samplename.resk10.txt.gz', chunksize=100):
      geuvadis.append(chunk.query('Chr == "1"'))
    geuvadis = pd.concat(geuvadis)
    geuvadis = geuvadis.set_index(geuvadis['Gene_Symbol'].apply(lambda x: x.split('.')[0]))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[34]:
   :END:

   First, replicate the result in [[https://www.nature.com/articles/ncomms15452][Delaneau et al 2017]] by using all 462
   individuals from GEUVADIS.

   #+BEGIN_SRC ipython
    pd.Series(geuvadis.columns).sort_values().to_csv('/scratch/midway2/aksarkar/singlecell/geuvadis/geuvadis-subset.txt', header=None, index=None)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[35]:
   :END:

   Write out the phenotype file for ~qtltools~. Important: GEUVADIS VCFs code
   chromosome without ~chr~.

   #+BEGIN_SRC ipython
     write_pheno_file(geuvadis, gene_info, '/scratch/midway2/aksarkar/singlecell/geuvadis/test.bed', prefix='')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[39]:
   :END:

   Index the phenotype file. Important: ~#~ sorts before ~c~, but after ~1~.

   #+CALL: tabix() :dir /scratch/midway2/aksarkar/singlecell/geuvadis

   #+RESULTS:
   : Submitted batch job 44542169

   Perform SNP QC in ~plink~.

   #+NAME: geuvadis-qc
   #+BEGIN_SRC sh :eval never-export :dir /scratch/midway2/aksarkar/singlecell/geuvadis
     sbatch --partition=broadwl --mem=2G --wait
     #!/bin/bash
     plink --memory 2000 --geno 0.01 --maf 0.05 --keep-fam /scratch/midway2/aksarkar/singlecell/geuvadis-subset.txt --vcf /project/compbio/geuvadis/genotypes/GEUVADIS.chr1.PH1PH2_465.IMPFRQFILT_BIALLELIC_PH.annotv2.genotypes.vcf.gz --recode vcf-iid --out geuvadis-chr1
     bgzip -f geuvadis-chr1.vcf
     tabix -f -p vcf geuvadis-chr1.vcf.gz
   #+END_SRC

   #+RESULTS: geuvadis-qc
   : Submitted batch job 44541229

   Run ~qtltools~.

   #+CALL: qtltools() :dir /scratch/midway2/aksarkar/singlecell/geuvadis

   #+RESULTS:
   : Submitted batch job 44685856

   Read the results.

   #+BEGIN_SRC ipython
    geuvadis_qtls = read_qtltools_output('geuvadis/test')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[23]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/geuvadis-beta-approx.png
    plot_approx_permutation(geuvadis_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[41]:
   [[file:figure/qtl-mapping.org/geuvadis-beta-approx.png]]
   :END:

   Plot the QQ plot

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/geuvadis-qq.png
     qqplot(geuvadis_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[24]:
   [[file:figure/qtl-mapping.org/geuvadis-qq.png]]
   :END:

   Repeat the analysis after subsetting to 54 individuals.

   #+BEGIN_SRC ipython
    np.random.seed(0)
    subset = np.random.choice([x for x in geuvadis.columns], size=54, replace=False)
    pd.Series(subset).sort_values().to_csv('/scratch/midway2/aksarkar/singlecell/geuvadis-subset.txt', header=None, index=None)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[42]:
   :END:

   #+BEGIN_SRC ipython
     write_pheno_file(geuvadis[subset], gene_info, '/scratch/midway2/aksarkar/singlecell/geuvadis/test.bed', prefix='')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[44]:
   :END:

   #+CALL: tabix() :dir /scratch/midway2/aksarkar/singlecell/geuvadis

   #+RESULTS:
   : Submitted batch job 44544326

   #+CALL: geuvadis-qc() :dir /scratch/midway2/aksarkar/singlecell/geuvadis

   #+RESULTS:
   : Submitted batch job 44544018

   #+CALL: qtltools() :dir /scratch/midway2/aksarkar/singlecell/geuvadis

   #+RESULTS:
   : Submitted batch job 44544375

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/geuvadis-54-beta-approx.png
     geuvadis_54_qtls = read_qtltools_output('geuvadis/test')
     plot_approx_permutation(geuvadis_54_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[47]:
   [[file:figure/qtl-mapping.org/geuvadis-54-beta-approx.png]]
   :END:

** Reproduce bulk eQTL calls

   The iPSC bulk eQTLs were called in [[https://genome.cshlp.org/content/28/1/122.long][Banovich et al 2018]].

   #+BEGIN_EXAMPLE
     eQTLs in iPSCs and LCLs: We transformed expression levels to a standard normal
     within each individual. We next accounted for unknown confounders by removing
     principal components from the LCL (15 PCs) and iPSC (10 PCs) data. Genotypes
     were obtained using impute2 as described previously (Li et al. 2016). We only
     considered variants within 50 kb of genes. To identify association between
     genotype and gene expression, we used FastQTL (Ongen et al. 2016). After the
     initial regression, a variable number of permutations were performed to obtain
     a gene-wise adjusted P-value (Ongen et al. 2016). To identify significant
     eQTLs, we used Storey's q-value (Storey and Tibshirani 2003) on the adjusted
     P-values. Genes with a q-value less than 0.1 are considered significant.
   #+END_EXAMPLE

   *Important notes:*

   1. The text doesn't state how expression level was quantified (it was the
      ratio of mapped reads to total reads after correction by
      ~WASP~).

      ~WASP~ ([[https://www.nature.com/articles/nmeth.3582][de Geijin et al 2015]]) fits quartic polynomials \(f, g\) which
      predict the total read count per region \(T^*_{ij}\) from the observed
      read count \(x_{ij}\) and GC content \(w_j\) by maximizing the likelihood
      of the observed read counts:

      \[ x_{ij} \sim \mathrm{Pois}(T^*_{ij}) \]

      \[ T^*_{ij} = \exp\left(f\left(\sum_i x_{ij}\right)\right) g(w_j) \]

      [[*Recall bulk eQTLs from log CPM][Using log CPM]] (under the assumption that we never compare genes to each
      other) yields 1279 eQTLs (89%).

   2. ~fastqtl~ expects gene start/end, and only takes /cis/-SNPs around the
      start ignoring strand. The code uses GENCODE v19 exons to define the
      start/end.

      ~qtltools~ expects TSS and strand, but doesn't use strand information in
      /cis/-eQTL mapping. Using the start coordinate of the provided expression
      matrix as TSS yields 1265 eQTLs (87%).

   3. The methods section of [[https://www.nature.com/articles/nature10808][Degner et al 2012]] states data is standardized
      across individuals, and quantile normalized within individuals. The
      equation contradicts the text, but the code follows the text.

   4. The code analyzes 100kb windows, contradicting the text.

   5. Not every gene in the input appears in the output, and changing the number
      of chunks changes the number of genes lost.

   6. QTL-gene pairs passed the Benjamini-Hochberg procedure, not Storey's
      procedure.

   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/reproduce-yang
     sbatch --partition=broadwl -a 1-25
     #!/bin/bash
     source activate scqtl
     fastqtl -V YRI_SNPs_2_IPSC.txt.gen.gz -B fastqtl_qqnorm_RNAseq_run.fixed.txt.gz -C fasteqtl_PC_RNAseq_run.fixed.txt -O bulk-qtl.$SLURM_ARRAY_TASK_ID.txt --exclude-samples file_IPSC.excl --window 1e5 --permute 1000 10000 --chunk $SLURM_ARRAY_TASK_ID 25 --seed 1475098497
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 44546060

   Read ~fastqtl~ output.

   #+BEGIN_SRC ipython
     bulk_qtls = read_fastqtl_output('reproduce-yang/bulk')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[19]:
   :END:

   Write out the summary stats with headers.

   #+BEGIN_SRC ipython
     bulk_qtls.to_csv('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-mapping/bulk.txt.gz', sep='\t', index=None, compression='gzip')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[21]:
   :END:

   Compare ~qtltools~ to ~fastqtl~. The input files need to be modified.

   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/reproduce-yang/
     sbatch --partition=broadwl --wait
     #!/bin/bash
     zcat fastqtl_qqnorm_RNAseq_run.fixed.txt.gz | awk -vOFS='\t' 'NR == 1 {$4 = "pid" OFS "gid" OFS "strand"; for (i = 5; i <= NF; i++) {$i = "NA"$i} print} NR > 1 {$4 = $4 OFS $4 OFS "+"; $3 = $2; print}' >test.bed
     awk 'NR == 1 {for (i = 2; i <= NF; i++) {$i = "NA"$i}} {print}' fasteqtl_PC_RNAseq_run.fixed.txt >bulk-covars.txt
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 44979838

   Check whether the FDR is properly controlled by permuting.
   
   #+BEGIN_SRC ipython
     np.random.seed(0)
     permutation = bulk_expr.columns.values.copy()
     np.random.shuffle(permutation[5:])
     bulk_expr.columns = permutation

     covars = (pd.read_table('/scratch/midway2/aksarkar/singlecell/reproduce-yang/covars.txt', sep=' ')
               .rename(columns={k: v for k, v in zip(bulk_expr.columns, permutation)}))
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/reproduce-yang/covars.txt', sep=' ', index=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[121]:
   :END:

   Fix the TSS by rewriting the phenotype file.

   #+BEGIN_SRC ipython
     bulk_expr = pd.read_table('/scratch/midway2/aksarkar/singlecell/reproduce-yang/test.bed', index_col=3)
     bulk_expr.index = [x.split('.')[0] for x in bulk_expr.index]
     write_pheno_file(bulk_expr.iloc[:,5:], gene_info, '/scratch/midway2/aksarkar/singlecell/reproduce-yang/test.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[152]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="test.bed") :dir /scratch/midway2/aksarkar/singlecell/reproduce-yang/

   #+RESULTS:
   : Submitted batch job 44683584

   Run ~qtltools~.

   #+CALL: qtltools(pheno="test", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/reproduce-yang/

   #+RESULTS:
   : Submitted batch job 44683586

   Run ~qtltools~ on reprocessed dosages.

   #+CALL: qtltools(pheno="test", geno="/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz", op="--cov covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/reproduce-yang/

   Read ~qtltools output~

   #+BEGIN_SRC ipython
     bulk_qtls = read_qtltools_output('reproduce-yang/test')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[25]:
   :END:

   Check the beta approximation.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/qqnorm-beta-approx.png
     plot_approx_permutation(bulk_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[134]:
   [[file:figure/qtl-mapping.org/qqnorm-beta-approx.png]]
   :END:

   Plot a QQ plot of adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/qqnorm-qq.png
     qqplot(bulk_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[135]:
   [[file:figure/qtl-mapping.org/qqnorm-qq.png]]
   :END:

   Take QTLs with \(\mathrm{FDR} < 0.1\).

   #+BEGIN_SRC ipython
     bulk_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[26]:
   : 1040
   :END:

** Recall bulk eQTLs from log CPM

   Read the counts matrix.

   #+BEGIN_SRC ipython
     bulk_counts = (pd.read_table('/project2/gilad/singlecell-qtl/bulk/counts_RNAseq_iPSC.txt', sep=' ', index_col=0)
                    .rename(columns=lambda x: 'NA{}'.format(x))
                    .rename(index=lambda x: x.split('.')[0]))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[34]:
   :END:

   Throw out individuals.

   #+BEGIN_SRC ipython
     with open('/scratch/midway2/aksarkar/singlecell/reproduce-yang/file_IPSC.excl') as f:
       for line in f:
         k = 'NA{}'.format(line.strip())
         if k in bulk_counts:
           del bulk_counts[k]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[35]:
   :END:

   Normalize the counts matrix by computing log CPM. Normalizing by length is
   unnecessary because we only ever compare counts for the same gene across
   individuals.

   #+BEGIN_SRC ipython
     bulk_log_cpm = (cpm(bulk_counts)
                     .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                     .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[36]:
   :END:

   Compute expression PCs.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=10).fit(bulk_log_cpm).components_, columns=bulk_log_cpm.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/recall-bulk/log-cpm-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[37]:
   :END:

   Check whether the false discovery rate is properly controlled by permuting
   the data.

   Write the phenotype matrix in ~qtltools~ format.  Use the annotation data
   (ENSEMBL 75) in this repository to be consistent with the single cell
   data. *Important: this loses 1716 genes (are they pseudogenes?)*

   #+BEGIN_SRC ipython
     write_pheno_file(
       bulk_log_cpm,
       gene_info,
       holdout=False,
       output_file='/scratch/midway2/aksarkar/singlecell/recall-bulk/bulk-log-cpm.bed')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[38]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="bulk-log-cpm.bed") :dir /scratch/midway2/aksarkar/singlecell/recall-bulk

   #+RESULTS:
   : Submitted batch job 44681764

   Ensure the dosage file follows the VCF standard. Add the prefix ~NA~ to sample IDs.

   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/reproduce-yang
     sbatch --partition=broadwl
     #!/bin/bash
     zcat YRI_SNPs_2_IPSC.txt.gen.gz | awk -vOFS='\t' 'BEGIN {print "##fileformat=VCFv4.2"; print "##FORMAT=<ID=DS,Number=1,Type=Float>"} NR == 1 {for (i = 10; i <= NF; i++) {$i = "NA"$i}} {print}' | bgzip >yri-dosages.vcf.gz
     tabix yri-dosages.vcf.gz
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 44546926

   Run ~qtltools~

   #+CALL: qtltools(pheno="bulk-log-cpm", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov log-cpm-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/recall-bulk

   #+RESULTS:
   : Submitted batch job 44681768

   Read the output. *Important: this loses 201 genes (is this a bug in
   ~qtltools~)?*

   #+BEGIN_SRC ipython
     bulk_cpm_qtls = read_qtltools_output('recall-bulk/bulk-log-cpm')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[137]:
   :END:

   Check the beta approximation.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/bulk-cpm-beta-approx.png
     plot_approx_permutation(bulk_cpm_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[40]:
   [[file:figure/qtl-mapping.org/bulk-cpm-beta-approx.png]]
   :END:

   Plot a QQ plot of adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/bulk-cpm-qq.png
     qqplot(bulk_cpm_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[138]:
   [[file:figure/qtl-mapping.org/bulk-cpm-qq.png]]
   :END:

   Take QTLs with \(\mathrm{FDR} < 0.1\).

   #+BEGIN_SRC ipython
     bulk_cpm_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[139]:
   : 1276
   :END:

** Recall bulk eQTLs from log TPM

   We [[file:kallisto.org][reprocessed the bulk RNA-Seq data]] using ~kallisto~. Read the TPM
   matrix.

   #+BEGIN_SRC ipython
     bulk_log_tpm = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/kallisto/bulk-ipsc-tpm.txt.gz', header=None, sep=' ')
     bulk_log_tpm = np.log(bulk_log_tpm.pivot(columns=0, index=1, values=2) + 1)
     bulk_log_tpm.index = [x.split('.')[0] for x in bulk_log_tpm.index]
     # Important: need to throw out all zero rows because they blow up
     # standardization
     bulk_log_tpm = (bulk_log_tpm[bulk_log_tpm.apply(lambda x: x.sum() > 0, axis=1)]
                     .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                     .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[140]:
   :END:

   To quantify how much power we expect to lose going from 58 to 49 individuals
   (in our scRNA-Seq data), perform QTL mapping on a random subset of 49
   individuals.

   #+BEGIN_SRC ipython
     np.random.seed(0)
     keep_inds = np.random.choice(bulk_log_tpm.columns, size=49, replace=False)
     bulk_log_tpm = bulk_log_tpm.filter(items=keep_inds, axis='columns')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[37]:
   :END:

   Check whether the false discovery rate is properly controlled by permuting
   the data.

   #+BEGIN_SRC ipython
     np.random.seed(0)
     permutation = bulk_log_tpm.columns.values
     np.random.shuffle(permutation)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[67]:
   :END:

   Get the TSS information. Use the annotation data (ENSEMBL 75) in this
   repository to be consistent with the single cell data.

   Write the phenotype matrix in ~qtltools~ format. *Important: this loses 1034
   genes*

   #+BEGIN_SRC ipython
     write_pheno_file(
       bulk_log_tpm,
       gene_info,
       holdout=False,
       output_file='/scratch/midway2/aksarkar/singlecell/recall-bulk/bulk-log-tpm.bed')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[141]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="bulk-log-tpm.bed") :dir /scratch/midway2/aksarkar/singlecell/recall-bulk

   #+RESULTS:
   : Submitted batch job 44686635

   Compute principal components.

   #+BEGIN_SRC ipython
    covars = pd.DataFrame(skd.PCA(n_components=6).fit(bulk_log_tpm).components_, columns=bulk_log_tpm.columns)
    covars.index.name = 'id'
    covars.to_csv('/scratch/midway2/aksarkar/singlecell/recall-bulk/log-tpm-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[142]:
   :END:

   Run ~qtltools~

   #+CALL: qtltools(pheno="bulk-log-tpm", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov log-tpm-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/recall-bulk

   #+RESULTS:
   : Submitted batch job 44686640

   Read the output. *Important: this loses 201 genes (is this a bug in
   ~qtltools~)?*

   #+BEGIN_SRC ipython
     bulk_tpm_qtls = read_qtltools_output('recall-bulk/bulk-log-tpm')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[143]:
   :END:

   Check the beta approximation to the permuted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/bulk-tpm-beta-approx.png
     plot_approx_permutation(bulk_tpm_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[144]:
   [[file:figure/qtl-mapping.org/bulk-tpm-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/bulk-log-tpm-qtl-qq.png
     qqplot(bulk_tpm_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[145]:
   [[file:figure/qtl-mapping.org/bulk-log-tpm-qtl-qq.png]]
   :END:

   Take QTLs with \(\mathrm{FDR} < 0.1\).

   #+BEGIN_SRC ipython
     bulk_tpm_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[146]:
   : 1020
   :END:

** Reprocess YRI dosages

   We have two individuals which weren't used in Banovich et al 2018, so we
   don't have their genotypes. Reprocess the IMPUTE2 output to get the correct
   dosage matrix.

   #+BEGIN_SRC sh :eval never
     rsync -nva -f '+ */' -f '+ *.impute2.gz' -f '+ YRI_samples.txt' -f '- *' ./ aksarkar@midway2.rcc.uchicago.edu:/scratch/midway2/aksarkar/singlecell/scqtl-mapping/
   #+END_SRC

   #+BEGIN_SRC ipython :eval never :tangle /scratch/midway2/aksarkar/singlecell/scqtl-mapping/reprocess-dosage.py
     import glob
     import gzip
     import numpy as np
     import pandas as pd
     import sqlite3

     def convert_impute2_vcf(file, mask, chrom, outfile, min_maf=0.05):
       for line in file:
         record = line.split()
         posterior = np.array([float(x) for x in record[5:]])
         dose = posterior.reshape(-1, 3).dot(np.arange(3))[mask]
         if min_maf <= dose.mean() / 2 <= 1 - min_maf:
           print(chrom, record[2], '{}.{}.{}'.format(record[1], chrom, record[2]),
                 record[3], record[4], '.', '.', '.', 'DS',
                 ,*['{:.3f}'.format(x) for x in dose], sep='\t', file=outfile)

     samples = pd.read_table('YRI_samples.txt', header=None, sep=' ')
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       keep = pd.read_sql('select chip_id from annotation group by chip_id having count(*) >= 50;', conn)
     mask = samples[0].isin(keep['chip_id']).values
     assert mask.sum() == 53
     with open('yri-120-dosages.vcf', 'w') as f:
       print('##fileformat=VCFv4.2', file=f)
       print('##FORMAT=<ID=DS,Number=1,Type=Float>', file=f)
       print('#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', *samples[0][mask], sep='\t', file=f)
       for c in range(1, 23):
         with gzip.open('chr{}.hg19.impute2.gz'.format(c), 'rt') as g:
           convert_impute2_vcf(g, mask, 'chr{}'.format(c), outfile=f)
   #+END_SRC


   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping
     sbatch --partition=mstephens
     #!/bin/bash
     source activate scqtl
     python reprocess-dosage.py
     bgzip yri-120-dosages.vcf
     tabix yri-120-dosages.vcf.gz
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 45277139

* Analysis using sample moments

  The most obvious way to estimate means/variances to use as quantitative
  phenotypes is to use the sample moments of per cell log CPM.

  Care has to be taken in handling zero-observations. Simply ignoring them
  leads to loss of power due to the pseudocount introduced in computing log
  CPM. To see this, fix one individual, one gene, and let \(r\) denote the
  observed count. Then,

  \[ \log\mathrm{CPM} \propto \ln(r + \epsilon) - \ln\mathrm{const} \]

  Let \(\mu = \mathbb{E}[r\,]\), \(\sigma^2 = \mathbb{V}[r\,]\), expand to
  second-order, then take expectations over cells:

  \[ \mathbb{E}[\,\ln (r + \epsilon)\,] \approx \ln(\mu + \epsilon) -
   \frac{\sigma^2}{(\mu + \epsilon)^2} \]

  \[ \mathbb{V}[\,\ln (r + \epsilon)\,] \approx \frac{2 \sigma^2}{(\mu +
   \epsilon)^2} - \frac{\sigma^4}{(\mu + \epsilon)^4} \]

** Call eQTLs from pooled scRNA-Seq

   Read the QC filters.

   #+NAME: qc-filters
   #+BEGIN_SRC ipython
     annotation = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-annotation.txt')
     keep_samples = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/quality-single-cells.txt', index_col=0, header=None)
     keep_genes = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/genes-pass-filter.txt', index_col=0, header=None)
     annotation = annotation.loc[keep_samples.values.ravel()]
     keep_inds = annotation.groupby('chip_id').apply(lambda x: len(x) >= 50)
   #+END_SRC

   #+RESULTS: qc-filters
   :RESULTS:
   # Out[162]:
   :END:

   Read and pool the UMI data.

   #+BEGIN_SRC ipython
     pooled_counts = pd.concat(
       [(chunk
         .filter(items=keep_genes[keep_genes.values].index, axis='index')
         # Important: this can't be done by filter because sample names are
         # different in the QC file
         .loc[:,keep_samples.values.ravel()]
         .groupby(annotation['chip_id'].values, axis=1)
         .agg(np.sum))
        for chunk in
        pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-counts.txt.gz',
                      chunksize=1000, index_col=0)])
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[163]:
   :END:

   Normalize the pooled counts.

   #+BEGIN_SRC ipython
     pooled_cpm = (cpm(pooled_counts).loc[:,keep_inds]
                   .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                   .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[164]:
   :END:

   Compute principal components and write out the covariate file.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=10).fit(pooled_cpm).components_, columns=pooled_cpm.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/pooled-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[165]:
   :END:

   Write out the phenotype file.

   #+BEGIN_SRC ipython
     write_pheno_file(pooled_cpm, gene_info, holdout=False, output_file='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/pooled.bed')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[166]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="pooled.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45395854

   Run ~qtltools~

   #+CALL: qtltools(pheno="pooled", geno="/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz", op="--cov pooled-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45395877

   Read the output. *Important: this loses 200 genes (is this a bug in
   ~qtltools~)?*

   #+BEGIN_SRC ipython
     pooled_qtls = read_qtltools_output('scqtl-mapping/pooled')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[167]:
   :END:

   Check the beta approximation.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/pooled-cpm-beta-approx.png
     plot_approx_permutation(pooled_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[168]:
   [[file:figure/qtl-mapping.org/pooled-cpm-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/pooled-qtl-qq.png
     qqplot(pooled_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[169]:
   [[file:figure/qtl-mapping.org/pooled-qtl-qq.png]]
   :END:

   Take QTLs with \(\mathrm{FDR} < 0.1\).

   #+BEGIN_SRC ipython
     pooled_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[170]:
   : 254
   :END:

** Call mean-QTLs

   Throw out individuals with fewer than 50 cells.

   #+CALL: qc-filters()

   #+RESULTS:
   :RESULTS:
   # Out[89]:
   :END:

   Read the count matrix.

   #+NAME: read-umi
   #+BEGIN_SRC ipython
     umi = pd.concat(
       [(chunk
         .filter(items=keep_genes[keep_genes.values].index, axis='index')
         # Important: this can't be done by filter because sample names are
         # different in the QC file
         .loc[:,keep_samples.values.ravel()])
        for chunk in
        pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-counts.txt.gz',
                      chunksize=1000, index_col=0)])
   #+END_SRC

   #+RESULTS: read-umi
   :RESULTS:
   # Out[90]:
   :END:

   We previously noted that 50 cells was sufficient to reliably estimate the
   mean of single cell data. Therefore, throw out zeros from the analysis and
   require that at least 50 samples have non-zero count.

   #+BEGIN_SRC ipython
     num_non_zero = umi.groupby(annotation['chip_id'].values, axis=1).agg(lambda x: (x > 0).values.sum(axis=1))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[105]:
   :END:

   Derive a cutoff for the number of individuals with at least 50 non-zero
   observations per gene.

   #+BEGIN_SRC ipython
     num_individuals_pass = (num_non_zero > 50).agg(np.sum, axis=1)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[106]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/num-individuals-pass.png
     plt.clf()
     n, b, _ = plt.hist(num_individuals_pass, color='k', bins=np.arange(0, 53, 2), histtype='step', cumulative=True, normed=True)
     plt.axhline(y=n[-2], c='r', ls=':', lw=1)
     plt.xlabel('Number of individuals with at least 50 non-zero observations')
     _ = plt.ylabel('Cumulative fraction of genes')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[128]:
   [[file:figure/qtl-mapping.org/num-individuals-pass.png]]
   :END:

   Compute the sample mean log CPM per individual, then normalize.

   #+BEGIN_SRC ipython
     sample_mean = (cpm(umi)
                    .mask(umi == 0)
                    .groupby(annotation['chip_id'].values, axis=1)
                    .agg(np.mean)
                    .loc[num_individuals_pass >= 50,keep_inds]
                    .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                    .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[134]:
   :END:

   Compute principal components and write out the covariate file.

   #+BEGIN_SRC ipython
    covars = pd.DataFrame(skd.PCA(n_components=10).fit(sample_mean).components_, columns=sample_mean.columns)
    covars.index.name = 'id'
    covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-mean-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[137]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(
       sample_mean,
       gene_info,
       output_file='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-mean.bed',
       holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[138]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="sample-mean.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45378606

   Run ~qtltools~.

   #+CALL: qtltools(pheno="sample-mean", geno="/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz", op="--cov sample-mean-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:

   Read the output.

   #+BEGIN_SRC ipython
     sample_mean_qtls = read_qtltools_output('scqtl-mapping/sample-mean')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[139]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-mean-qtl-beta-approx.png
     plot_approx_permutation(sample_mean_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[141]:
   [[file:figure/qtl-mapping.org/sample-mean-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-mean-qtl-qq.png
     qqplot(sample_mean_qtls)
   #+end_SRC

   #+RESULTS:
   :RESULTS:
   # Out[142]:
   [[file:figure/qtl-mapping.org/sample-mean-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
    sample_mean_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[140]:
   : 195
   :END:

** Call variance-QTLs

   Throw out individuals with fewer than 50 cells.

   #+CALL: qc-filters()

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   :END:

   Read the UMI matrix.

   #+CALL: read-umi()

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   :END:

   Compute the sample variance of log CPM per individual, then normalize.

   #+BEGIN_SRC ipython
     sample_var = (cpm(umi)
                   .mask(umi == 0)
                   .groupby(annotation['chip_id'].values, axis=1)
                   .agg(np.var)
                   .loc[num_individuals_pass >= 50,keep_inds]
                   .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                   .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[143]:
   :END:

   Compute principal components and write out the covariate file.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=2).fit(sample_var).components_, columns=sample_var.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-var-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[144]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(sample_var, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-var.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[145]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="sample-var.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45379136

   Run ~qtltools~.

   #+CALL: qtltools(pheno="sample-var", geno="/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz", op="--cov sample-var-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45379151

   Read the output.

   #+BEGIN_SRC ipython
     sample_var_qtls = read_qtltools_output('scqtl-mapping/sample-var')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[146]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-var-qtl-beta-approx.png
     plot_approx_permutation(sample_var_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[147]:
   [[file:figure/qtl-mapping.org/sample-var-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-var-qtl-qq.png
     qqplot(sample_var_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[148]:
   [[file:figure/qtl-mapping.org/sample-var-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     sample_var_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[149]:
   : 0
   :END:

** Call CV-QTLs

   Throw out individuals with fewer than 50 cells.

   #+CALL: qc-filters()

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   :END:

   Read the UMI matrix.

   #+CALL: read-umi()

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   :END:

   Compute the sample CV of log CPM per individual, then normalize.

   #+BEGIN_SRC ipython
     sample_cv = (cpm(umi)
                  .mask(umi == 0)
                  .groupby(annotation['chip_id'].values, axis=1)
                  .agg(lambda x: np.std(x, axis=1) / (np.mean(x, axis=1) + 1e-8))
                  .loc[num_individuals_pass >= 50,keep_inds]
                  .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                  .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[152]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(sample_cv, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-cv.bed', holdout=True)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[153]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="sample-cv.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45379460

   Run ~qtltools~.

   #+CALL: qtltools(pheno="sample-cv", geno="/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz", op="--window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45379490

   Read the output.

   #+BEGIN_SRC ipython
    sample_cv_qtls = read_qtltools_output('scqtl-mapping/sample-cv')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[154]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-cv-qtl-beta-approx.png
     plot_approx_permutation(sample_cv_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[155]:
   [[file:figure/qtl-mapping.org/sample-cv-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-cv-qtl-qq.png
    qqplot(sample_cv_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[156]:
   [[file:figure/qtl-mapping.org/sample-cv-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
    sample_cv_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[157]:
   : 0
   :END:

** Call Fano-QTLs

   Throw out individuals with fewer than 50 cells.

   #+CALL: qc-filters()

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   :END:

   Read the UMI matrix.

   #+CALL: read-umi()

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   :END:

   Fisher's index of dispersion is defined as \(V[x] / E[x]\). The Fano factor
   is Fisher's index of dispersion over a fixed window (in our case, the total
   number of reads).

   Compute the sample Fano factor of log CPM per individual, then normalize.

   #+BEGIN_SRC ipython
     sample_fano = (cpm(umi)
                    .mask(umi == 0)
                    .groupby(annotation['chip_id'].values, axis=1)
                    .agg(lambda x: np.var(x, axis=1) / (np.mean(x, axis=1)))
                    .loc[num_individuals_pass >= 50,keep_inds]
                    .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                    .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[158]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(sample_fano, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample_fano.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[159]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="sample_fano.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45379754

   Compute principal components and write out the covariate file.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=2).fit(sample_fano).components_, columns=sample_fano.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-fano-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[160]:
   :END:

   Run ~qtltools~.

   #+CALL: qtltools(pheno="sample_fano", geno="/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz", op="--cov sample-fano-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45379764

   Read the output.

   #+BEGIN_SRC ipython
     sample_fano_qtls = read_qtltools_output('scqtl-mapping/sample_fano')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[161]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-fano-qtl-beta-approx.png
     plot_approx_permutation(sample_fano_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[162]:
   [[file:figure/qtl-mapping.org/sample-fano-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-fano-qtl-qq.png
     qqplot(sample_fano_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[163]:
   [[file:figure/qtl-mapping.org/sample-fano-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     sample_fano_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[164]:
   : 0
   :END:

* Analysis using ZINB
** Call \mu-QTLs

   Throw out individuals with fewer than 50 cells.

   #+CALL: qc-filters()

   #+RESULTS:
   :RESULTS:
   # Out[63]:
   :END:

   Read the estimated parameters \(\log \mu_{ik}\). Exclude individuals with
   fewer than 50 cells.

   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       log_mu = (pd.read_sql(
         """select gene, ind, log_mu from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn)
                   .pivot(index='gene', columns='ind', values='log_mu'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[166]:
   :END:

   Normalize the mean matrix analagous to the bulk data. In our estimation
   procedure, we now return \(\ln\mu = -\infty\) for individuals with only zero
   observations. Clip this to \(\ln\epsilon\), where \(\epsilon\) is the
   smallest representable floating point number.

   #+BEGIN_SRC ipython
     log_mu = (np.clip(log_mu.loc[keep_genes.values.ravel()].dropna(), np.log(np.finfo(np.float).eps), 0)
               .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
               .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[167]:
   :END:

   Compute principal components of the mean matrix.

   #+BEGIN_SRC ipython
    covars = pd.DataFrame(skd.PCA(n_components=10).fit(log_mu).components_, columns=log_mu.columns)
    covars.index.name = 'id'
    covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/log_mu-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[168]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(log_mu, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/log_mu.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[169]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="log_mu.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45380264

   Run ~qtltools~.

   #+CALL: qtltools(pheno="log_mu", geno="/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz", op="--cov log_mu-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45380269

   Read the output.

   #+BEGIN_SRC ipython
     log_mu_qtls = read_qtltools_output('scqtl-mapping/log_mu')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[170]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/mu-qtl-beta-approx.png
     plot_approx_permutation(log_mu_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[171]:
   [[file:figure/qtl-mapping.org/mu-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/mu-qtl-qq.png
     qqplot(log_mu_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[172]:
   [[file:figure/qtl-mapping.org/mu-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     log_mu_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[173]:
   : 196
   :END:

** Call \phi-QTLs

   Read the estimated parameters. Exclude individuals with fewer than 50 cells.

   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       log_phi = (pd.read_sql(
         """select gene, ind, log_phi from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn)
                  .pivot(index='gene', columns='ind', values='log_phi'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[174]:
   :END:

   Normalize the dispersion matrix. Again, we have infinite values, but
   dispersions are not restricted to be in \([0, 1]\), so we have to change the
   clipping bounds.

   #+BEGIN_SRC ipython
     log_phi = np.clip(log_phi.loc[keep_genes.values.ravel()].dropna(), -300, 300).transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=1)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[175]:
   :END:

   Write out the phenotype file.

   #+BEGIN_SRC ipython
     write_pheno_file(log_phi, gene_info, holdout=False, output_file='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/log_phi.bed')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[176]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="log_phi.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45380395

   Run ~qtltools~.

   #+CALL: qtltools(pheno="log_phi", geno="/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz", op="--window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45380397

   Read the output.

   #+BEGIN_SRC ipython
    log_phi_qtls = read_qtltools_output('scqtl-mapping/log_phi')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[177]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/phi-qtl-beta-approx.png
    plot_approx_permutation(log_phi_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[178]:
   [[file:figure/qtl-mapping.org/phi-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/phi-qtl-qq.png
    qqplot(log_phi_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[179]:
   [[file:figure/qtl-mapping.org/phi-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     log_phi_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[180]:
   : 0
   :END:

** Call \pi-QTLs

   For each gene \(k\), fit a linear model:

   \[ \mathrm{logit}(\pi_k) = X\beta + \epsilon \]

   Read the estimated parameters. Exclude individuals with fewer than 50 cells.

   #+BEGIN_SRC ipython
    with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
      logodds = (pd.read_sql(
        """select gene, ind, logodds from params where ind in 
        (select chip_id from annotation group by chip_id 
        having count(distinct sample) >= 50);""", conn)
                 .pivot(index='gene', columns='ind', values='logodds'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[181]:
   :END:

   Normalize the log odds matrix.

   #+BEGIN_SRC ipython
     logodds = np.clip(logodds.loc[keep_genes.values.ravel()].dropna(), -300, 300)
     logodds = logodds.loc[(logodds.agg(np.std, axis=1) > 0).values]
     logodds = logodds.transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=1)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[182]:
   :END:

   Write out the phenotype file.

   #+BEGIN_SRC ipython
     write_pheno_file(logodds, gene_info, holdout=False, output_file='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/logodds.bed')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[183]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="logodds.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45380825

   Run ~qtltools~.

   #+CALL: qtltools(pheno="logodds", geno="/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz", op="--window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45380832

   Read the output.

   #+BEGIN_SRC ipython
     logodds_qtls = read_qtltools_output('scqtl-mapping/logodds')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[184]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/logodds-qtl-beta-approx.png
     plot_approx_permutation(logodds_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[185]:
   [[file:figure/qtl-mapping.org/logodds-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/logodds-qtl-qq.png
     qqplot(logodds_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[186]:
   [[file:figure/qtl-mapping.org/logodds-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     logodds_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[187]:
   : 0
   :END:

** Call mean-QTLs

   We have \(r_{ijk} \sim g_{ijk}(\cdot)\), where \(g\) is the ZINB density [[file:zinb.org][as
   previously defined]].

   Fixing individual \(i\), gene \(k\), we can estimate a
   zero-inflation--corrected mean as:

   \[ E[r_{ijk}] = R_{ijk} \mu_{ik} \]

   Read the estimated corrected means.

   #+NAME: read-mean
   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       mean = (pd.read_sql(
         """select gene, ind, mean from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn)
                  .pivot(index='gene', columns='ind', values='mean'))
   #+END_SRC

   #+RESULTS: read-mean
   :RESULTS:
   # Out[188]:
   :END:

   Normalize the mean matrix.

   #+NAME: normalize-mean
   #+BEGIN_SRC ipython
     mean = mean.loc[keep_genes.values.ravel()].transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=0)
   #+END_SRC

   #+RESULTS: normalize-mean
   :RESULTS:
   # Out[189]:
   :END:

   #+RESULTS:
   :RESULTS:
   # Out[208]:
   :END:

   Compute principal components of the mean matrix.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=10).fit(mean).components_, columns=mean.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/mean-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[190]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
    write_pheno_file(mean, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/mean.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[191]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="mean.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45381092

   Run ~qtltools~.

   #+CALL: qtltools(pheno="mean", geno="/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz", op="--cov mean-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45381098

   Read the output.

   #+BEGIN_SRC ipython
     mean_qtls = read_qtltools_output('scqtl-mapping/mean')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[192]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/mean-qtl-beta-approx.png
     plot_approx_permutation(mean_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[193]:
   [[file:figure/qtl-mapping.org/mean-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/mean-qtl-qq.png
    qqplot(mean_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[194]:
   [[file:figure/qtl-mapping.org/mean-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     mean_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[195]:
   : 208
   :END:

** Call variance-QTLs

   We have \(r_{ijk} \sim g_{ijk}(\cdot)\), where \(g\) is the ZINB density [[file:zinb.org][as
   previously defined]].

   Fixing individual \(i\), gene \(k\), we can estimate a
   zero-inflation--corrected variance as:

   \[ E[r_{ijk}] = R_{ijk} \mu_{ik} \]

   \[ V[r_{ijk}] = E[r_{ijk}] + \left(E[r_{ijk}]\right)^2 \phi_{ik} \]

   Read the estimated corrected variances.

   #+NAME: read-variance
   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       variance = (pd.read_sql(
         """select gene, ind, var from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn)
                  .pivot(index='gene', columns='ind', values='var'))
   #+END_SRC

   #+RESULTS: read-variance
   :RESULTS:
   # Out[196]:
   :END:

   Normalize the variance matrix.

   #+NAME: normalize-variance
   #+BEGIN_SRC ipython
     variance = variance.loc[keep_genes.values.ravel()].transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=0)
   #+END_SRC

   #+RESULTS: normalize-variance
   :RESULTS:
   # Out[197]:
   :END:

   #+RESULTS:
   :RESULTS:
   # Out[48]:
   :END:

   Compute principal components of the variance matrix.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=2).fit(variance).components_, columns=variance.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/variance-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[198]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~.

   #+BEGIN_SRC ipython
     write_pheno_file(variance, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/variance.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[199]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="variance.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45381211

   Run ~qtltools~.

   #+CALL: qtltools(pheno="variance", geno="/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz", op="--cov variance-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45381214

   Read the output.

   #+BEGIN_SRC ipython
     variance_qtls = read_qtltools_output('scqtl-mapping/variance')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[200]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/variance-qtl-beta-approx.png
     plot_approx_permutation(variance_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[201]:
   [[file:figure/qtl-mapping.org/variance-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/variance-qtl-qq.png
     qqplot(variance_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[202]:
   [[file:figure/qtl-mapping.org/variance-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     variance_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[203]:
   : 100
   :END:

** Call CV-QTLs

   Estimate the coefficient of variation using the corrected moments.

   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       params = (pd.read_sql(
         """select gene, ind, mean, var from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn))
       params['cv'] = np.sqrt(params['var']) / (params['mean'] + 1e-8)
       cv = params.pivot(index='gene', columns='ind', values='cv')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[204]:
   :END:

   Normalize the CV matrix.

   #+BEGIN_SRC ipython
     cv = cv.loc[keep_genes.values.ravel()].transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=0)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[205]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(cv, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/cv.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[206]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="cv.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45381353

   Run ~qtltools~.

   #+CALL: qtltools(pheno="cv", geno="/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz", op="--window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45381354

   Read the output.

   #+BEGIN_SRC ipython
     cv_qtls = read_qtltools_output('scqtl-mapping/cv')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[207]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/cv-qtl-beta-approx.png
     plot_approx_permutation(cv_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[208]:
   [[file:figure/qtl-mapping.org/cv-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/cv-qtl-qq.png
     qqplot(cv_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[209]:
   [[file:figure/qtl-mapping.org/cv-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     cv_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[210]:
   : 4
   :END:

** Call Fano-QTLs

   Estimate the coefficient of variation using the corrected moments.

   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       params = (pd.read_sql(
         """select gene, ind, mean, var from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn))
       params['fano'] = params['var'] / (params['mean'] + 1e-8)
       fano = params.pivot(index='gene', columns='ind', values='fano')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[211]:
   :END:

   Normalize the Fano matrix.

   #+BEGIN_SRC ipython
     fano = fano.loc[keep_genes.values.ravel()].transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=0)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[212]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(fano, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/fano.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[213]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="fano.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45381553

   Run ~qtltools~.

   #+CALL: qtltools(pheno="fano", geno="/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz", op="--window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45381664

   Read the output.

   #+BEGIN_SRC ipython
     fano_qtls = read_qtltools_output('scqtl-mapping/fano')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[215]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/fano-qtl-beta-approx.png
     plot_approx_permutation(fano_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[216]:
   [[file:figure/qtl-mapping.org/fano-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/fano-qtl-qq.png
     qqplot(fano_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[217]:
   [[file:figure/qtl-mapping.org/fano-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     fano_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[218]:
   : 10
   :END:

** Call dispersion QTLs via departure from genome-wide dispersion

   We previously showed that most genes have equal over-dispersion across the
   genome. Therefore, we define a new phenotype as the difference from this
   theoretical relationship and map QTLs for it.

   #+CALL: qc-filters()

   #+RESULTS:
   :RESULTS:
   # Out[25]:
   :END:

   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       params = (pd.read_sql(
         """select gene, ind, mean, var from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn))
       params['resid'] = params['var'] / (params['mean'] + 1e-8) - 1 - params['mean'] * 0.24
       resid = params.pivot(index='gene', columns='ind', values='resid')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[219]:
   :END:

   Normalize the resid matrix.

   #+BEGIN_SRC ipython
     resid = resid.loc[keep_genes.values.ravel()].transform(lambda x: (x - x.mean()) / x.std(), axis=1)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[220]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(resid, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/resid.bed', holdout=True)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[221]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="resid.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45381856

   Run ~qtltools~.

   #+CALL: qtltools(pheno="resid", geno="/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz", op="--window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45381864

   Read the output.

   #+BEGIN_SRC ipython
     resid_qtls = read_qtltools_output('scqtl-mapping/resid')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[222]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/resid-qtl-beta-approx.png
     plot_approx_permutation(resid_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[223]:
   [[file:figure/qtl-mapping.org/resid-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/resid-qtl-qq.png
     qqplot(resid_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[224]:
   [[file:figure/qtl-mapping.org/resid-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     resid_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[225]:
   : 0
   :END:

* Write out the QTLs

  #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping
    sbatch --partition=broadwl
    #!/bin/bash
    cat >.rsync-filter <<EOF
    + */
    + *.bed.gz
    + *.txt.gz
    + *covars*
    - *
    EOF
    function z { test $1-qtl.1.txt -nt $1.txt.gz && cat $1-qtl.*.txt | awk 'BEGIN {print "gene", "chr", "start", "end", "strand", "num_vars", "distance", "id", "var_chr", "var_start", "var_end", "df", "dummy", "a", "b", "p_nominal", "beta", "p_empirical", "p_beta"} {print}' | gzip >$1.txt.gz; }
    export -f z
    parallel -j1 z ::: cv fano log_mu logodds log_phi mean pooled resid sample-cv sample-mean sample-var sample_fano variance
    rsync -FFau . /project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-mapping/
  #+END_SRC

  #+RESULTS:
  : Submitted batch job 45395999

* QTL overlap
** Replication rates

  Read the QTLs and normalized expression matrices.

  #+BEGIN_SRC ipython
    prefix = '/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-mapping/'
    qtls = {pheno: (pd.read_table('{}/{}.txt.gz'.format(prefix, pheno), sep=' '),
                    pd.read_table('{}/{}.bed.gz'.format(prefix, pheno)).set_index('pid').filter(like='NA', axis='columns'))
            for pheno in ['bulk', 'pooled', 'log_mu', 'log_phi', 'mean', 'variance', 'fano']}
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[171]:
  :END:

  The bulk QTL gene names need to be munged.

  #+BEGIN_SRC ipython
    qtls['bulk'][0]['gene'] = qtls['bulk'][0]['gene'].apply(lambda x: x.split('.')[0])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[172]:
  :END:

  Compute the gene-level FDR filter.

  #+BEGIN_SRC ipython
    for k in qtls:
      qtls[k][0]['fdr_pass'] = bh(qtls[k][0]['p_beta']) < 0.1
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[173]:
  :END:

  Read covariates for mean phenotypes.

  #+BEGIN_SRC ipython
    base = pathlib.Path('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-mapping/')
    covars = [pd.read_table(base / '{}-covars.txt'.format(f), sep='\s+', engine='python', index_col=0)
              for f in ('bulk', 'pooled', 'log_mu', 'mean')]
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[174]:
  :END:

  Estimate replication rates for mean QTLs.

  #+BEGIN_SRC ipython
    pd.options.display.float_format = '{:.3g}'.format
    pairwise_replication(qtls, phenos=['bulk', 'pooled', 'log_mu', 'mean'], ticks=['Bulk', 'Pooled', '$\log(\mu)$', 'ZI mean'], covars=covars)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[180]:
  #+BEGIN_EXAMPLE
    Bulk  Pooled  $\log(\mu)$  ZI mean
    Bulk          100    82.6         80.6     80.7
    Pooled        100     100         98.8     98.8
    $\log(\mu)$   100    99.5          100      100
    ZI mean       100    99.5          100      100
  #+END_EXAMPLE
  :END:

  Estimate the rate at which variance QTLs replicate as mean QTLs (and vice versa).

  #+BEGIN_SRC ipython
    pairwise_replication(qtls,
                         phenos=['bulk', 'pooled', 'log_mu', 'mean', 'log_phi', 'variance', 'fano'],
                         ticks=['Bulk', 'Pooled', '$\log(\mu)$', 'ZI mean', '$\log(\phi)$', 'ZI variance', 'ZI Fano'],
                         covars=covars + [None for _ in range(3)])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[181]:
  #+BEGIN_EXAMPLE
    Bulk  Pooled  $\log(\mu)$  ZI mean  $\log(\phi)$  ZI variance  \
    Bulk           100    82.6         80.6     80.7          39.6         77.6
    Pooled         100     100         98.8     98.8          47.2         98.4
    $\log(\mu)$    100    99.5          100      100          41.3         99.5
    ZI mean        100    99.5          100      100          40.4         99.5
    $\log(\phi)$   100     100          100      100           100          100
    ZI variance    100     100          100      100            77          100
    ZI Fano        100     100          100      100           100          100

    ZI Fano
    Bulk             57.1
    Pooled             87
    $\log(\mu)$      86.2
    ZI mean          84.6
    $\log(\phi)$      100
    ZI variance       100
    ZI Fano           100
  #+END_EXAMPLE
  :END:

** Relationship of \(p\)-values, effect sizes, and expression levels

   Compute relative abundance per individual.

   #+BEGIN_SRC ipython
    with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
      abundance = (pd.read_sql(
        """select gene, ind, log_mu from params where ind in 
        (select chip_id from annotation group by chip_id 
        having count(distinct sample) >= 50);""", conn)
                  .pivot(index='gene', columns='ind', values='log_mu'))
    abundance -= abundance.agg(sp.logsumexp)
    abundance /= np.log(2)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[94]:
   :END:

   Investigate whether variance QTL \(p\)-values are correlated with relative
   abundance.

   #+BEGIN_SRC ipython
    variance_qtls = qtls['variance'][0]
    thresh_pass = variance_qtls['p_beta'] < 1e-2
    var_qtl_abundance, var_qtl_stats = abundance.align(variance_qtls[thresh_pass].set_index('gene'), axis='index', join='inner')
    fdr_pass = var_qtl_stats['fdr_pass']
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[95]:
   :END:

   Count how many variance QTLs have \(p < 10^{-2}\)

   #+BEGIN_SRC ipython
    thresh_pass.sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[96]:
   : 258
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/var-qtl-vs-log-mu.png
    plt.clf()
    plt.errorbar(x=var_qtl_abundance.mean(axis=1), y=-np.log10(var_qtl_stats['p_beta']), xerr=var_qtl_abundance.std(axis=1), fmt='none', label=None, lw=1, ecolor='.8', zorder=-1)
    plt.scatter(x=var_qtl_abundance[fdr_pass].mean(axis=1), y=-np.log10(var_qtl_stats[fdr_pass]['p_beta']), c='r', s=4, label='FDR 10%')
    plt.scatter(x=var_qtl_abundance[~fdr_pass].mean(axis=1), y=-np.log10(var_qtl_stats[~fdr_pass]['p_beta']), c='k', s=4, label='p < 0.01')
    plt.legend(loc='upper left', frameon=False)
    plt.xlabel('$\log_2(\mathrm{relative\ abundance})$')
    _ = plt.ylabel('Variance QTL $-\log_{10}(p)$')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[97]:
   [[file:figure/qtl-mapping.org/var-qtl-vs-log-mu.png]]
   :END:

   Make sure our effect sizes match ~qtltools~.

   #+BEGIN_SRC ipython
    variance = qtls['variance'][1]
    Xv, Yv = extract_qtl_gene_pair(variance_qtls[thresh_pass], variance, dosages='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz')
    Cv = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-mapping/variance-covars.txt', index_col=0)
    Cv = Cv.align(Xv, axis='columns', join='inner')[0]
    my_var_qtl_stats = replication_tests(Xv, Yv, Cv)
    my_var_qtl_stats.merge(variance_qtls, on='gene').apply(lambda x: abs(x['beta_x'] - x['beta_y']), axis=1).describe()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[103]:
   #+BEGIN_EXAMPLE
     count       258
     mean     0.0849
     std        0.16
     min     0.00197
     25%      0.0208
     50%      0.0493
     75%         0.1
     max         2.2
     dtype: float64
   #+END_EXAMPLE
   :END:

   Look at the gene with max difference in estimated effect size.

   #+BEGIN_SRC ipython
    my_var_qtl_stats.iloc[my_var_qtl_stats.merge(variance_qtls, on='gene').apply(lambda x: abs(x['beta_x'] - x['beta_y']), axis=1).idxmax()]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[104]:
   #+BEGIN_EXAMPLE
     beta             -0.347
     gene    ENSG00000138587
     p                 0.109
     se                0.217
     Name: 90, dtype: object
   #+END_EXAMPLE
   :END:

   Estimate standard errors via the bootstrap.

   #+BEGIN_SRC ipython
    var_qtl_stats['bootstrap_se'] = bootstrap_se(Xv, Yv, Cv)
    var_qtl_stats['se'] = my_var_qtl_stats.set_index('gene')['se']
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[105]:
   :END:

   Investigate whether analytic SEs are reasonable:

   #+BEGIN_SRC ipython
    var_qtl_stats['se'].describe()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[106]:
   #+BEGIN_EXAMPLE
     count       258
     mean     0.0467
     std      0.0328
     min     0.00963
     25%      0.0252
     50%      0.0368
     75%      0.0552
     max       0.217
     Name: se, dtype: float64
   #+END_EXAMPLE
   :END:
  
   #+BEGIN_SRC ipython
    var_qtl_stats['bootstrap_se'].describe()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[107]:
   #+BEGIN_EXAMPLE
     count      258
     mean     0.209
     std     0.0728
     min      0.109
     25%      0.159
     50%      0.193
     75%      0.237
     max      0.634
     Name: bootstrap_se, dtype: float64
   #+END_EXAMPLE
   :END:

   Plot analytic SEs against bootstrap SEs.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/var-qtl-se.png
    plt.clf()
    plt.gcf().set_size_inches(4, 4)
    plt.scatter(var_qtl_stats['se'], var_qtl_stats['bootstrap_se'], s=1, c='k')
    plt.plot([0, 1], [0, 1], c='r', ls=':', lw=1)
    plt.xlim([0, 1])
    plt.ylim([0, 1])
    plt.xlabel('Analytic SE')
    _ = plt.ylabel('Bootstrap SE')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[109]:
   [[file:figure/qtl-mapping.org/var-qtl-se.png]]
   :END:

   Compute \(z\)-scores using the bootstrap SEs.

   #+BEGIN_SRC ipython
    var_qtl_stats['z'] = var_qtl_stats['beta'] / var_qtl_stats['bootstrap_se']
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[110]:
   :END:

   Compute a \(z\)-score from the estimated effect size and the \(p\)-value.

   #+BEGIN_SRC ipython
    var_qtl_stats['isf_z'] = np.sign(var_qtl_stats['beta']) * np.sqrt(st.chi2(1).isf(var_qtl_stats['p_nominal']))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[125]:
   :END:

   Plot bootstrap \(z\)-scores against inverse-transformed \(z\)-scores.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/bootstrap-z-vs-nominal-p-inverse-cdf.png
    plt.clf()
    plt.gcf().set_size_inches(4, 4)
    plt.scatter(var_qtl_stats['z'], var_qtl_stats['isf_z'], s=3, c='k')
    plt.axhline(y=0, c='k', lw=1)
    plt.axvline(x=0, c='k', lw=1)
    plt.plot([-15, 15], [-15, 15], c='r', ls=':', lw=1)
    plt.xlim([-15, 15])
    plt.ylim([-15, 15])
    plt.xlabel('Bootstrap $z$-score')
    _ = plt.ylabel('Inverse CDF $z$-score')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[132]:
   [[file:figure/qtl-mapping.org/bootstrap-z-vs-nominal-p-inverse-cdf.png]]
   :END:

   Investigate whether \(z\)-scores based on bootstrap SEs agree with
   permutation \(p\)-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/var-qtl-z.png
    plt.clf()
    plt.scatter(-np.log10(var_qtl_stats[fdr_pass]['p_beta']), var_qtl_stats[fdr_pass]['z'], c='r', label='FDR 10%', s=4)
    plt.scatter(-np.log10(var_qtl_stats[~fdr_pass]['p_beta']), var_qtl_stats[~fdr_pass]['z'], c='k', label='p < 0.01', s=4)
    plt.xlabel('Variance QTL $-\log_{10}(p)$')
    plt.ylabel('Variance QTL $z$-score')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[133]:
   : Text(0,0.5,'Variance QTL $z$-score')
   [[file:figure/qtl-mapping.org/var-qtl-z.png]]
   :END:

   Investigate whether variance QTL \(z\)-scores are correlated with relative
   abundance.

   #+BEGIN_SRC ipython
    var_qtl_abundance = var_qtl_abundance.align(var_qtl_stats, axis='index', join='inner')[0]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[134]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/var-qtl-z-vs-log-mu.png
    plt.clf()
    plt.errorbar(x=var_qtl_abundance.mean(axis=1), y=var_qtl_stats['z'], xerr=var_qtl_abundance.std(axis=1), fmt='none', label=None, lw=1, ecolor='.8', zorder=1)
    plt.scatter(x=var_qtl_abundance[fdr_pass].mean(axis=1), y=var_qtl_stats[fdr_pass]['z'], c='r', s=2, label='FDR 10%', zorder=2)
    plt.scatter(x=var_qtl_abundance[~fdr_pass].mean(axis=1), y=var_qtl_stats[~fdr_pass]['z'], c='k', s=2, label='p < 0.01', zorder=2)
    plt.legend(frameon=False)
    plt.axhline(y=0, c='k')
    plt.xlabel('$\log_2(\mathrm{relative\ abundance})$')
    _ = plt.ylabel('Variance QTL $z$-score')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[135]:
   [[file:figure/qtl-mapping.org/var-qtl-z-vs-log-mu.png]]
   :END:

   Investigate whether variance QTL \(z\)-scores are correlated with pooled QTL
   \(z\)-scores.

   #+BEGIN_SRC ipython
    Xm, Ym = extract_qtl_gene_pair(variance_qtls[thresh_pass], qtls['pooled'][1], dosages='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz')
    Cm = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-mapping/pooled-covars.txt')
    Cm = Cm.align(Xm, axis='columns', join='inner')[0]
    var_qtl_stats['mean_beta'] = replication_tests(Xm, Ym, Cm).set_index('gene')['beta']
    var_qtl_stats['mean_z'] = var_qtl_stats['mean_beta'] / bootstrap_se(Xm, Ym, Cm)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[182]:
   :END:

   Plot variance QTL \(z\)-scores against pooled QTL \(z\)-scores.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/var-qtl-vs-mean-qtl.png
     lim = [-12, 12]
     plt.clf()
     plt.gcf().set_size_inches(6, 6)
     plt.plot(lim, lim, c='r', ls=':', lw=1)
     plt.scatter(var_qtl_stats[fdr_pass]['z'], var_qtl_stats[fdr_pass]['mean_z'], c='r', s=3, label='FDR 10%')
     plt.scatter(var_qtl_stats[~fdr_pass]['z'], var_qtl_stats[~fdr_pass]['mean_z'], c='k', s=3, label='Permuted p < 0.01')
     plt.legend()
     plt.axhline(y=0, c='k', lw=1)
     plt.axvline(x=0, c='k', lw=1)
     plt.xlim(lim)
     plt.ylim(lim)
     plt.title('Variance-effect SNP-gene pairs')
     plt.xlabel('Variance QTL $z$-score')
     _ = plt.ylabel('Pooled QTL $z$-score')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[183]:
   [[file:figure/qtl-mapping.org/var-qtl-vs-mean-qtl.png]]
   :END:

   Compute the same in the other direction.

   #+BEGIN_SRC ipython 
    mean_qtl_stats = qtls['pooled'][0]
    mean_qtl_stats = mean_qtl_stats[mean_qtl_stats['fdr_pass']].copy()
    X, Y = extract_qtl_gene_pair(mean_qtl_stats, qtls['pooled'][1], dosages='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz')
    mean_snp_mean_z = mean_qtl_stats.set_index('gene')['beta'] / bootstrap_se(X, Y, Cm)
    X, Y = extract_qtl_gene_pair(mean_qtl_stats, qtls['variance'][1], dosages='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz')
    mean_snp_var_z = replication_tests(X, Y, Cv).set_index('gene')['beta'] / bootstrap_se(X, Y, Cv)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[248]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/mean-qtl-vs-var-qtl.png
     lim = [-12, 12]
     plt.clf()
     plt.gcf().set_size_inches(6, 6)
     plt.plot(lim, lim, c='r', ls=':', lw=1)
     plt.scatter(mean_snp_mean_z, mean_snp_var_z, c='k', s=3, label='FDR 10%')
     plt.axhline(y=0, c='k', lw=1)
     plt.axvline(x=0, c='k', lw=1)
     plt.xlim(lim)
     plt.ylim(lim)
     plt.title('Mean-effect SNP-gene pairs')
     plt.xlabel('Variance QTL $z$-score')
     _ = plt.ylabel('Pooled QTL $z$-score')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[249]:
   [[file:figure/qtl-mapping.org/mean-qtl-vs-var-qtl.png]]
   :END:

** Predicting mean QTLs from variance QTLs

   As we change the threshold for calling mean (variance) QTLs, track the
   precision and recall of variance (mean) QTLs.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/var-qtl-mean-qtl-prc.png
     plt.clf()
     plt.gcf().set_size_inches(4, 4)
     Y, P = qtls['pooled'][0]['fdr_pass'].align(qtls['variance'][0]['p_beta'].dropna(), join='inner')
     p, r, _ = sklearn.metrics.precision_recall_curve(Y.astype(int), -np.log(P))
     plt.plot(r[::10], p[::10], lw=1, c='k', label='Variance')
     Y, P = qtls['variance'][0]['fdr_pass'].align(qtls['pooled'][0]['p_beta'].dropna(), join='inner')
     p, r, _ = sklearn.metrics.precision_recall_curve(Y.astype(int), -np.log(P))
     plt.plot(r[::10], p[::10], lw=1, c='r', label='Mean')
     plt.legend()
     plt.xlabel('Recall of QTLs at FDR 10%')
     _ = plt.ylabel('Precision of QTLs at FDR 10%')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[256]:
   [[file:figure/qtl-mapping.org/var-qtl-mean-qtl-prc.png]]
   :END:

   Track sensitivity and specificity of mean QTLs.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/var-qtl-mean-qtl-roc.png
     plt.clf()
     plt.gcf().set_size_inches(4, 4)
     Y, P = qtls['pooled'][0]['fdr_pass'].align(qtls['variance'][0]['p_beta'].dropna(), join='inner')
     fpr, tpr, _ = sklearn.metrics.roc_curve(Y.astype(int), -np.log(P))
     plt.plot(fpr[::10], tpr[::10], lw=1, c='k', label='Variance')
     Y, P = qtls['variance'][0]['fdr_pass'].align(qtls['pooled'][0]['p_beta'].dropna(), join='inner')
     fpr, tpr, _ = sklearn.metrics.roc_curve(Y.astype(int), -np.log(P))
     plt.plot(fpr[::10], tpr[::10], lw=1, c='r', label='Mean')
     plt.legend()
     plt.xlabel('False positive rate of QTLs at FDR 10%')
     _ = plt.ylabel('True positive rate of QTLs at FDR 10%')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[258]:
   [[file:figure/qtl-mapping.org/var-qtl-mean-qtl-roc.png]]
   :END:

** Multivariate adaptive shrinkage

   Write out a subset of the phenotype matrix to get SNP-level summary stats for
   ~mash~.

   #+BEGIN_SRC ipython
     write_pheno_file(qtls['variance'][1].filter(items=qtls['variance'][0][thresh_pass]['gene'], axis='index'),
                      gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/variance-fdr-pass.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[264]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="variance-fdr-pass.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45396919

   Run the nominal pass.

   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping :eval never-export 
    sbatch --partition=broadwl --mem=8G --wait
    #!/bin/bash
    source activate scqtl
    qtltools cis --vcf /scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz --bed variance-fdr-pass.bed.gz --cov variance-covars.txt --window 100000 --nominal 1 --out variance-fdr-pass-nominal.txt
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 45396920

   Compute \(\hat\beta\) and bootstrap SE ourselves to check whether we can
   simply inverse CDF transform from the nominal \(p\)-values.

   #+BEGIN_SRC ipython
    test_var_qtl_stats = estimate_beta_se(Yv.head(n=1), '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz', gene_info, Cv)
    test_var_qtl_stats['z'] = test_var_qtl_stats['beta'] / test_var_qtl_stats['se']
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[265]:
   :END:

   Read the results.

   #+BEGIN_SRC ipython
    nominal_var_qtl_stats = read_nominal_pass('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/variance-fdr-pass-nominal.txt')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[65]:
   :END:

   Check our \(z\)-scores against inverse CDF-derived \(z\)-scores.

   #+BEGIN_SRC ipython
    M = test_var_qtl_stats.merge(nominal_var_qtl_stats, left_on=['gene', 'snp'], right_on=['gene', 'id'])
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[267]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/bootstrap-z-vs-nominal-p-inverse-cdf.png
    plt.clf()
    plt.gcf().set_size_inches(4, 4)
    lim = [-6, 6]
    plt.scatter(M['z_x'], M['z_y'], c='k', s=3)
    plt.axhline(y=0, c='k', lw=1)
    plt.axvline(x=0, c='k', lw=1)
    plt.plot(lim, lim, c='r', ls=':', lw=1)
    plt.xlim(lim)
    plt.ylim(lim)
    plt.xlabel('Bootstrap $z$ scores')
    _ = plt.ylabel('Inverse CDF $z$ scores')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[268]:
   [[file:figure/qtl-mapping.org/bootstrap-z-vs-nominal-p-inverse-cdf.png]]
   :END:

   Subset the pooled expression matrix at the variance QTL genes.

   #+BEGIN_SRC ipython
    write_pheno_file(qtls['pooled'][1].filter(items=qtls['variance'][0][thresh_pass]['gene'], axis='index'),
                     gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/pooled-fdr-pass.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[269]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="pooled-fdr-pass.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45397009

   Run the nominal pass.

   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping :eval never-export 
    sbatch --partition=broadwl --mem=4G --wait
    #!/bin/bash
    source activate scqtl
    qtltools cis --vcf /scratch/midway2/aksarkar/singlecell/scqtl-mapping/yri-120-dosages.vcf.gz --bed pooled-fdr-pass.bed.gz --cov pooled-covars.txt --window 100000 --nominal 1 --out pooled-fdr-pass-nominal.txt
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 45397011

   Read the results

   #+BEGIN_SRC ipython
     nominal_pooled_qtl_stats = read_nominal_pass('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/pooled-fdr-pass-nominal.txt')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[66]:
   :END:

   Prepare the summary statistics for ~mash~ EB estimation.

   #+BEGIN_SRC ipython
     Z = nominal_var_qtl_stats.merge(nominal_pooled_qtl_stats, on=['gene', 'id']).set_index(['gene', 'id'])[['z_x', 'z_y']]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[195]:
   :END:

   Run two-condition ~mash~.

   #+BEGIN_SRC ipython
     data = mashr.mash_set_data(numpy2ri(Z_sub.values), numpy2ri(np.ones(Z_sub.shape)))
     V = mashr.estimate_null_correlation(data)
     data = mashr.mash_set_data(numpy2ri(Z_sub.values), numpy2ri(np.ones(Z_sub.shape)), V=V)
     U = mashr.cov_canonical(data)
     mash_result = mashr.mash(data, U, verbose=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[196]:
   :END:

   Write out the intermediate representation of the mash result.

   #+BEGIN_SRC ipython
     with open('mash-result.pkl', 'wb') as f:
       pickle.dump(mash_result, f)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[197]:
   :END:

   Read the intermediate representation.

   #+BEGIN_SRC ipython
     with open('mash-result.pkl', 'rb') as f:
       mash_result = pickle.load(f)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[2]:
   :END:

   Recover the estimated mixture weights.

   #+BEGIN_SRC ipython
     {k: v for k, v in zip(['pointmass'] + list(U.names),
                           np.array(mashr.get_estimated_pi(mash_result)))}
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[198]:
   #+BEGIN_EXAMPLE
     {'equal_effects': 0.6304740345396695,
     'identity': 3.222654477200791e-07,
     'pointmass': 0.2799479785087344,
     'simple_het_1': 3.3854982953530273e-07,
     'simple_het_2': 3.6256921592961205e-07,
     'simple_het_3': 0.08957557566393076,
     'singletons_1': 1.10893521460435e-06,
     'singletons_2': 2.7896795759335475e-07}
   #+END_EXAMPLE
   :END:

   Recover the estimated sharing of effects.

   #+BEGIN_SRC ipython
     np.array(mashr.get_pairwise_sharing(mash_result))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[203]:
   #+BEGIN_EXAMPLE
     array([[1.        , 0.96786156],
     [0.96786156, 1.        ]])
   #+END_EXAMPLE
   :END:
