#+TITLE: QTL mapping pipeline
#+SETUPFILE: setup.org

* Introduction

  We take a modular approach to call QTLs:

  1. Estimate a mean and a dispersion for each individual
  2. Treat the mean/dispersion as continuous phenotypes and perform QTL mapping

  Here, we solve (2).

  1. [[*Reproduce bulk eQTL calls][We reproduce eQTLs]] called on the bulk RNA-Seq
  2. [[*Analysis using sample moments][We call mean/variance/CV/Fano QTLs]] using sample moments
  3. [[*Analysis using ZINB][We call mean/variance/CV/Fano QTLs]] using ZINB parameters
  4. [[*QTL overlap][We test replication/overlap]] between different QTL calls

* Setup                                                            :noexport:

  #+BEGIN_SRC emacs-lisp
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(memory="16G", venv="scqtl") :dir /scratch/midway2/aksarkar/singlecell

  #+RESULTS:
  : Submitted batch job 45268702

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])

    import colorcet
    import gzip
    import matplotlib.pyplot as plt
    import numpy as np
    import os.path
    import pandas as pd
    import rpy2.robjects.packages
    import rpy2.robjects.pandas2ri
    import rpy2.robjects.numpy2ri
    import scipy.special as sp
    import scipy.stats as st
    import sklearn.decomposition as skd
    import sqlite3
    import tabix

    ashr = rpy2.robjects.packages.importr('ashr')
    edger = rpy2.robjects.packages.importr('edgeR')
    mashr = rpy2.robjects.packages.importr('mashr')

    pandas2ri = rpy2.robjects.pandas2ri
    numpy2ri = rpy2.robjects.numpy2ri.numpy2ri
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[1]:
  :END:

* Implementation

  #+NAME: r-wrappers
  #+BEGIN_SRC ipython
    def cpm(x):
      return pd.DataFrame(pandas2ri.ri2py(edger.cpm(numpy2ri(x.values), log=True)),
                          columns=x.columns,
                          index=x.index)

    def qqnorm(x):
      """Wrap around R qqnorm"""
      return np.asarray(rpy2.robjects.r['qqnorm'](numpy2ri(x))[0])

    def bh(x):
      """Wrap around p.adjust(..., method='fdr')"""
      return np.asarray(rpy2.robjects.r['p.adjust'](numpy2ri(x), method='fdr'))
  #+END_SRC

  #+RESULTS: r-wrappers
  :RESULTS:
  # Out[2]:
  :END:

  #+NAME: get-gene-info
  #+BEGIN_SRC ipython
    gene_info = (pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-genes.txt.gz')
                 .set_index('gene')
                 .query('source == "H. sapiens"')
                 .query('chr != "hsX"')
                 .query('chr != "hsY"')
                 .query('chr != "hsMT"'))
  #+END_SRC

  #+RESULTS: get-gene-info
  :RESULTS:
  # Out[3]:
  :END:

  #+RESULTS:
  :RESULTS:
  # Out[40]:
  :END:

  #+NAME: write-gene-info
  #+BEGIN_SRC ipython
    with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
      gene_info.to_sql('gene_info', conn, index=True, if_exists='replace')
  #+END_SRC

  #+RESULTS: write-gene-info
  :RESULTS:
  # Out[4]:
  :END:

  #+RESULTS:
  :RESULTS:
  # Out[45]:
  :END:

  #+NAME: write-pheno-def
  #+BEGIN_SRC ipython
    def qtltools_format(row, prefix='chr'):
      row['#Chr'] = '{}{}'.format(prefix, row['chr'][2:])
      row['gid'] = row.name
      row['pid'] = row.name
      # Important: qtltools expects TSS start/end
      if row['strand'] == '+':
        row['end'] = row['start']
      else:
        row['start'] = row['end']
      return row.loc[['#Chr', 'start', 'end', 'pid', 'gid', 'strand']]

    def write_pheno_file(pheno, gene_info, output_file, holdout=True, **kwargs):
      if holdout:
        genes = gene_info.loc[gene_info.apply(lambda x: bool(int(x['chr'][2:]) % 2), axis=1)]
      else:
        genes = gene_info
      (genes
       .apply(qtltools_format, **kwargs, axis=1)
       .merge(pheno, left_index=True, right_index=True)
       .to_csv(output_file,
               sep='\t',
               header=True,
               index=False,
               index_label=False))
  #+END_SRC

  #+RESULTS: write-pheno-def
  :RESULTS:
  # Out[4]:
  :END:

  #+NAME: tabix
  #+BEGIN_SRC sh :var input="test.bed" :var partition="broadwl" :dir /scratch/midway2/aksarkar/singlecell :eval never-export
    export input=$input
    sbatch --partition=$partition --wait
    #!/bin/bash
    module load bedtools
    bedtools sort -header -i $input | bgzip >$input.gz
    tabix -f -p bed $input.gz
  #+END_SRC

  #+NAME: qtltools
  #+BEGIN_SRC sh :var pheno="test" :var geno="geuvadis-chr1.vcf.gz" :var partition="broadwl" :var op="--permute 100000" :dir /scratch/midway2/aksarkar/singlecell :eval never-export 
    export pheno=$pheno
    export geno=$geno
    export op=$op
    sbatch --partition=$partition -a 1-100 -J $pheno-qtl --wait
    #!/bin/bash
    source activate scqtl
    qtltools cis --vcf $geno --bed $pheno.bed.gz $op --chunk $SLURM_ARRAY_TASK_ID 100 --out $pheno-qtl.$SLURM_ARRAY_TASK_ID.txt --seed 0
  #+END_SRC

  #+NAME: read-qtltools-def
  #+BEGIN_SRC ipython
    def _read_helper(pheno, columns):
      file_names = ['{}-qtl.{}.txt'.format(pheno, i) for i in range(1, 101)]
      res = (pd.concat([pd.read_table(f, header=None, sep=' ')
                         for f in file_names if os.path.exists(f) and
                         os.path.getsize(f) > 0])
              .rename(columns={i: x for i, x in enumerate(columns)})
              .dropna()
              .sort_values('p_beta'))
      res['p_adjust'] = bh(res['p_beta'])
      res['fdr_pass'] = res['p_adjust'] < 0.1
      return res


    def read_fastqtl_output(pheno):
      columns = ['gene', 'num_snps', 'a', 'b', 'dummy', 'id',
                 'distance', 'p', 'beta', 'p_empirical', 'p_beta']
      res = _read_helper(pheno, columns)
      # Drop the gene version number
      res['gene'] = res['gene'].apply(lambda x: x.split('.')[0])
      res['chr'] = res['id'].apply(lambda x: x.split('.')[1])
      res['pos'] = res['id'].apply(lambda x: x.split('.')[2])
      res['id'] = res['id'].apply(lambda x: x.split('.')[0])
      return res

    def read_qtltools_output(pheno):
      columns = ['gene', 'chr', 'start', 'end', 'strand', 'num_vars',
                 'distance', 'id', 'var_chr', 'var_start', 'var_end', 'df',
                 'dummy', 'a', 'b', 'p_nominal', 'beta', 'p_empirical', 'p_beta']
      res = _read_helper(pheno, columns)
      res['chr'] = res['var_chr']
      res['pos'] = res['var_start']
      res['id'] = res['id'].apply(lambda x: x.split('.')[0])
      return res

    def read_nominal_pass(f):
      isf = st.chi2(1).isf
      result = pd.read_table(f, sep=' ', header=None)
      result.columns = ['gene', 'chr', 'start', 'end', 'strand', 'n', 'distance', 'id', 'var_chr', 'var_start', 'var_end', 'p_nominal', 'beta', 'top']
      result['z'] = np.sign(result['beta']) * np.sqrt(isf(result['p_nominal']))
      return result
  #+END_SRC

  #+RESULTS: read-qtltools-def
  :RESULTS:
  # Out[5]:
  :END:

  #+RESULTS:
  :RESULTS:
  # Out[79]:
  :END:

  #+NAME: plot-approx-perm-def
  #+BEGIN_SRC ipython
    def plot_approx_permutation(df):
      plt.clf()
      plt.gcf().set_size_inches(6, 6)
      plt.scatter(df['p_empirical'], df['p_beta'], s=1, c='k')
      plt.plot([0, 1], [0, 1], c='r', ls='--')
      plt.xlabel('Empirical p-value')
      plt.ylabel('Approximate p-value')
  #+END_SRC

  #+RESULTS: plot-approx-perm-def
  :RESULTS:
  # Out[6]:
  :END:

  #+NAME: qqplot-def
  #+BEGIN_SRC ipython
    def qqplot(qtls):
      N = qtls.shape[0]
      # 95% bootstrap CI
      ci = -np.log10(np.percentile(np.sort(np.random.uniform(size=(100, N)), axis=1), [5, 95], axis=0))

      grid = -np.log10(np.arange(1, 1 + N) / N)
      plt.clf()
      plt.gcf().set_size_inches(6, 6)
      plt.scatter(grid, -np.log10(qtls['p_beta']), s=1, c='k')
      plt.plot([0, np.log10(qtls.shape[0])], [0, np.log10(qtls.shape[0])], c='r', ls='--')
      plt.plot(grid, ci[0], c='r', ls=':')
      plt.plot(grid, ci[1], c='r', ls=':')
      plt.xlabel('Expected $-\log_{10}(p)$')
      _ = plt.ylabel('Observed $-\log_{10}(p)$')
  #+END_SRC

  #+RESULTS: qqplot-def
  :RESULTS:
  # Out[7]:
  :END:

  #+NAME: replication-tests-def
  #+BEGIN_SRC ipython
    def parse_vcf_dosage(record):
      geno = [float(g) for g in record[9:]]
      return pd.Series(geno)

    def extract_qtl_gene_pair(qtl_gene_df, pheno_df, dosages):
      """Return aligned genotype and phenotype matrix for each QTL-gene pair in qtl_gene_df"""
      common_phenos, common_qtls = pheno_df.align(qtl_gene_df.set_index('gene'), join='inner', axis=0)
      # Important: individual IDs do not have the NA prefix in the VCF
      header = ['NA{}'.format(x) for x in pd.read_table(dosages, nrows=1, header=0).columns[9:]]
      genotypes = tabix.open(dosages)
      X, Y = (common_qtls
              .apply(lambda x: parse_vcf_dosage(next(genotypes.query(x['chr'], int(x['var_start']) - 1, int(x['var_start'])))), axis=1)
              .rename(columns={i: ind for i, ind in enumerate(header)})
              .align(common_phenos, join='inner', axis=None))
      return X, Y

    def replication_tests(X, Y, C=None):
      """Return a DataFrame containing replication p-values

      X - centered dosage matrix (num_genes, num_individuals)
      Y - phenotype matrix (num_genes, num_individuals)
      C - confounder matrix (num_confounders, num_individuals)

      """
      p, n = X.shape
      assert Y.shape == (p, n)
      if C is not None:
        assert C.shape[1] == n
        C = np.array(C).T
        C = C - C.mean(axis=0)
        # Construct the annihilator matrix I - X X^+
        M = np.eye(n) - C.dot(np.linalg.pinv(C))
      result = []
      _sf = st.chi2(1).sf
      for (_, x), (name, y) in zip(X.iterrows(), Y.iterrows()):
        if np.isclose(x.std(), 0):
          print('Skipping {}'.format(name))
          continue
        x = x.values.copy().reshape(-1, 1)
        x -= x.mean()
        y = y.values.copy().ravel()
        y -= y.mean()
        if C is not None:
          y = M.dot(y)
          y -= y.mean()
        beta, rss, *_ = np.linalg.lstsq(x, y, rcond=-1)
        sigma2 = rss / y.shape[0]
        se = sigma2 / x.T.dot(x).ravel()
        pval = _sf(np.square(beta / se))
        result.append({'gene': name, 'beta': beta[0], 'se': se[0], 'p': pval.ravel()[0]})
      return pd.DataFrame.from_dict(result)

    def pairwise_replication(qtls, phenos, ticks):
      repl_rate = np.ones((len(phenos), len(phenos)))
      for i, ki in enumerate(phenos):
        for j, kj in enumerate(phenos):
          if i == j:
            continue
          q, p = qtls[ki][0], qtls[kj][1]
          X, Y = extract_qtl_gene_pair(q[q['fdr_pass']], p,
                                       dosages='/scratch/midway2/aksarkar/singlecell/reproduce-yang/YRI_SNPs_2_IPSC.txt.gen.gz')
          if X.empty:
            continue
          replication = q.merge(
            replication_tests(X, Y),
            on='gene',
            suffixes=['_1', '_2'])[['gene', 'id', 'beta_1', 'beta_2', 'p']]
          replication['fdr_pass'] = bh(replication['p']) < .1
          replication['replicated'] = replication.apply(lambda x: x['fdr_pass'] and x['beta_1'] * x['beta_2'] > 0, axis=1)
          repl_rate[i, j] = replication['replicated'].sum() / replication.shape[0]
      return pd.DataFrame(100 * repl_rate, columns=ticks, index=ticks)
  #+END_SRC

  #+RESULTS: replication-tests-def
  :RESULTS:
  # Out[8]:
  :END:

  #+NAME: bootstrap-def
  #+BEGIN_SRC ipython
    def bootstrap_se(X, Y, C=None, num_bootstraps=100, seed=0):
      np.random.seed(seed)
      beta = {}
      for i in range(num_bootstraps):
        b = np.random.choice(X.shape[1], size=X.shape[1], replace=True)
        if C is not None:
          beta[i] = replication_tests(X.iloc[:,b], Y.iloc[:,b], C.iloc[:,b]).set_index('gene')['beta']
        else:
          beta[i] = replication_tests(X.iloc[:,b], Y.iloc[:,b]).set_index('gene')['beta']
      return pd.DataFrame.from_dict(beta).agg(np.std, axis=1)
  #+END_SRC

  #+RESULTS: bootstrap-def
  :RESULTS:
  # Out[9]:
  :END:

  #+NAME: bootstrap-betahat-se-def
  #+BEGIN_SRC ipython
    def _fit_lm(x, y):
      n, p = x.shape
      assert y.shape == (n, 1)
      y -= y.mean()
      x -= x.mean(axis=0)
      beta = x.T.dot(y) / np.var(x, axis=0).values.reshape(-1, 1)
      return beta

    def estimate_beta_se(genes, dosages, gene_info, covars=None, window=100000, n_bootstrap=100, seed=0):
      """Estimate beta via OLS and SE via bootstrap

      genes - dataframe (num_genes, num_individuals)
      dosages - VCF file name
      gene_info - dataframe (see read_gene_info)
      covars - dataframe (num_covars, num_individuals)

      """
      with gzip.open(dosages, 'rt') as f:
        for line in f:
          if line.startswith('#CHROM'):
            header = line.split()[9:]
            break
      dosages = tabix.open(dosages)
      if covars is not None:
        covars, genes = covars.align(genes, axis='columns', join='inner')
        _, n = covars.shape
        covars = covars.values.T
        M = np.eye(n) - covars.dot(np.linalg.pinv(covars))
      result = []
      for gene, Y in genes.iterrows():
        if gene in gene_info.index:
          record = gene_info.loc[gene]
          if record['strand'] == '+':
            X = dosages.query('chr{}'.format(record['chr'][2:]), record['start'] - window, record['start'] + window)
          else:
            X = dosages.query('chr{}'.format(record['chr'][2:]), record['end'] - window, record['end'] + window)
          X = list(X)
          meta = [row[2] for row in X]
          X = pd.DataFrame([parse_vcf_dosage(row) for row in X])
          X.index = meta
          X.columns = header
          X, Y = X.align(Y, axis='columns', join='inner')
          if covars is not None:
            Y = M.dot(Y - Y.mean())
          X = X.transform(lambda x: x - x.mean(), axis=1)

          beta = [_fit_lm(X.T, Y.reshape(-1, 1))]
          np.random.seed(seed)
          for _ in range(n_bootstrap):
            B = np.random.choice(n, size=n, replace=True)
            beta.append(_fit_lm(X.iloc[:,B].T, Y[B].reshape(-1, 1)))
          result.append(pd.DataFrame({'gene': gene, 'snp': meta, 'beta': beta[0].values.ravel(), 'se': np.std(np.ma.masked_invalid(np.hstack(beta[1:])), axis=1)}))
      return pd.concat(result)
  #+END_SRC

  #+RESULTS: bootstrap-betahat-se-def
  :RESULTS:
  # Out[10]:
  :END:

* Preliminaries
** Test validity of approximate permutation test

   ~qtltools~ tries to calibrate false discovery rates using the following
   procedure:

   1. For each gene, permute the genotype data to estimate the null distribution
      of the p-values
   2. Fit a beta distribution to the permuted p-values via ML
   3. Compute the lower tail probability of the observed p-value, assuming it
      was generated from the fitted beta distribution
   4. Apply FDR correction on the set of lower tail probabilities (across all
      genes)

   Test whether the beta approximation is appropriate for our sample size by
   subsetting GEUVADIS. Take all genes on chromosome 1.

   #+BEGIN_SRC ipython
    geuvadis = []
    for chunk in pd.read_table('/project/compbio/geuvadis/analysis_results/GD462.GeneQuantRPKM.50FN.samplename.resk10.txt.gz', chunksize=100):
      geuvadis.append(chunk.query('Chr == "1"'))
    geuvadis = pd.concat(geuvadis)
    geuvadis = geuvadis.set_index(geuvadis['Gene_Symbol'].apply(lambda x: x.split('.')[0]))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[34]:
   :END:

   First, replicate the result in [[https://www.nature.com/articles/ncomms15452][Delaneau et al 2017]] by using all 462
   individuals from GEUVADIS.

   #+BEGIN_SRC ipython
    pd.Series(geuvadis.columns).sort_values().to_csv('/scratch/midway2/aksarkar/singlecell/geuvadis/geuvadis-subset.txt', header=None, index=None)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[35]:
   :END:

   Write out the phenotype file for ~qtltools~. Important: GEUVADIS VCFs code
   chromosome without ~chr~.

   #+BEGIN_SRC ipython
     write_pheno_file(geuvadis, gene_info, '/scratch/midway2/aksarkar/singlecell/geuvadis/test.bed', prefix='')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[39]:
   :END:

   Index the phenotype file. Important: ~#~ sorts before ~c~, but after ~1~.

   #+CALL: tabix() :dir /scratch/midway2/aksarkar/singlecell/geuvadis

   #+RESULTS:
   : Submitted batch job 44542169

   Perform SNP QC in ~plink~.

   #+NAME: geuvadis-qc
   #+BEGIN_SRC sh :eval never-export :dir /scratch/midway2/aksarkar/singlecell/geuvadis
     sbatch --partition=broadwl --mem=2G --wait
     #!/bin/bash
     plink --memory 2000 --geno 0.01 --maf 0.05 --keep-fam /scratch/midway2/aksarkar/singlecell/geuvadis-subset.txt --vcf /project/compbio/geuvadis/genotypes/GEUVADIS.chr1.PH1PH2_465.IMPFRQFILT_BIALLELIC_PH.annotv2.genotypes.vcf.gz --recode vcf-iid --out geuvadis-chr1
     bgzip -f geuvadis-chr1.vcf
     tabix -f -p vcf geuvadis-chr1.vcf.gz
   #+END_SRC

   #+RESULTS: geuvadis-qc
   : Submitted batch job 44541229

   Run ~qtltools~.

   #+CALL: qtltools() :dir /scratch/midway2/aksarkar/singlecell/geuvadis

   #+RESULTS:
   : Submitted batch job 44685856

   Read the results.

   #+BEGIN_SRC ipython
    geuvadis_qtls = read_qtltools_output('geuvadis/test')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[23]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/geuvadis-beta-approx.png
    plot_approx_permutation(geuvadis_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[41]:
   [[file:figure/qtl-mapping.org/geuvadis-beta-approx.png]]
   :END:

   Plot the QQ plot

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/geuvadis-qq.png
     qqplot(geuvadis_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[24]:
   [[file:figure/qtl-mapping.org/geuvadis-qq.png]]
   :END:

   Repeat the analysis after subsetting to 54 individuals.

   #+BEGIN_SRC ipython
    np.random.seed(0)
    subset = np.random.choice([x for x in geuvadis.columns], size=54, replace=False)
    pd.Series(subset).sort_values().to_csv('/scratch/midway2/aksarkar/singlecell/geuvadis-subset.txt', header=None, index=None)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[42]:
   :END:

   #+BEGIN_SRC ipython
     write_pheno_file(geuvadis[subset], gene_info, '/scratch/midway2/aksarkar/singlecell/geuvadis/test.bed', prefix='')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[44]:
   :END:

   #+CALL: tabix() :dir /scratch/midway2/aksarkar/singlecell/geuvadis

   #+RESULTS:
   : Submitted batch job 44544326

   #+CALL: geuvadis-qc() :dir /scratch/midway2/aksarkar/singlecell/geuvadis

   #+RESULTS:
   : Submitted batch job 44544018

   #+CALL: qtltools() :dir /scratch/midway2/aksarkar/singlecell/geuvadis

   #+RESULTS:
   : Submitted batch job 44544375

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/geuvadis-54-beta-approx.png
     geuvadis_54_qtls = read_qtltools_output('geuvadis/test')
     plot_approx_permutation(geuvadis_54_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[47]:
   [[file:figure/qtl-mapping.org/geuvadis-54-beta-approx.png]]
   :END:

** Reproduce bulk eQTL calls

   The iPSC bulk eQTLs were called in [[https://genome.cshlp.org/content/28/1/122.long][Banovich et al 2018]].

   #+BEGIN_EXAMPLE
     eQTLs in iPSCs and LCLs: We transformed expression levels to a standard normal
     within each individual. We next accounted for unknown confounders by removing
     principal components from the LCL (15 PCs) and iPSC (10 PCs) data. Genotypes
     were obtained using impute2 as described previously (Li et al. 2016). We only
     considered variants within 50 kb of genes. To identify association between
     genotype and gene expression, we used FastQTL (Ongen et al. 2016). After the
     initial regression, a variable number of permutations were performed to obtain
     a gene-wise adjusted P-value (Ongen et al. 2016). To identify significant
     eQTLs, we used Storey's q-value (Storey and Tibshirani 2003) on the adjusted
     P-values. Genes with a q-value less than 0.1 are considered significant.
   #+END_EXAMPLE

   *Important notes:*

   1. The text doesn't state how expression level was quantified (it was the
      ratio of mapped reads to total reads after correction by
      ~WASP~).

      ~WASP~ ([[https://www.nature.com/articles/nmeth.3582][de Geijin et al 2015]]) fits quartic polynomials \(f, g\) which
      predict the total read count per region \(T^*_{ij}\) from the observed
      read count \(x_{ij}\) and GC content \(w_j\) by maximizing the likelihood
      of the observed read counts:

      \[ x_{ij} \sim \mathrm{Pois}(T^*_{ij}) \]

      \[ T^*_{ij} = \exp\left(f\left(\sum_i x_{ij}\right)\right) g(w_j) \]

      [[*Recall bulk eQTLs from log CPM][Using log CPM]] (under the assumption that we never compare genes to each
      other) yields 1279 eQTLs (89%).

   2. ~fastqtl~ expects gene start/end, and only takes /cis/-SNPs around the
      start ignoring strand. The code uses GENCODE v19 exons to define the
      start/end.

      ~qtltools~ expects TSS and strand, but doesn't use strand information in
      /cis/-eQTL mapping. Using the start coordinate of the provided expression
      matrix as TSS yields 1265 eQTLs (87%).

   3. The methods section of [[https://www.nature.com/articles/nature10808][Degner et al 2012]] states data is standardized
      across individuals, and quantile normalized within individuals. The
      equation contradicts the text, but the code follows the text.

   4. The code analyzes 100kb windows, contradicting the text.

   5. Not every gene in the input appears in the output, and changing the number
      of chunks changes the number of genes lost.

   6. QTL-gene pairs passed the Benjamini-Hochberg procedure, not Storey's
      procedure.

   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/reproduce-yang
     sbatch --partition=broadwl -a 1-25
     #!/bin/bash
     source activate scqtl
     fastqtl -V YRI_SNPs_2_IPSC.txt.gen.gz -B fastqtl_qqnorm_RNAseq_run.fixed.txt.gz -C fasteqtl_PC_RNAseq_run.fixed.txt -O bulk-qtl.$SLURM_ARRAY_TASK_ID.txt --exclude-samples file_IPSC.excl --window 1e5 --permute 1000 10000 --chunk $SLURM_ARRAY_TASK_ID 25 --seed 1475098497
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 44546060

   Read ~fastqtl~ output.

   #+BEGIN_SRC ipython
     bulk_qtls = read_fastqtl_output('reproduce-yang/bulk')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[19]:
   :END:

   Write out the summary stats with headers.

   #+BEGIN_SRC ipython
     bulk_qtls.to_csv('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-mapping/bulk.txt.gz', sep='\t', index=None, compression='gzip')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[21]:
   :END:

   Compare ~qtltools~ to ~fastqtl~. The input files need to be modified.

   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/reproduce-yang/
     sbatch --partition=broadwl --wait
     #!/bin/bash
     zcat fastqtl_qqnorm_RNAseq_run.fixed.txt.gz | awk -vOFS='\t' 'NR == 1 {$4 = "pid" OFS "gid" OFS "strand"; for (i = 5; i <= NF; i++) {$i = "NA"$i} print} NR > 1 {$4 = $4 OFS $4 OFS "+"; $3 = $2; print}' >test.bed
     awk 'NR == 1 {for (i = 2; i <= NF; i++) {$i = "NA"$i}} {print}' fasteqtl_PC_RNAseq_run.fixed.txt >covars.txt
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 44979838

   Check whether the FDR is properly controlled by permuting.
   
   #+BEGIN_SRC ipython
     np.random.seed(0)
     permutation = bulk_expr.columns.values.copy()
     np.random.shuffle(permutation[5:])
     bulk_expr.columns = permutation

     covars = (pd.read_table('/scratch/midway2/aksarkar/singlecell/reproduce-yang/covars.txt', sep=' ')
               .rename(columns={k: v for k, v in zip(bulk_expr.columns, permutation)}))
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/reproduce-yang/covars.txt', sep=' ', index=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[121]:
   :END:

   Fix the TSS by rewriting the phenotype file.

   #+BEGIN_SRC ipython
     bulk_expr = pd.read_table('/scratch/midway2/aksarkar/singlecell/reproduce-yang/test.bed', index_col=3)
     bulk_expr.index = [x.split('.')[0] for x in bulk_expr.index]
     write_pheno_file(bulk_expr.iloc[:,5:], gene_info, '/scratch/midway2/aksarkar/singlecell/reproduce-yang/test.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[152]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="test.bed") :dir /scratch/midway2/aksarkar/singlecell/reproduce-yang/

   #+RESULTS:
   : Submitted batch job 44683584

   Run ~qtltools~.

   #+CALL: qtltools(pheno="test", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/reproduce-yang/

   #+RESULTS:
   : Submitted batch job 44683586

   Read ~qtltools output~

   #+BEGIN_SRC ipython
     bulk_qtls = read_qtltools_output('reproduce-yang/test')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[130]:
   :END:

   Check the beta approximation.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/qqnorm-beta-approx.png
     plot_approx_permutation(bulk_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[134]:
   [[file:figure/qtl-mapping.org/qqnorm-beta-approx.png]]
   :END:

   Plot a QQ plot of adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/qqnorm-qq.png
     qqplot(bulk_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[135]:
   [[file:figure/qtl-mapping.org/qqnorm-qq.png]]
   :END:

   Take QTLs with \(\mathrm{FDR} < 0.1\).

   #+BEGIN_SRC ipython
     bulk_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[136]:
   : 1441
   :END:

** Recall bulk eQTLs from log CPM

   Read the counts matrix.

   #+BEGIN_SRC ipython
     bulk_counts = (pd.read_table('/project2/gilad/singlecell-qtl/bulk/counts_RNAseq_iPSC.txt', sep=' ', index_col=0)
                    .rename(columns=lambda x: 'NA{}'.format(x))
                    .rename(index=lambda x: x.split('.')[0]))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[34]:
   :END:

   Throw out individuals.

   #+BEGIN_SRC ipython
     with open('/scratch/midway2/aksarkar/singlecell/reproduce-yang/file_IPSC.excl') as f:
       for line in f:
         k = 'NA{}'.format(line.strip())
         if k in bulk_counts:
           del bulk_counts[k]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[35]:
   :END:

   Normalize the counts matrix by computing log CPM. Normalizing by length is
   unnecessary because we only ever compare counts for the same gene across
   individuals.

   #+BEGIN_SRC ipython
     bulk_log_cpm = (cpm(bulk_counts)
                     .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                     .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[36]:
   :END:

   Compute expression PCs.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=10).fit(bulk_log_cpm).components_, columns=bulk_log_cpm.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/recall-bulk/log-cpm-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[37]:
   :END:

   Check whether the false discovery rate is properly controlled by permuting
   the data.

   Write the phenotype matrix in ~qtltools~ format.  Use the annotation data
   (ENSEMBL 75) in this repository to be consistent with the single cell
   data. *Important: this loses 1716 genes (are they pseudogenes?)*

   #+BEGIN_SRC ipython
     write_pheno_file(
       bulk_log_cpm,
       gene_info,
       holdout=False,
       output_file='/scratch/midway2/aksarkar/singlecell/recall-bulk/bulk-log-cpm.bed')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[38]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="bulk-log-cpm.bed") :dir /scratch/midway2/aksarkar/singlecell/recall-bulk

   #+RESULTS:
   : Submitted batch job 44681764

   Ensure the dosage file follows the VCF standard. Add the prefix ~NA~ to sample IDs.

   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/reproduce-yang
     sbatch --partition=broadwl
     #!/bin/bash
     zcat YRI_SNPs_2_IPSC.txt.gen.gz | awk -vOFS='\t' 'BEGIN {print "##fileformat=VCFv4.2"; print "##FORMAT=<ID=DS,Number=1,Type=Float>"} NR == 1 {for (i = 10; i <= NF; i++) {$i = "NA"$i}} {print}' | bgzip >yri-dosages.vcf.gz
     tabix yri-dosages.vcf.gz
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 44546926

   Run ~qtltools~

   #+CALL: qtltools(pheno="bulk-log-cpm", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov log-cpm-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/recall-bulk

   #+RESULTS:
   : Submitted batch job 44681768

   Read the output. *Important: this loses 201 genes (is this a bug in
   ~qtltools~)?*

   #+BEGIN_SRC ipython
     bulk_cpm_qtls = read_qtltools_output('recall-bulk/bulk-log-cpm')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[137]:
   :END:

   Check the beta approximation.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/bulk-cpm-beta-approx.png
     plot_approx_permutation(bulk_cpm_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[40]:
   [[file:figure/qtl-mapping.org/bulk-cpm-beta-approx.png]]
   :END:

   Plot a QQ plot of adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/bulk-cpm-qq.png
     qqplot(bulk_cpm_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[138]:
   [[file:figure/qtl-mapping.org/bulk-cpm-qq.png]]
   :END:

   Take QTLs with \(\mathrm{FDR} < 0.1\).

   #+BEGIN_SRC ipython
     bulk_cpm_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[139]:
   : 1276
   :END:

** Recall bulk eQTLs from log TPM

   We [[file:kallisto.org][reprocessed the bulk RNA-Seq data]] using ~kallisto~. Read the TPM
   matrix.

   #+BEGIN_SRC ipython
     bulk_log_tpm = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/kallisto/bulk-ipsc-tpm.txt.gz', header=None, sep=' ')
     bulk_log_tpm = np.log(bulk_log_tpm.pivot(columns=0, index=1, values=2) + 1)
     bulk_log_tpm.index = [x.split('.')[0] for x in bulk_log_tpm.index]
     # Important: need to throw out all zero rows because they blow up
     # standardization
     bulk_log_tpm = (bulk_log_tpm[bulk_log_tpm.apply(lambda x: x.sum() > 0, axis=1)]
                     .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                     .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[140]:
   :END:

   To quantify how much power we expect to lose going from 58 to 49 individuals
   (in our scRNA-Seq data), perform QTL mapping on a random subset of 49
   individuals.

   #+BEGIN_SRC ipython
     np.random.seed(0)
     keep_inds = np.random.choice(bulk_log_tpm.columns, size=49, replace=False)
     bulk_log_tpm = bulk_log_tpm.filter(items=keep_inds, axis='columns')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[37]:
   :END:

   Check whether the false discovery rate is properly controlled by permuting
   the data.

   #+BEGIN_SRC ipython
     np.random.seed(0)
     permutation = bulk_log_tpm.columns.values
     np.random.shuffle(permutation)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[67]:
   :END:

   Get the TSS information. Use the annotation data (ENSEMBL 75) in this
   repository to be consistent with the single cell data.

   Write the phenotype matrix in ~qtltools~ format. *Important: this loses 1034
   genes*

   #+BEGIN_SRC ipython
     write_pheno_file(
       bulk_log_tpm,
       gene_info,
       holdout=False,
       output_file='/scratch/midway2/aksarkar/singlecell/recall-bulk/bulk-log-tpm.bed')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[141]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="bulk-log-tpm.bed") :dir /scratch/midway2/aksarkar/singlecell/recall-bulk

   #+RESULTS:
   : Submitted batch job 44686635

   Compute principal components.

   #+BEGIN_SRC ipython
    covars = pd.DataFrame(skd.PCA(n_components=6).fit(bulk_log_tpm).components_, columns=bulk_log_tpm.columns)
    covars.index.name = 'id'
    covars.to_csv('/scratch/midway2/aksarkar/singlecell/recall-bulk/log-tpm-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[142]:
   :END:

   Run ~qtltools~

   #+CALL: qtltools(pheno="bulk-log-tpm", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov log-tpm-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/recall-bulk

   #+RESULTS:
   : Submitted batch job 44686640

   Read the output. *Important: this loses 201 genes (is this a bug in
   ~qtltools~)?*

   #+BEGIN_SRC ipython
     bulk_tpm_qtls = read_qtltools_output('recall-bulk/bulk-log-tpm')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[143]:
   :END:

   Check the beta approximation to the permuted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/bulk-tpm-beta-approx.png
     plot_approx_permutation(bulk_tpm_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[144]:
   [[file:figure/qtl-mapping.org/bulk-tpm-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/bulk-log-tpm-qtl-qq.png
     qqplot(bulk_tpm_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[145]:
   [[file:figure/qtl-mapping.org/bulk-log-tpm-qtl-qq.png]]
   :END:

   Take QTLs with \(\mathrm{FDR} < 0.1\).

   #+BEGIN_SRC ipython
     bulk_tpm_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[146]:
   : 1020
   :END:

** Reprocess YRI dosages

   We have two individuals which weren't used in Banovich et al 2018, so we
   don't have their genotypes. Reprocess the IMPUTE2 output to get the correct
   dosage matrix.

   #+BEGIN_SRC sh :eval never
     rsync -nva -f '+ */' -f '+ *.impute2.gz' -f '+ YRI_samples.txt' -f '- *' ./ aksarkar@midway2.rcc.uchicago.edu:/scratch/midway2/aksarkar/singlecell/scqtl-mapping/
   #+END_SRC

   #+BEGIN_SRC ipython :eval never :tangle /scratch/midway2/aksarkar/singlecell/scqtl-mapping/reprocess-dosage.py
     import glob
     import gzip
     import numpy as np
     import pandas as pd
     import sqlite3

     def convert_impute2_vcf(file, mask, chrom, outfile, min_maf=0.05):
       for line in file:
         record = line.split()
         posterior = np.array([float(x) for x in record[5:]])
         dose = posterior.reshape(-1, 3).dot(np.arange(3))[mask]
         if min_maf <= dose.mean() / 2 <= 1 - min_maf:
           print(chrom, record[2], '{}.{}.{}'.format(record[1], chrom, record[2]),
                 record[3], record[4], '.', '.', '.', 'DS',
                 ,*['{:.3f}'.format(x) for x in dose], sep='\t', file=outfile)

     samples = pd.read_table('YRI_samples.txt', header=None, sep=' ')
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       keep = pd.read_sql('select chip_id from annotation group by chip_id having count(*) >= 50;', conn)
     mask = samples[0].isin(keep['chip_id']).values
     assert mask.sum() == 53
     with gzip.open('yri-120-dosages.vcf.gz', 'wt') as f:
       print('##fileformat=VCFv4.2', file=f)
       print('##FORMAT=<ID=DS,Number=1,Type=Float>', file=f)
       print('#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', *samples[0][mask], sep='\t', file=f)
       for c in range(1, 23):
         with gzip.open('chr{}.hg19.impute2.gz'.format(c), 'rt') as g:
           convert_impute2_vcf(g, mask, 'chr{}'.format(c), outfile=f)
   #+END_SRC


   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping
     sbatch --partition=mstephens
     #!/bin/bash
     source activate scqtl
     python reprocess-dosage.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 45277139

* Analysis using sample moments

  The simplest possible way to estimate means/variances/dispersions to use as
  quantitative phenotypes is to use the sample moments.

  Intuitively, the phenotypes defined this way will be confounded by
  differential proportion of zeros between individuals, but we need to quantify
  the resulting loss in power.

** Call eQTLs from pooled scRNA-Seq

   Read the QC filters.

   #+NAME: qc-filters
   #+BEGIN_SRC ipython
     annotation = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-annotation.txt')
     keep_samples = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/quality-single-cells.txt', index_col=0, header=None)
     keep_genes = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/genes-pass-filter.txt', index_col=0, header=None)
     annotation = annotation.loc[keep_samples.values.ravel()]
     keep_inds = annotation.groupby('chip_id').apply(lambda x: len(x) >= 50)
   #+END_SRC

   #+RESULTS: qc-filters
   :RESULTS:
   # Out[16]:
   :END:

   Read and pool the UMI data.

   #+BEGIN_SRC ipython
     pooled_counts = pd.concat(
       [(chunk
         .filter(items=keep_genes[keep_genes.values].index, axis='index')
         # Important: this can't be done by filter because sample names are
         # different in the QC file
         .loc[:,keep_samples.values.ravel()]
         .groupby(annotation['chip_id'].values, axis=1)
         .agg(np.sum))
        for chunk in
        pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-counts.txt.gz',
                      chunksize=1000, index_col=0)])
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[17]:
   :END:

   Normalize the pooled counts.

   #+BEGIN_SRC ipython
     pooled_cpm = (cpm(pooled_counts).loc[:,keep_inds]
                   .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                   .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[18]:
   :END:

   Compute principal components and write out the covariate file.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=10).fit(pooled_cpm).components_, columns=pooled_cpm.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/pooled-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[19]:
   :END:

   Write out the phenotype file.

   #+BEGIN_SRC ipython
     write_pheno_file(pooled_cpm, gene_info, holdout=False, output_file='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/pooled.bed')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[13]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="pooled.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45127968

   Run ~qtltools~

   #+CALL: qtltools(pheno="pooled", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov pooled-covars.txt  --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45127969

   Read the output. *Important: this loses 200 genes (is this a bug in
   ~qtltools~)?*

   #+BEGIN_SRC ipython
     pooled_qtls = read_qtltools_output('scqtl-mapping/pooled')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[14]:
   :END:

   Check the beta approximation.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/pooled-cpm-beta-approx.png
     plot_approx_permutation(pooled_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[15]:
   [[file:figure/qtl-mapping.org/pooled-cpm-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/pooled-qtl-qq.png
     qqplot(pooled_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[16]:
   [[file:figure/qtl-mapping.org/pooled-qtl-qq.png]]
   :END:

   Take QTLs with \(\mathrm{FDR} < 0.1\).

   #+BEGIN_SRC ipython
    pooled_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[17]:
   : 240
   :END:

** Call mean-QTLs

   Throw out individuals with fewer than 50 cells.

   #+CALL: qc-filters()

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   :END:

   Read the count matrix.

   #+NAME: read-umi
   #+BEGIN_SRC ipython
     umi = pd.concat(
       [(chunk
         .filter(items=keep_genes[keep_genes.values].index, axis='index')
         # Important: this can't be done by filter because sample names are
         # different in the QC file
         .loc[:,keep_samples.values.ravel()])
        for chunk in
        pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-counts.txt.gz',
                      chunksize=1000, index_col=0)])
   #+END_SRC

   Compute the sample mean log CPM per individual, then normalize.

   #+BEGIN_SRC ipython
     sample_mean = (cpm(umi)
                    .groupby(annotation['chip_id'].values, axis=1)
                    .agg(np.mean)
                    .loc[:,keep_inds]
                    .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                    .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[14]:
   :END:

   Compute principal components and write out the covariate file.

   #+BEGIN_SRC ipython
    covars = pd.DataFrame(skd.PCA(n_components=10).fit(sample_mean).components_, columns=sample_mean.columns)
    covars.index.name = 'id'
    covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-mean-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[15]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(
       sample_mean,
       gene_info,
       output_file='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-mean.bed',
       holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[16]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="sample-mean.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45128520

   Run ~qtltools~.

   #+CALL: qtltools(pheno="sample-mean", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov sample-mean-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45128522

   Read the output.

   #+BEGIN_SRC ipython
     sample_mean_qtls = read_qtltools_output('scqtl-mapping/sample-mean')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[17]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-mean-qtl-beta-approx.png
     plot_approx_permutation(sample_mean_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[18]:
   [[file:figure/qtl-mapping.org/sample-mean-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-mean-qtl-qq.png
     qqplot(sample_mean_qtls)
   #+end_SRC

   #+RESULTS:
   :RESULTS:
   # Out[19]:
   [[file:figure/qtl-mapping.org/sample-mean-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
    sample_mean_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[20]:
   : 176
   :END:

** Call variance-QTLs

   Throw out individuals with fewer than 50 cells.

   #+CALL: qc-filters()

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   :END:

   Read the UMI matrix.

   #+CALL: read-umi()

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   :END:

   Compute the sample variance of log CPM per individual, then normalize.

   #+BEGIN_SRC ipython
     sample_var = (cpm(umi)
                    .groupby(annotation['chip_id'].values, axis=1)
                    .agg(np.var)
                    .loc[:,keep_inds]
                    .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                    .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   :END:

   Compute principal components and write out the covariate file.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=2).fit(sample_var).components_, columns=sample_var.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-var-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[21]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(sample_var, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-var.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[22]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="sample-var.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45128698

   Run ~qtltools~.

   #+CALL: qtltools(pheno="sample-var", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov sample-var-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45128699

   Read the output.

   #+BEGIN_SRC ipython
     sample_var_qtls = read_qtltools_output('scqtl-mapping/sample-var')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[23]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-var-qtl-beta-approx.png
     plot_approx_permutation(sample_var_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[24]:
   [[file:figure/qtl-mapping.org/sample-var-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-var-qtl-qq.png
     qqplot(sample_var_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[25]:
   [[file:figure/qtl-mapping.org/sample-var-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     sample_var_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[26]:
   : 3
   :END:

** Call CV-QTLs

   Throw out individuals with fewer than 50 cells.

   #+CALL: qc-filters()

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   :END:

   Read the UMI matrix.

   #+CALL: read-umi()

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   :END:

   Compute the sample CV of log CPM per individual, then normalize.

   #+BEGIN_SRC ipython
     sample_cv = (cpm(umi)
                    .groupby(annotation['chip_id'].values, axis=1)
                    .agg(lambda x: np.std(x, axis=1) / (np.mean(x, axis=1) + 1e-8))
                    .loc[:,keep_inds]
                    .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                    .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[30]:
   :END:

   Normalize the CV matrix.

   #+BEGIN_SRC ipython
     sample_cv = sample_cv.loc[:,keep_inds].transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=0)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[31]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(sample_cv, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-cv.bed', holdout=True)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[32]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="sample-cv.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45128842

   Run ~qtltools~.

   #+CALL: qtltools(pheno="sample-cv", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45128843

   Read the output.

   #+BEGIN_SRC ipython
    sample_cv_qtls = read_qtltools_output('scqtl-mapping/sample-cv')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[33]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-cv-qtl-beta-approx.png
     plot_approx_permutation(sample_cv_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[34]:
   [[file:figure/qtl-mapping.org/sample-cv-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-cv-qtl-qq.png
    qqplot(sample_cv_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[35]:
   [[file:figure/qtl-mapping.org/sample-cv-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
    sample_cv_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[36]:
   : 0
   :END:

** Call Fano-QTLs

   Throw out individuals with fewer than 50 cells.

   #+CALL: qc-filters()

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   :END:

   Read the UMI matrix.

   #+CALL: read-umi()

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   :END:

   Fisher's index of dispersion is defined as \(V[x] / E[x]\). The Fano factor
   is Fisher's index of dispersion over a fixed window (in our case, the total
   number of reads).

   Compute the sample Fano factor of log CPM per individual, then normalize.

   #+BEGIN_SRC ipython
     sample_fano = (cpm(umi)
                    .groupby(annotation['chip_id'].values, axis=1)
                    .agg(lambda x: np.var(x, axis=1) / (np.mean(x, axis=1)))
                    .loc[:,keep_inds]
                    .transform(lambda x: (x - x.mean()) / x.std(), axis=1)
                    .apply(qqnorm, axis=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[38]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(sample_fano, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample_fano.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[40]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="sample_fano.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45129160

   Compute principal components and write out the covariate file.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=2).fit(sample_fano).components_, columns=sample_fano.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/sample-fano-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[41]:
   :END:

   Run ~qtltools~.

   #+CALL: qtltools(pheno="sample_fano", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov sample-fano-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45129161

   Read the output.

   #+BEGIN_SRC ipython
     sample_fano_qtls = read_qtltools_output('scqtl-mapping/sample_fano')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[42]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-fano-qtl-beta-approx.png
     plot_approx_permutation(sample_fano_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[43]:
   [[file:figure/qtl-mapping.org/sample-fano-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/sample-fano-qtl-qq.png
     qqplot(sample_fano_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[44]:
   [[file:figure/qtl-mapping.org/sample-fano-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     sample_fano_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[45]:
   : 2
   :END:

* Analysis using ZINB
** Call \mu-QTLs

   Throw out individuals with fewer than 50 cells.

   #+CALL: qc-filters()

   #+RESULTS:
   :RESULTS:
   # Out[63]:
   :END:

   Read the estimated parameters \(\log \mu_{ik}\). Exclude individuals with
   fewer than 50 cells.

   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       log_mu = (pd.read_sql(
         """select gene, ind, log_mu from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn)
                   .pivot(index='gene', columns='ind', values='log_mu'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   :END:

   Normalize the mean matrix analagous to the bulk data. In our estimation
   procedure, we now return \(\ln\mu = -\infty\) for individuals with only zero
   observations. Clip this to \(\ln\epsilon\), where \(\epsilon\) is the
   smallest representable floating point number.

   #+BEGIN_SRC ipython
     log_mu = np.clip(log_mu.loc[keep_genes.values.ravel()].dropna(), np.log(np.finfo(np.float).eps), 0).transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=0)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[12]:
   :END:

   Compute principal components of the mean matrix.

   #+BEGIN_SRC ipython
    covars = pd.DataFrame(skd.PCA(n_components=10).fit(log_mu).components_, columns=log_mu.columns)
    covars.index.name = 'id'
    covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/log_mu-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[13]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(log_mu, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/log_mu.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[20]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="log_mu.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45074749

   Run ~qtltools~.

   #+CALL: qtltools(pheno="log_mu", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov log_mu-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45074760

   Read the output.

   #+BEGIN_SRC ipython
     log_mu_qtls = read_qtltools_output('scqtl-mapping/log_mu')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[21]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/mu-qtl-beta-approx.png
     plot_approx_permutation(log_mu_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[22]:
   [[file:figure/qtl-mapping.org/mu-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/mu-qtl-qq.png
     qqplot(log_mu_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[23]:
   [[file:figure/qtl-mapping.org/mu-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     log_mu_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[24]:
   : 211
   :END:

** Call \phi-QTLs

   Read the estimated parameters. Exclude individuals with fewer than 50 cells.

   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       log_phi = (pd.read_sql(
         """select gene, ind, log_phi from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn)
                  .pivot(index='gene', columns='ind', values='log_phi'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[14]:
   :END:

   Normalize the dispersion matrix. Again, we have infinite values, but
   dispersions are not restricted to be in \([0, 1]\), so we have to change the
   clipping bounds.

   #+BEGIN_SRC ipython
     log_phi = np.clip(log_phi.loc[keep_genes.values.ravel()].dropna(), -300, 300).transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=1)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[206]:
   :END:

   Write out the phenotype file.

   #+BEGIN_SRC ipython
     write_pheno_file(log_phi, gene_info, holdout=False, output_file='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/log_phi.bed')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[27]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="log_phi.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45075315

   Run ~qtltools~.

   #+CALL: qtltools(pheno="log_phi", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45075319

   Read the output.

   #+BEGIN_SRC ipython
    log_phi_qtls = read_qtltools_output('scqtl-mapping/log_phi')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[22]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/phi-qtl-beta-approx.png
    plot_approx_permutation(log_phi_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[29]:
   [[file:figure/qtl-mapping.org/phi-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/phi-qtl-qq.png
    qqplot(log_phi_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[30]:
   [[file:figure/qtl-mapping.org/phi-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     log_phi_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[31]:
   : 0
   :END:

** Call \pi-QTLs

   For each gene \(k\), fit a linear model:

   \[ \mathrm{logit}(\pi_k) = X\beta + \epsilon \]

   Read the estimated parameters. Exclude individuals with fewer than 50 cells.

   #+BEGIN_SRC ipython
    with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
      logodds = (pd.read_sql(
        """select gene, ind, logodds from params where ind in 
        (select chip_id from annotation group by chip_id 
        having count(distinct sample) >= 50);""", conn)
                 .pivot(index='gene', columns='ind', values='logodds'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[32]:
   :END:

   Normalize the log odds matrix.

   #+BEGIN_SRC ipython
     logodds = np.clip(logodds.loc[keep_genes.values.ravel()].dropna(), -300, 300)
     logodds = logodds.loc[(logodds.agg(np.std, axis=1) > 0).values]
     logodds = logodds.transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=1)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[33]:
   :END:

   Write out the phenotype file.

   #+BEGIN_SRC ipython
     write_pheno_file(logodds, gene_info, holdout=False, output_file='/scratch/midway2/aksarkar/singlecell/scqtl-mapping/logodds.bed')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[34]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="logodds.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45075744

   Run ~qtltools~.

   #+CALL: qtltools(pheno="logodds", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45075760

   Read the output.

   #+BEGIN_SRC ipython
     logodds_qtls = read_qtltools_output('scqtl-mapping/logodds')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[23]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/logodds-qtl-beta-approx.png
     plot_approx_permutation(logodds_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[36]:
   [[file:figure/qtl-mapping.org/logodds-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/logodds-qtl-qq.png
     qqplot(logodds_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[37]:
   [[file:figure/qtl-mapping.org/logodds-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     logodds_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[38]:
   : 0
   :END:

** Call mean-QTLs

   We have \(r_{ijk} \sim g_{ijk}(\cdot)\), where \(g\) is the ZINB density [[file:zinb.org][as
   previously defined]].

   Fixing individual \(i\), gene \(k\), we can estimate a
   zero-inflation--corrected mean as:

   \[ E[r_{ijk}] = R_{ijk} \mu_{ik} \]

   Read the estimated corrected means.

   #+NAME: read-mean
   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       mean = (pd.read_sql(
         """select gene, ind, mean from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn)
                  .pivot(index='gene', columns='ind', values='mean'))
   #+END_SRC

   #+RESULTS: read-mean
   :RESULTS:
   # Out[16]:
   :END:

   #+RESULTS:
   :RESULTS:
   # Out[207]:
   :END:

   Normalize the mean matrix.

   #+NAME: normalize-mean
   #+BEGIN_SRC ipython
     mean = mean.loc[keep_genes.values.ravel()].transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=0)
   #+END_SRC

   #+RESULTS: normalize-mean
   :RESULTS:
   # Out[17]:
   :END:

   #+RESULTS:
   :RESULTS:
   # Out[208]:
   :END:

   Compute principal components of the mean matrix.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=10).fit(mean).components_, columns=mean.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/mean-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[41]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
    write_pheno_file(mean, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/mean.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[42]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="mean.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45076054

   Run ~qtltools~.

   #+CALL: qtltools(pheno="mean", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov mean-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45076062

   Read the output.

   #+BEGIN_SRC ipython
     mean_qtls = read_qtltools_output('scqtl-mapping/mean')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[135]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/mean-qtl-beta-approx.png
     plot_approx_permutation(mean_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[44]:
   [[file:figure/qtl-mapping.org/mean-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/mean-qtl-qq.png
    qqplot(mean_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[45]:
   [[file:figure/qtl-mapping.org/mean-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     mean_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[46]:
   : 199
   :END:

** Call variance-QTLs

   We have \(r_{ijk} \sim g_{ijk}(\cdot)\), where \(g\) is the ZINB density [[file:zinb.org][as
   previously defined]].

   Fixing individual \(i\), gene \(k\), we can estimate a
   zero-inflation--corrected variance as:

   \[ E[r_{ijk}] = R_{ijk} \mu_{ik} \]

   \[ V[r_{ijk}] = E[r_{ijk}] + \left(E[r_{ijk}]\right)^2 \phi_{ik} \]

   Read the estimated corrected variances.

   #+NAME: read-variance
   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       variance = (pd.read_sql(
         """select gene, ind, var from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn)
                  .pivot(index='gene', columns='ind', values='var'))
   #+END_SRC

   #+RESULTS: read-variance
   :RESULTS:
   # Out[61]:
   :END:

   #+RESULTS:
   :RESULTS:
   # Out[47]:
   :END:

   Normalize the variance matrix.

   #+NAME: normalize-variance
   #+BEGIN_SRC ipython
     variance = variance.loc[keep_genes.values.ravel()].transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=0)
   #+END_SRC

   #+RESULTS: normalize-variance
   :RESULTS:
   # Out[64]:
   :END:

   #+RESULTS:
   :RESULTS:
   # Out[48]:
   :END:

   Compute principal components of the variance matrix.

   #+BEGIN_SRC ipython
     covars = pd.DataFrame(skd.PCA(n_components=2).fit(variance).components_, columns=variance.columns)
     covars.index.name = 'id'
     covars.to_csv('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/variance-covars.txt', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[65]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~.

   #+BEGIN_SRC ipython
     write_pheno_file(variance, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/variance.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[66]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="variance.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45224226

   Run ~qtltools~.

   #+CALL: qtltools(pheno="variance", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--cov variance-covars.txt --window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45224227

   Read the output.

   #+BEGIN_SRC ipython
     variance_qtls = read_qtltools_output('scqtl-mapping/variance')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[67]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/variance-qtl-beta-approx.png
     plot_approx_permutation(variance_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[68]:
   [[file:figure/qtl-mapping.org/variance-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/variance-qtl-qq.png
     qqplot(variance_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[69]:
   [[file:figure/qtl-mapping.org/variance-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     variance_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[70]:
   : 100
   :END:

** Call CV-QTLs

   Estimate the coefficient of variation using the corrected moments.

   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       params = (pd.read_sql(
         """select gene, ind, mean, var from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn))
       params['cv'] = np.sqrt(params['var']) / (params['mean'] + 1e-8)
       cv = params.pivot(index='gene', columns='ind', values='cv')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[55]:
   :END:

   Normalize the CV matrix.

   #+BEGIN_SRC ipython
     cv = cv.loc[keep_genes.values.ravel()].transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=0)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[56]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(cv, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/cv.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[57]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="cv.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45076903

   Run ~qtltools~.

   #+CALL: qtltools(pheno="cv", geno="/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz", op="--window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45076906

   Read the output.

   #+BEGIN_SRC ipython
     cv_qtls = read_qtltools_output('scqtl-mapping/cv')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[26]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/cv-qtl-beta-approx.png
     plot_approx_permutation(cv_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[59]:
   [[file:figure/qtl-mapping.org/cv-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/cv-qtl-qq.png
     qqplot(cv_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[60]:
   [[file:figure/qtl-mapping.org/cv-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     cv_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[61]:
   : 4
   :END:

** Call Fano-QTLs

   Estimate the coefficient of variation using the corrected moments.

   #+BEGIN_SRC ipython
     with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
       params = (pd.read_sql(
         """select gene, ind, mean, var from params where ind in 
         (select chip_id from annotation group by chip_id 
         having count(distinct sample) >= 50);""", conn))
       params['fano'] = params['var'] / (params['mean'] + 1e-8)
       fano = params.pivot(index='gene', columns='ind', values='fano')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[211]:
   :END:

   Normalize the Fano matrix.

   #+BEGIN_SRC ipython
     fano = fano.loc[keep_genes.values.ravel()].transform(lambda x: (x - x.mean()) / x.std(), axis=1).apply(qqnorm, axis=0)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[212]:
   :END:

   Write out the [[https://qtltools.github.io/qtltools/pages/input_files.html][phenotype file]] for ~qtltools~. Hold out even chromosomes while
   optimizing the power to detect eQTLs.

   #+BEGIN_SRC ipython
     write_pheno_file(fano, gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/fano.bed', holdout=False)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[64]:
   :END:

   Index the phenotype file.

   #+CALL: tabix(input="fano.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45077183

   Run ~qtltools~.

   #+CALL: qtltools(pheno="fano", geno="", op="--window 100000 --permute 10000") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

   #+RESULTS:
   : Submitted batch job 45077190

   Read the output.

   #+BEGIN_SRC ipython
     fano_qtls = read_qtltools_output('scqtl-mapping/fano')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[27]:
   :END:

   Check the beta approximation to the permutation p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/fano-qtl-beta-approx.png
     plot_approx_permutation(fano_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[66]:
   [[file:figure/qtl-mapping.org/fano-qtl-beta-approx.png]]
   :END:

   Plot a QQ plot of the adjusted p-values.

   #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/fano-qtl-qq.png
     qqplot(fano_qtls)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[67]:
   [[file:figure/qtl-mapping.org/fano-qtl-qq.png]]
   :END:

   Take QTLs at FDR 10%.

   #+BEGIN_SRC ipython
     fano_qtls['fdr_pass'].sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[68]:
   : 9
   :END:

* Write out the QTLs

  #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping
    sbatch --partition=broadwl
    #!/bin/bash
    cat >.rsync-filter <<EOF
    + */
    + *.bed.gz
    + *.txt.gz
    + *covars*
    - *
    EOF
    function z { test $1-qtl.1.txt -nt $1.txt.gz && cat $1-qtl.*.txt | awk 'BEGIN {print "gene", "chr", "start", "end", "strand", "num_vars", "distance", "id", "var_chr", "var_start", "var_end", "df", "dummy", "a", "b", "p_nominal", "beta", "p_empirical", "p_beta"} {print}' | gzip >$1.txt.gz; }
    export -f z
    parallel -j1 z ::: cv fano log-mean logodds mean phi pooled variance
    rsync -FFau . /project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-mapping/
  #+END_SRC

  #+RESULTS:
  : Submitted batch job 45224360

* QTL overlap
** Replication rates

  Read the QTLs and normalized expression matrices.

  #+BEGIN_SRC ipython
    prefix = '/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-mapping/'
    qtls = {pheno: (pd.read_table('{}/{}.txt.gz'.format(prefix, pheno), sep=' '),
                    pd.read_table('{}/{}.bed.gz'.format(prefix, pheno)).set_index('pid').filter(like='NA', axis='columns'))
            for pheno in ['pooled', 'log_mu', 'log_phi', 'mean', 'variance', 'fano']}
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[123]:
  :END:

  The bulk QTLs are in ~fastqtl~ format and need some munging.

  #+BEGIN_SRC ipython
    bulk_qtls = pd.read_table('{}/bulk.txt.gz'.format(prefix))
    bulk_qtls['var_start'] = bulk_qtls['pos']
    # Important: this collides with the field we're going to add in
    # replication_tests
    del bulk_qtls['p']
    bulk_expr = pd.read_table('{}/bulk.bed.gz'.format(prefix)).set_index('pid').filter(like='NA', axis='columns')
    bulk_expr.index = [x.split('.')[0] for x in bulk_expr.index]
    qtls['bulk'] = (bulk_qtls, bulk_expr)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[124]:
  :END:

  Compute the gene-level FDR filter.

  #+BEGIN_SRC ipython
    for k in qtls:
      qtls[k][0]['fdr_pass'] = bh(qtls[k][0]['p_beta']) < 0.1
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[136]:
  :END:

  Estimate replication rates for mean QTLs.

  #+BEGIN_SRC ipython
    pd.options.display.float_format = '{:.3g}'.format
    pairwise_replication(qtls, phenos=['bulk', 'pooled', 'log_mu', 'mean'], ticks=['Bulk', 'Pooled', '$\log(\mu)$', 'ZI mean'])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[88]:
  #+BEGIN_EXAMPLE
    Bulk  Pooled  $\log(\mu)$  ZI mean
    Bulk          100    80.1         77.2     77.1
    Pooled         82     100          100     99.6
    $\log(\mu)$  80.6    99.5          100      100
    ZI mean      80.1    99.5          100      100
  #+END_EXAMPLE
  :END:

  Estimate the rate at which variance QTLs replicate as mean QTLs (and vice versa).

  #+BEGIN_SRC ipython
    pairwise_replication(qtls,
                         phenos=['bulk', 'pooled', 'log_mu', 'mean', 'log_phi', 'variance', 'fano'],
                         ticks=['Bulk', 'Pooled', '$\log(\mu)$', 'ZI mean', '$\log(\phi)$', 'ZI variance', 'ZI Fano'])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[104]:
  #+BEGIN_EXAMPLE
    $\log(\mu)$  ZI mean  $\log(\phi)$  ZI variance  ZI Fano
    $\log(\mu)$           100      100          43.3         99.5     83.3
    ZI mean               100      100          41.9          100     81.8
    $\log(\phi)$          100      100           100          100      100
    ZI variance           100      100          84.1          100      100
    ZI Fano               100      100           100          100      100
  #+END_EXAMPLE
  :END:

** Relationship of \(p\)-values, effect sizes, and expression levels

  Compute relative abundance per individual.

  #+BEGIN_SRC ipython
    with sqlite3.connect('/project2/mstephens/aksarkar/projects/singlecell-qtl/browser/browser.db') as conn:
      abundance = (pd.read_sql(
        """select gene, ind, log_mu from params where ind in 
        (select chip_id from annotation group by chip_id 
        having count(distinct sample) >= 50);""", conn)
                  .pivot(index='gene', columns='ind', values='log_mu'))
    abundance -= abundance.agg(sp.logsumexp)
    abundance /= np.log(2)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[137]:
  :END:

  Investigate whether variance QTL \(p\)-values are correlated with relative
  abundance.

  #+BEGIN_SRC ipython
    variance_qtls = qtls['variance'][0]
    thresh_pass = variance_qtls['p_beta'] < 1e-2
    var_qtl_abundance, var_qtl_stats = abundance.align(variance_qtls[thresh_pass].set_index('gene'), axis='index', join='inner')
    fdr_pass = var_qtl_stats['fdr_pass']
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[138]:
  :END:

  Count how many variance QTLs have \(p < 10^{-2}\)

  #+BEGIN_SRC ipython
    thresh_pass.sum()
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[139]:
  : 248
  :END:

  #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/var-qtl-vs-log-mu.png
    plt.clf()
    plt.errorbar(x=var_qtl_abundance.mean(axis=1), y=-np.log10(var_qtl_stats['p_beta']), xerr=var_qtl_abundance.std(axis=1), fmt='none', label=None, lw=1, ecolor='.8', zorder=-1)
    plt.scatter(x=var_qtl_abundance[fdr_pass].mean(axis=1), y=-np.log10(var_qtl_stats[fdr_pass]['p_beta']), c='r', s=4, label='FDR 10%')
    plt.scatter(x=var_qtl_abundance[~fdr_pass].mean(axis=1), y=-np.log10(var_qtl_stats[~fdr_pass]['p_beta']), c='k', s=4, label='p < 0.01')
    plt.legend(loc='upper left', frameon=False)
    plt.xlabel('$\log_2(\mathrm{relative\ abundance})$')
    _ = plt.ylabel('Variance QTL $-\log_{10}(p)$')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[82]:
  [[file:figure/qtl-mapping.org/var-qtl-vs-log-mu.png]]
  :END:

  Make sure our effect sizes match ~qtltools~.

  #+BEGIN_SRC ipython
    variance = qtls['variance'][1]
    Xv, Yv = extract_qtl_gene_pair(variance_qtls[thresh_pass], variance, dosages='/scratch/midway2/aksarkar/singlecell/reproduce-yang/YRI_SNPs_2_IPSC.txt.gen.gz')
    Cv = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-mapping/variance-covars.txt', index_col=0)
    Cv = Cv.align(Xv, axis='columns', join='inner')[0]
    my_var_qtl_stats = replication_tests(Xv, Yv, Cv)
    my_var_qtl_stats.merge(variance_qtls, on='gene').apply(lambda x: abs(x['beta_x'] - x['beta_y']), axis=1).describe()
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[83]:
  #+BEGIN_EXAMPLE
    count    248.000000
    mean       0.097948
    std        0.471870
    min        0.000321
    25%        0.022069
    50%        0.054700
    75%        0.089498
    max        7.432064
    dtype: float64
  #+END_EXAMPLE
  :END:

  Look at the gene with max difference in estimated effect size.

  #+BEGIN_SRC ipython
    my_var_qtl_stats.iloc[my_var_qtl_stats.merge(variance_qtls, on='gene').apply(lambda x: abs(x['beta_x'] - x['beta_y']), axis=1).idxmax()]
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[92]:
  #+BEGIN_EXAMPLE
    beta           -103.961
    gene    ENSG00000137285
    p               0.78185
    se              375.433
    Name: 200, dtype: object
  #+END_EXAMPLE
  :END:

  #+BEGIN_SRC ipython
    variance_qtls.query('gene == "ENSG00000137285"')['beta']
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[93]:
  #+BEGIN_EXAMPLE
    953   -111.393
    Name: beta, dtype: float64
  #+END_EXAMPLE
  :END:

  Estimate standard errors via the bootstrap.

  #+BEGIN_SRC ipython
    var_qtl_stats['bootstrap_se'] = bootstrap_se(Xv, Yv, Cv)
    var_qtl_stats['se'] = my_var_qtl_stats.set_index('gene')['se']
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[162]:
  :END:

  Investigate whether analytic SEs are reasonable:

  #+BEGIN_SRC ipython
    var_qtl_stats['se'].describe()
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[147]:
  #+BEGIN_EXAMPLE
    count    248.000000
    mean       1.561811
    std       23.836989
    min        0.009998
    25%        0.025567
    50%        0.035241
    75%        0.055008
    max      375.432921
    Name: se, dtype: float64
  #+END_EXAMPLE
  :END:

  #+BEGIN_SRC ipython
    var_qtl_stats['bootstrap_se'].describe()
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[176]:
  #+BEGIN_EXAMPLE
    count    247.000000
    mean       0.267170
    std        0.888356
    min        0.094744
    25%        0.158373
    50%        0.187001
    75%        0.238489
    max       14.088750
    Name: bootstrap_se, dtype: float64
  #+END_EXAMPLE
  :END:

  Throw out the gene with abnormally large SE.

  #+BEGIN_SRC ipython
    var_qtl_stats.loc[var_qtl_stats['se'].idxmax()]
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[163]:
  #+BEGIN_EXAMPLE
    chr                               chr6
    start                          3231965
    end                            3231964
    strand                               -
    num_vars                           960
    distance                        -88595
    id              rs4959814.chr6.3320559
    var_chr                           chr6
    var_start                  3.32056e+06
    var_end                    3.32056e+06
    df                                  49
    dummy                          33.4195
    a                             0.888297
    b                              58.8358
    p_nominal                  9.04449e-07
    beta                          -111.393
    p_empirical                 0.00259974
    p_beta                        0.006076
    fdr_pass                         False
    bootstrap_se                   24.2859
    se                             375.433
    Name: ENSG00000137285, dtype: object
  #+END_EXAMPLE
  :END:

  #+BEGIN_SRC ipython
    var_qtl_stats.loc[var_qtl_stats['bootstrap_se'].idxmax()]
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[177]:
  #+BEGIN_EXAMPLE
    chr                               chr17
    start                           2415186
    end                             2415185
    strand                                -
    num_vars                            578
    distance                         -20240
    id              rs7215976.chr17.2435425
    var_chr                           chr17
    var_start                   2.43542e+06
    var_end                     2.43542e+06
    df                                   49
    dummy                           32.9984
    a                              0.947312
    b                               39.0474
    p_nominal                   5.20528e-06
    beta                           -3.07316
    p_empirical                  0.00909909
    p_beta                       0.00983825
    fdr_pass                          False
    bootstrap_se                    14.0888
    se                             0.356516
    z                             -0.218129
    mean_beta                      -2.50384
    mean_z                        -0.378847
    Name: ENSG00000127804, dtype: object
  #+END_EXAMPLE
  :END:

  #+BEGIN_SRC ipython
    var_qtl_stats = var_qtl_stats.dropna().drop('ENSG00000137285')
    fdr_pass = var_qtl_stats['fdr_pass']
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[164]:
  :END:

  #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/var-qtl-se.png
    plt.clf()
    plt.gcf().set_size_inches(4, 4)
    plt.scatter(var_qtl_stats['se'], var_qtl_stats['bootstrap_se'], s=1, c='k')
    plt.plot([0, 2], [0, 2], c='r', ls=':', lw=1)
    plt.xlim([0, 2])
    plt.ylim([0, 2])
    plt.xlabel('Analytic SE')
    _ = plt.ylabel('Bootstrap SE')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[165]:
  [[file:figure/qtl-mapping.org/var-qtl-se.png]]
  :END:

  Compute \(z\)-scores using the bootstrap SEs.

  #+BEGIN_SRC ipython
    var_qtl_stats['z'] = var_qtl_stats['beta'] / var_qtl_stats['bootstrap_se']
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[166]:
  :END:

  Investigate whether \(z\)-scores based on bootstrap SEs agree with
  permutation \(p\)-values.

  #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/var-qtl-z.png
    plt.clf()
    plt.scatter(-np.log10(var_qtl_stats[fdr_pass]['p_beta']), var_qtl_stats[fdr_pass]['z'], c='r', label='FDR 10%', s=4)
    plt.scatter(-np.log10(var_qtl_stats[~fdr_pass]['p_beta']), var_qtl_stats[~fdr_pass]['z'], c='k', label='p < 0.01', s=4)
    plt.xlabel('Variance QTL $-\log_{10}(p)$')
    plt.ylabel('Variance QTL $z$-score')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[167]:
  : Text(0,0.5,'Variance QTL $z$-score')
  [[file:figure/qtl-mapping.org/var-qtl-z.png]]
  :END:

  Investigate whether variance QTL \(z\)-scores are correlated with relative
  abundance.

  #+BEGIN_SRC ipython
    var_qtl_abundance = var_qtl_abundance.align(var_qtl_stats, axis='index', join='inner')[0]
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[169]:
  :END:

  #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/var-qtl-z-vs-log-mu.png
    plt.clf()
    plt.errorbar(x=var_qtl_abundance.mean(axis=1), y=var_qtl_stats['z'], xerr=var_qtl_abundance.std(axis=1), fmt='none', label=None, lw=1, ecolor='.8', zorder=1)
    plt.scatter(x=var_qtl_abundance[fdr_pass].mean(axis=1), y=var_qtl_stats[fdr_pass]['z'], c='r', s=2, label='FDR 10%', zorder=2)
    plt.scatter(x=var_qtl_abundance[~fdr_pass].mean(axis=1), y=var_qtl_stats[~fdr_pass]['z'], c='k', s=2, label='p < 0.01', zorder=2)
    plt.legend(frameon=False)
    plt.axhline(y=0, c='k')
    plt.xlabel('$\log_2(\mathrm{relative\ abundance})$')
    _ = plt.ylabel('Variance QTL $z$-score')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[170]:
  [[file:figure/qtl-mapping.org/var-qtl-z-vs-log-mu.png]]
  :END:

  Investigate whether variance QTL \(z\)-scores are correlated with pooled QTL
  \(z\)-scores.

  #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/var-qtl-vs-log-mu.png
    Xm, Ym = extract_qtl_gene_pair(variance_qtls[thresh_pass], qtls['pooled'][1], dosages='/scratch/midway2/aksarkar/singlecell/reproduce-yang/YRI_SNPs_2_IPSC.txt.gen.gz')
    Cm = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-mapping/pooled-covars.txt')
    Cm = Cm.align(Xm, axis='columns', join='inner')[0]
    var_qtl_stats['mean_beta'] = replication_tests(Xm, Ym, Cm).set_index('gene')['beta']
    var_qtl_stats['mean_z'] = var_qtl_stats['mean_beta'] / bootstrap_se(Xm, Ym, Cm)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[171]:
  :END:

  #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/var-qtl-vs-mean-qtl.png
    lim = [-12, 12]
    plt.clf()
    plt.gcf().set_size_inches(6, 6)
    plt.plot(lim, lim, c='r', ls=':', lw=1)
    plt.scatter(var_qtl_stats[fdr_pass]['z'], var_qtl_stats[fdr_pass]['mean_z'], c='r', s=3, label='FDR 10%')
    plt.scatter(var_qtl_stats[~fdr_pass]['z'], var_qtl_stats[~fdr_pass]['mean_z'], c='k', s=3, label='Permuted p < 0.01')
    plt.legend()
    plt.axhline(y=0, c='k', lw=1)
    plt.axvline(x=0, c='k', lw=1)
    plt.xlim(lim)
    plt.ylim(lim)
    plt.xlabel('Variance QTL $z$-score')
    _ = plt.ylabel('Pooled QTL $z$-score')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[178]:
  [[file:figure/qtl-mapping.org/var-qtl-vs-mean-qtl.png]]
  :END:

** Predicting mean QTLs from variance QTLs

  As we change the threshold for calling variance QTLs, track the precision and
  recall of mean QTLs (at the gene level).

  #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/var-qtl-mean-qtl-prc.png
    Y, P = qtls['pooled'][0]['fdr_pass'].align(qtls['variance'][0]['p_beta'].dropna(), join='inner')
    p, r, _ = sklearn.metrics.precision_recall_curve(Y.astype(int), -np.log(P))
    plt.clf()
    plt.gcf().set_size_inches(4, 4)
    plt.plot(r[::10], p[::10], lw=1, c='k')
    plt.xlabel('Recall of mean QTLs')
    _ = plt.ylabel('Precision of mean QTLs')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[218]:
  [[file:figure/qtl-mapping.org/var-qtl-mean-qtl-prc.png]]
  :END:

  Track sensitivity and specificity of mean QTLs.

  #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/var-qtl-mean-qtl-roc.png
    fpr, tpr, _ = sklearn.metrics.roc_curve(Y.astype(int), -np.log(P))
    plt.clf()
    plt.gcf().set_size_inches(4, 4)
    plt.plot(fpr[::10], tpr[::10], lw=1, c='k')
    plt.xlabel('False positive rate of mean QTLs')
    _ = plt.ylabel('True positive rate of mean QTLs')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[219]:
  [[file:figure/qtl-mapping.org/var-qtl-mean-qtl-roc.png]]
  :END:

  As we change the threshold for calling pooled QTLs, track the precision and
  recall of variance QTLs (at the gene level).

  #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/pooled-qtl-var-qtl-prc.png
    Y, P = qtls['variance'][0]['fdr_pass'].align(qtls['pooled'][0]['p_beta'].dropna(), join='inner')
    p, r, _ = sklearn.metrics.precision_recall_curve(Y.astype(int), -np.log(P))
    plt.clf()
    plt.gcf().set_size_inches(4, 4)
    plt.plot(r[::10], p[::10], lw=1, c='k')
    plt.xlabel('Recall of variance QTLs')
    _ = plt.ylabel('Precision of variance QTLs')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[220]:
  [[file:figure/qtl-mapping.org/pooled-qtl-var-qtl-prc.png]]
  :END:
  
  Track sensitivity and specificity of variance QTLs.

  #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/pooled-qtl-var-qtl-roc.png
    fpr, tpr, _ = sklearn.metrics.roc_curve(Y.astype(int), -np.log(P))
    plt.clf()
    plt.gcf().set_size_inches(4, 4)
    plt.plot(fpr[::10], tpr[::10], lw=1, c='k')
    plt.xlabel('False positive rate of variance QTLs')
    _ = plt.ylabel('True positive rate of variance QTLs')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[222]:
  [[file:figure/qtl-mapping.org/pooled-qtl-var-qtl-roc.png]]
  :END:

** Multivariate adaptive shrinkage

  Write out a subset of the phenotype matrix to get SNP-level summary stats for
  ~mash~.

  #+BEGIN_SRC ipython
    write_pheno_file(qtls['variance'][1].filter(items=qtls['variance'][0][qtls['variance'][0][thresh_pass]]['gene'], axis='index'),
                     gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/variance-fdr-pass.bed', holdout=False)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[194]:
  :END:

  Index the phenotype file.

  #+CALL: tabix(input="variance-fdr-pass.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

  #+RESULTS:
  : Submitted batch job 45224858

  Run the nominal pass.

  #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping :eval never-export 
    sbatch --partition=broadwl --mem=8G --wait
    #!/bin/bash
    source activate scqtl
    qtltools cis --vcf /scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz --bed variance-fdr-pass.bed.gz --cov variance-covars.txt --window 100000 --nominal 1 --out variance-fdr-pass-nominal.txt
  #+END_SRC

  #+RESULTS:
  : Submitted batch job 45224965

  Compute \(\hat\beta\) and bootstrap SE ourselves to check whether we can
  simply inverse CDF transform from the nominal \(p\)-values.

  #+BEGIN_SRC ipython
    test_var_qtl_stats = estimate_beta_se(Yv.head(n=1), '/scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz', gene_info, Cv)
    test_var_qtl_stats['z'] = test_var_qtl_stats['beta'] / test_var_qtl_stats['se']
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[206]:
  :END:

  Read the results.

  #+BEGIN_SRC ipython
    nominal_var_qtl_stats = read_nominal_pass('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/variance-fdr-pass-nominal.txt')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[141]:
  :END:

  Check our \(z\)-scores against inverse CDF-derived \(z\)-scores.

  #+BEGIN_SRC ipython
    M = test_var_qtl_stats.merge(nominal_var_qtl_stats, left_on=['gene', 'snp'], right_on=['gene', 'id'])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[234]:
  :END:

  #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/bootstrap-z-vs-nominal-p-inverse-cdf.png
    plt.clf()
    plt.gcf().set_size_inches(4, 4)
    lim = [-6, 6]
    plt.scatter(M['z_x'], M['z_y'], c='k', s=3)
    plt.axhline(y=0, c='k', lw=1)
    plt.axvline(x=0, c='k', lw=1)
    plt.plot(lim, lim, c='r', ls=':', lw=1)
    plt.xlim(lim)
    plt.ylim(lim)
    plt.xlabel('Bootstrap $z$ scores')
    _ = plt.ylabel('Inverse CDF $z$ scores')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[235]:
  [[file:figure/qtl-mapping.org/bootstrap-z-vs-nominal-p-inverse-cdf.png]]
  :END:

  Subset the pooled expression matrix at the variance QTL genes.

  #+BEGIN_SRC ipython
    write_pheno_file(qtls['pooled'][1].filter(items=qtls['variance'][0][qtls['variance'][0]['fdr_pass']]['gene'], axis='index'),
                     gene_info, '/scratch/midway2/aksarkar/singlecell/scqtl-mapping/pooled-fdr-pass.bed', holdout=False)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[236]:
  :END:

  Index the phenotype file.

  #+CALL: tabix(input="pooled-fdr-pass.bed") :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping

  #+RESULTS:
  : Submitted batch job 45224966

  Run the nominal pass.

  #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping :eval never-export 
    sbatch --partition=broadwl --mem=4G --wait
    #!/bin/bash
    source activate scqtl
    qtltools cis --vcf /scratch/midway2/aksarkar/singlecell/reproduce-yang/yri-dosages.vcf.gz --bed pooled-fdr-pass.bed.gz --cov pooled-covars.txt --window 100000 --nominal 1 --out pooled-fdr-pass-nominal.txt
  #+END_SRC

  #+RESULTS:
  : Submitted batch job 45224967

  Read the results

  #+BEGIN_SRC ipython
    nominal_pooled_qtl_stats = read_nominal_pass('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/pooled-fdr-pass-nominal.txt')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[142]:
  :END:

  Run two-condition ~mash~.

  #+BEGIN_SRC ipython
    Z = nominal_var_qtl_stats.merge(nominal_pooled_qtl_stats, on=['gene', 'id'])[['gene', 'z_x', 'z_y']].set_index('gene')
    mash_result = {}
    for k, g in Z.groupby(level=0):
      data = mashr.mash_set_data(numpy2ri(g.values), numpy2ri(np.ones(g.shape)))
      U = mashr.cov_canonical(data)
      mash_result[k] = mashr.mash(data, U, verbose=False)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[238]:
  :END:

  Recover the estimated mixture weights.

  #+BEGIN_SRC ipython
    pihat = pd.DataFrame.from_dict({k: np.array(mashr.get_estimated_pi(v)) for k, v in mash_result.items()}).T
    pihat.columns = ['pointmass'] + list(U.names)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[239]:
  :END:

  Plot the distribution of mixture weights over all genes.

  #+BEGIN_SRC ipython
    pihat.describe()
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[254]:
  #+BEGIN_EXAMPLE
    pointmass      identity  singletons_1  singletons_2  equal_effects  \
    count  100.000000  1.000000e+02  1.000000e+02  1.000000e+02     100.000000
    mean     0.236113  1.440518e-08  7.370024e-04  1.325172e-08       0.763150
    std      0.171014  2.923391e-08  7.369911e-03  2.542430e-08       0.170895
    min      0.025428  1.255758e-16  0.000000e+00  1.554074e-13       0.331600
    25%      0.086583  9.203208e-11  6.397202e-11  1.579286e-10       0.658428
    50%      0.192531  8.103858e-10  8.467295e-10  9.780927e-10       0.803813
    75%      0.341572  9.041796e-09  1.336859e-08  1.140590e-08       0.913417
    max      0.668400  1.577300e-07  7.369912e-02  1.242829e-07       0.974572

    simple_het_1  simple_het_2  simple_het_3
    count  1.000000e+02  1.000000e+02  1.000000e+02
    mean   9.991417e-09  1.350293e-08  1.403216e-08
    std    2.232040e-08  4.009257e-08  3.783770e-08
    min    6.954820e-14  0.000000e+00  0.000000e+00
    25%    6.905415e-11  5.008974e-11  5.619386e-11
    50%    5.612049e-10  4.565214e-10  7.012256e-10
    75%    7.695997e-09  6.202010e-09  8.381193e-09
    max    1.208672e-07  3.013986e-07  2.835197e-07
  #+END_EXAMPLE
  :END:

  #+BEGIN_SRC ipython :ipyfile figure/qtl-mapping.org/mash-mean-var.png
    plt.clf()
    grid = np.linspace(0, 1, 100)
    for k, v in {'pointmass': 'Point mass', 'equal_effects': 'Equal effects'}.items():
      f = st.gaussian_kde(pihat[k])
      plt.plot(grid, f(grid), label=v, lw=1)
    plt.legend()
    plt.xlabel('Mixture proportion')
    plt.ylabel('Density')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[268]:
  : Text(0,0.5,'Density')
  [[file:figure/qtl-mapping.org/mash-mean-var.png]]
  :END:
