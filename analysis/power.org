#+TITLE: Power to detect QTLs in single cell data
#+SETUPFILE: setup.org

* Introduction

  We [[file:qtl-mapping.org][previously found]] that our study lost power to detect eQTLs, and was
  underpowered to directly detect dispersion-QTLs.

  Here, we estimate power to detect eQTLs and dispersion-QTLs as a function of:

  - number of cells per individual
  - number of molecules per cell
  - number of individuals

* Setup                                                            :noexport:
 
 #+BEGIN_SRC emacs-lisp
    (org-babel-lob-ingest "~/.emacs.d/org-templates/library.org")
    (org-babel-lob-ingest "/project2/mstephens/aksarkar/projects/singlecell-qtl/analysis/zinb.org")
  #+END_SRC

  #+RESULTS:
  : 18

  #+CALL: ipython3(memory="4G", venv="scqtl")

  #+RESULTS:
  : Submitted batch job 46371363

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])

    import collections
    import colorcet
    import gzip
    import io
    import matplotlib.pyplot as plt
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[1]:
  :END:

  #+NAME: power-imports
  #+BEGIN_SRC ipython
    import multiprocessing as mp
    import numpy as np
    import pandas as pd
    import scipy.optimize as so
    import scipy.stats as st
    import tabix
  #+END_SRC

  #+RESULTS: power-imports
  :RESULTS:
  # Out[2]:
  :END:

* Differential dispersion

  Perform a nested model comparison for each gene \(k\), comparing the model:

  \[ r_{ijk} \sim ZINB(\pi_{ik}, \mu_{ik}, \phi_{ik}) \]

  against the model:

  \[ r_{ijk} \sim ZINB(\pi_{ik}, \mu_{ik}, \phi_{i}) \]

  #+NAME: lrt-impl
  #+BEGIN_SRC ipython :eval never
    def lrt(umi, onehot, design, size_factor):
      _, _, _, llik0 = fit(
        umi=umi.values.T.astype(np.float32),
        onehot=onehot.astype(np.float32),
        design=design.astype(np.float32),
        size_factor=size_factor.astype(np.float32),
        fit_null=True,
        return_llik=True,
        learning_rate=5e-2,
        max_epochs=4000)
      _, _, _, llik1 = fit(
        umi=umi.values.T.astype(np.float32),
        onehot=onehot.astype(np.float32),
        design=design.astype(np.float32),
        size_factor=size_factor.astype(np.float32),
        return_llik=True,
        learning_rate=5e-2,
        max_epochs=4000)
      T = 2 * (llik1 - llik0)
      return T, st.chi2(1).logsf(T)
  #+END_SRC

** Null calibration via parametric bootstrap

   Sample null data from the model, using empirical estimates of the parameters
   in the observed data.

   #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/singlecell-qtl/code/tf-lrt-null-parametric.py
     <<zinb-imports>>
     <<tf-imports>>
     <<tf-zinb-impl>>
     <<lrt-impl>>
     <<sim-impl>>

     log_mu = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/density-estimation/design1/zi2-log-mu.txt.gz', index_col=0, sep=' ')
     log_phi = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/density-estimation/design1/zi2-log-phi.txt.gz', index_col=0, sep=' ')
     logodds = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/density-estimation/design1/zi2-log-mu.txt.gz', index_col=0, sep=' ')
     params = pd.DataFrame({'log_mu': log_mu['NA18507'],
                            'log_phi': log_phi['NA18507'],
                            'logodds': logodds['NA18507']},
                           index=log_mu.index)
     params = params[params['log_mu'] > -10]
     n = 100
     umi = pd.DataFrame([simulate(2 * n, size=1e5, log_mu=log_mu, log_phi=log_phi, logodds=logodds)[0][:,0]
                         for _, (log_mu, log_phi, logodds) in params.iterrows() if log_mu > -10], index=params.index)
     onehot = np.zeros((2 * n, 2))
     onehot[:n,0] = 1
     onehot[n:,1] = 1
     design = np.zeros((2 * n, 1))
     size_factor = 1e5 * np.ones((2 * n, 1))
     T, P = lrt(umi, onehot, design, size_factor)
     pd.DataFrame({'chi2': T, 'logp': P}, index=umi.index).to_csv('null-calibration-p.txt.gz', sep='\t', compression='gzip')
   #+END_SRC

   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/power/
     sbatch --partition=gpu --gres=gpu:1 --mem=16G --job-name=tf-lrt-null --output=tf-lrt-null-parametric.out
     #!/bin/bash
     source activate scqtl
     python /project2/mstephens/aksarkar/projects/singlecell-qtl/code/tf-lrt-null-parametric.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 46322399

   Read the results.

   #+BEGIN_SRC ipython
     null_lrt = pd.read_table('/scratch/midway2/aksarkar/singlecell/power/null-calibration-p.txt.gz')
     N = null_lrt.shape[0]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[2]:
   :END:

   Report how many genes were simulated.

   #+BEGIN_SRC ipython
     N
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[3]:
   : 1832
   :END:

   Estimate bootstrap CIs for the quantiles.

   #+BEGIN_SRC ipython
     B = np.sort(st.chi2(1).rvs((N, 100)), axis=0)
     ci = np.percentile(B, [2.5, 97.5], axis=1)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[18]:
   :END:

   Plot the QQ-plot.

   #+BEGIN_SRC ipython :ipyfile figure/power.org/null-calibration-p.png
     plt.clf()
     plt.gcf().set_size_inches(4, 4)
     grid = st.chi2(1).ppf(np.linspace(0, 1 - 1 / N, N))
     plt.scatter(grid, null_lrt['chi2'].sort_values(), c='k', s=2)
     plt.fill_between(grid, ci[0], ci[1], color='k', alpha=0.1)
     lim = [0, 1.01 * grid.max()]
     plt.plot(lim, lim, c='r', lw=1)
     plt.xlim(lim)
     plt.xlabel('Expected $\chi^2$ statistic')
     _ = plt.ylabel('Observed $\chi^2$ statistic')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[40]:
   [[file:figure/power.org/null-calibration-p.png]]
   :END:

** Null calibration via nonparametric bootstrap                    :noexport:

   Assuming the true single cells all came from one individual, generate new
   single cells by sampling counts for each gene iid. with replacement. This
   method assumes genes are independent, which is justified only if we perform
   analysis one gene at a time.

   #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/singlecell-qtl/code/tf-lrt-null.py
     <<zinb-imports>>
     <<tf-imports>>
     <<tf-zinb-impl>>
     <<lrt-impl>>

     def downsample_counts(umi, size_factor, num_mols):
       """Return a downsampled matrix of UMI counts

       This is needed so that every cell has the same number of molecules in
       expectation

       """
       p = num_mols / size_factor
       assert (p <= 1).all()
       return umi.apply(lambda x: np.random.binomial(x, p), axis=1)

     def sample_cells(umi, n=1):
       """Return a sampled matrix of UMI counts

       Assume the input matrix is UMI for a single individal. Sample gene counts
       i.i.d. from the empirical distribution of counts

       """
       result = np.zeros((umi.shape[0], n))
       for i, row in enumerate(umi.values):
         result[i] = np.random.choice(row, size=n, replace=True)
       return pd.DataFrame(result, index=umi.index)

     <<read-data-qc-impl>>
     log_mu = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/density-estimation/design1/zi2-log-mu.txt.gz', index_col=0, sep=' ')
     keep_cells = np.logical_and(
       annotations['chip_id'] == 'NA18507',
       annotations['mol_hs'] > 1e5,
     )
     umi = umi.loc[log_mu['NA18507'] >= -10,keep_cells.values]

     # Generate counts at equal number of molecules (to simplify bootstrapping)
     np.random.seed(1)
     umi = downsample_counts(umi, annotations['mol_hs'], 1e5)

     # Generate two groups under the null
     n = 100
     umi = sample_cells(umi, n=2 * n)
     onehot = np.zeros((2 * n, 2))
     onehot[:n,0] = 1
     onehot[n:,1] = 1
     design = np.zeros((2 * n, 1))
     size_factor = num_mols.min() * np.ones((2 * n, 1))

     T, P = lrt(umi, onehot, design, size_factor)
     pd.DataFrame({'chi2': T, 'logp': P}, index=umi.index).to_csv('null-calibration.txt.gz', sep='\t', compression='gzip')
   #+END_SRC

   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/power/
     sbatch --partition=gpu --gres=gpu:1 --mem=16G --job-name=tf-lrt-null --output=tf-lrt-null.out
     #!/bin/bash
     source activate scqtl
     python /project2/mstephens/aksarkar/projects/singlecell-qtl/code/tf-lrt-null.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 46323093

   Plot the QQ-plot.

   #+BEGIN_SRC ipython :ipyfile figure/power.org/null-calibration.png
     null_lrt = pd.read_table('/scratch/midway2/aksarkar/singlecell/power/null-calibration.txt.gz')
     N = null_lrt.shape[0]
     plt.clf()
     plt.gcf().set_size_inches(4, 4)
     plt.scatter(st.chi2(1).ppf(np.linspace(0, 1 - 1 / N, N)), null_lrt['chi2'].sort_values(), c='k', s=2, alpha=0.25)
     lim = [0, 1.1 * null_lrt['chi2'].max()]
     plt.plot(lim, lim, c='r', ls=':', lw=1)
     plt.xlim(lim)
     plt.ylim(lim)
     plt.xlabel('Expected chi-square statistic')
     _ = plt.ylabel('Observed chi-square statistic')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   [[file:figure/power.org/null-calibration.png]]
   :END:

** Power

   Sample from the assumed model.

   #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/singlecell-qtl/code/tf-lrt-power.py
     <<zinb-imports>>
     <<tf-imports>>
     <<tf-zinb-impl>>
     <<lrt-impl>>
     <<sim-impl>>

     log_mu = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/density-estimation/design1/zi2-log-mu.txt.gz', index_col=0, sep=' ')
     log_phi = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/density-estimation/design1/zi2-log-phi.txt.gz', index_col=0, sep=' ')
     logodds = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/density-estimation/design1/zi2-log-mu.txt.gz', index_col=0, sep=' ')
     params = pd.DataFrame({'log_mu': log_mu['NA18507'],
                            'log_phi': log_phi['NA18507'],
                            'logodds': logodds['NA18507']},
                           index=log_mu.index)
     params = params[params['log_mu'] > -10].sample(n=50)

     sample_sizes = np.geomspace(1e2, 1e5, 5).astype(int)
     log_fold_changes = np.log(np.geomspace(1.1, 2, 5))
     depths = np.geomspace(1e4, 1e6, 5)

     result = []
     for num_mols in depths:
       for log_fc in log_fold_changes:
         for num_samples in sample_sizes:
           umi = []
           for _, (log_mu, log_phi, logodds) in params.iterrows():
             umi.append(np.hstack([
               simulate(num_samples, size=num_mols, log_mu=log_mu, log_phi=log_phi, logodds=logodds)[0][:,0],
               simulate(num_samples, size=num_mols, log_mu=log_mu, log_phi=log_phi + log_fc, logodds=logodds)[0][:,0]
             ]))
           umi = pd.DataFrame(umi, index=params.index)
           onehot = np.zeros((umi.shape[1], 2))
           onehot[:num_samples,0] = 1
           onehot[num_samples:,1] = 1
           design = np.zeros((umi.shape[1], 1))
           size_factor = num_mols * np.ones((umi.shape[1], 1))
           T, P = lrt(umi, onehot, design, size_factor)
           result.append(pd.DataFrame({
             'num_mols': num_mols,
             'num_samples': num_samples,
             'log_fold_change': log_fc,
             'chi2': T,
             'logp': P}))
     pd.concat(result).to_csv('lrt-power.txt.gz', sep='\t', compression='gzip') 
   #+END_SRC

   #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/power/
     sbatch --partition=gpu --gres=gpu:1 --mem=16G --job-name=tf-lrt-power --output=tf-lrt-power.out
     #!/bin/bash
     source activate scqtl
     python /project2/mstephens/aksarkar/projects/singlecell-qtl/code/tf-lrt-power.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 46367157

   #+BEGIN_SRC sh
     sacct -j 46367157 -o Elapsed
   #+END_SRC

   #+RESULTS:
   :    Elapsed 
   : ---------- 
   :   06:59:58 
   :   06:59:58 
   :   06:59:58 

   Move the results to permanent storage.

   #+BEGIN_SRC sh
     rsync -FFau /scratch/midway2/aksarkar/singlecell/power /project2/mstephens/aksarkar/projects/singlecell-qtl/data/power/
   #+END_SRC

   #+RESULTS:

   Read the results.

   #+BEGIN_SRC ipython
     lrt_results = (pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/power/lrt-power.txt.gz', index_col=0)
                  .reindex())
     features = ['num_mols', 'num_samples', 'log_fold_change']
     lrt_power = (lrt_results
                  .groupby(features)
                  .apply(lambda x: (np.exp(x['logp']) < 0.05).sum() / x.shape[0])
                  .to_frame()
                  .reset_index())
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[46]:
   :END:

   Plot the results.

   #+BEGIN_SRC ipython :ipyfile figure/power.org/lrt-power.png
     plt.clf()
     plt.gcf().set_size_inches(4, 4)
     num_mols = 1e5
     grid = np.log(np.linspace(1.1, 2, 100))
     groups = sorted(set(lrt_power['num_samples']))
     for i, n in enumerate(groups):
       color = colorcet.cm['inferno']((i + 1 / (2 * len(groups))) / len(groups))
       subset = lrt_power[np.logical_and(lrt_power['num_mols'] == num_mols, lrt_power['num_samples'] == n)]
       plt.plot(np.exp(subset['log_fold_change']), subset[0], lw=1, marker='.', ms=8, c=color,
                label='$10^{{{:.1f}}}$'.format(np.log(n) / np.log(10)))
     plt.legend(title='# samples', frameon=False, loc='center left', bbox_to_anchor=(1, .5))
     plt.xlabel('Fold change in dispersion')
     plt.ylabel('Power at level 0.05')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[83]:
   : Text(0,0.5,'Power at level 0.05')
   [[file:figure/power.org/lrt-power.png]]
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/power.org/lrt-power-fixed-samples.png
     plt.clf()
     plt.gcf().set_size_inches(4, 4)
     num_samples = 100
     groups = sorted(set(lrt_power['num_mols']))
     for i, n in enumerate(groups):
       color = colorcet.cm['inferno']((i + 1 / (2 * len(groups))) / len(groups))
       subset = lrt_power[np.logical_and(lrt_power['num_mols'] == n, lrt_power['num_samples'] == num_samples)]
       plt.plot(np.exp(subset['log_fold_change']), subset[0], lw=1, marker='.', ms=8, c=color, label='$10^{{{:.1f}}}$'.format(np.log(n) / np.log(10)))
     plt.legend(title='# molecules', frameon=False, loc='center left', bbox_to_anchor=(1, .5))
     plt.xlabel('Fold change in dispersion')
     plt.ylabel('Power at level 0.05')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[87]:
   : Text(0,0.5,'Power at level 0.05')
   [[file:figure/power.org/lrt-power-fixed-samples.png]]
   :END:

* eQTL discovery

  We assume expression is generated from \(m\) causal effects (out of \(p\)
  variants) following a linear model:

  \[ \ln\mu_i = \sum_j X_{ij} \beta_j + \epsilon_i \]

  \[ \mathbb{E}[x_i] = 0, \mathbb{V}[x_i] = 1 \]

  \[ \beta_j \sim N(0, h^2 / m) \text{if \(j\) causal}\]

  \[ \epsilon_i \sim N(0, 1 - h^2) \]

  #+NAME: eqtl-sim-impl
  #+BEGIN_SRC ipython
    def read_dosage(row, dose_file, window=100000):
      x = np.array([record[9:] for record in dose_file.query(row['chr'], row['start'] - window, row['start'] + window)]).astype(np.float).T
      x -= x.mean(axis=0)
      x /= x.std(axis=0)
      return x

    def generate_pheno(x, pve, m=1):
      n, p = x.shape
      theta = np.zeros(p)
      # Assume x standardized
      theta[np.random.choice(p, m, replace=False)] = np.random.normal(size=m)
      y = x.dot(theta)
      y += np.random.normal(scale=np.sqrt(y.var() * (1 / pve - 1)), size=n)
      return y.reshape(-1, 1)

    _sf = st.chi2(1).sf

    def nominal_test(x, y):
      n = y.shape[0]
      # Assume x standardized, so diag(X' X) = n I
      beta = x.T.dot(y) / n
      df = n - 1
      rss = ((y ** 2).sum() - beta ** 2 * n)
      sigma2 = rss / df
      return _sf(beta ** 2 / sigma2)

    def beta_llik(theta, x):
      return -st.beta.logpdf(x, *theta).mean()

    def permutation_test(x, y, num_trials=100):
      pval = nominal_test(x, y).min()
      null_pheno = y.copy()
      null_pvals = []
      for _ in range(num_trials):
        np.random.shuffle(null_pheno)
        null_pvals.append(nominal_test(x, null_pheno).min())
      null_pvals = np.array(null_pvals)
      theta = np.ones(2)
      opt = so.minimize(beta_llik, x0=theta, args=(null_pvals,))
      if opt.success:
        theta = opt.x
      else:
        # Method of moments
        theta = np.array([1, (1 / null_pvals.mean() - 1)])
        theta *= np.square(null_pvals.mean()) * ((1 - null_pvals.mean()) / null_pvals.var() - 1)
      return st.beta.cdf(pval, *theta)

    # Important: tabix read doesn't appear to be thread-safe
    read_lock = mp.Lock()

    def evaluate(num_individuals, num_causal, pve, num_genes=100):
      query = eqtls.sample(n=num_genes)
      result = []
      for _, record in query.iterrows():
        read_lock.acquire()
        try:
          x = read_dosage(record, yri)
        finally:
          read_lock.release()
        keep = np.random.choice(x.shape[0], num_individuals, replace=False)
        x = x[keep]
        y = generate_pheno(x, pve=pve, m=num_causal)
        pval = permutation_test(x, y)
        result.append({
          'gene': record.name,
          'num_individuals': x.shape[0],
          'num_snps': x.shape[1],
          'num_causal': num_causal,
          'pve': pve,
          'pval': pval})
      return pd.DataFrame.from_dict(result)
  #+END_SRC

  #+RESULTS: eqtl-sim-impl
  :RESULTS:
  # Out[3]:
  :END:

  Re-QC dosages for 120 YRI individuals.

  #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/scqtl-mapping
    sbatch --partition=broadwl --job-name=reprocess-dosage --out=reprocess-dosage.out
    #!/bin/bash
    set -e
    source activate scqtl
    python /project2/mstephens/aksarkar/projects/singlecell-qtl/code/reprocess-dosage.py
    bgzip dosages.vcf
    tabix dosages.vcf.gz
  #+END_SRC

  #+RESULTS:
  : Submitted batch job 46369493

  Run the power calculation on 28 CPUs.

  #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/singlecell-qtl/code/eqtl-power.py
    <<power-imports>>
    <<eqtl-sim-impl>>

    yri = tabix.open('/scratch/midway2/aksarkar/singlecell/scqtl-mapping/dosages.vcf.gz')
    # Restrict to genes where we previously successfully mapped eQTLs
    eqtls = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-mapping/pooled.txt.gz', sep=' ', index_col=0).dropna()

    args = [(n, m, pve)
            for n in (53, 75, 100, 120)
            for m in (1, 2, 3)
            for pve in np.geomspace(.01, 0.5, 5)]

    np.random.seed(0)
    with mp.Pool() as pool:
      result = pool.starmap(evaluate, args)
    pd.concat(result).to_csv('eqtl-power.txt.gz', compression='gzip', sep='\t')
  #+END_SRC

  #+BEGIN_SRC sh :dir /scratch/midway2/aksarkar/singlecell/power/
    sbatch --partition=broadwl -n1 -c28 --exclusive --mem=16G --job-name=eqtl-power --output=eqtl-power.out
    #!/bin/bash
    source activate scqtl
    python /project2/mstephens/aksarkar/projects/singlecell-qtl/code/eqtl-power.py
  #+END_SRC

  #+RESULTS:
  : Submitted batch job 46371621

  #+BEGIN_SRC sh
    sacct -j 46371621 -o Elapsed
  #+END_SRC

  #+RESULTS:
  :    Elapsed 
  : ---------- 
  :   00:21:38 
  :   00:21:38 
  :   00:21:38 

  Read the results.

  #+BEGIN_SRC ipython
    qtl_results = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/power/eqtl-power.txt.gz', index_col=0)
    qtl_power = qtl_results.groupby(['num_individuals', 'num_causal', 'pve']).apply(lambda x: (x['pval'] < 0.05).sum() / x.shape[0]).reset_index().rename(columns={0: 'power'})
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[22]:
  :END:

  Plot the results.

  #+BEGIN_SRC ipython :ipyfile figure/power.org/eqtl-power.png
    plt.clf()
    fig, ax = plt.subplots(1, 3, sharey=True)
    fig.set_size_inches(8, 3)
    for i, m in enumerate([1, 2, 3]):
      for n in [53, 75, 100, 120]:
        subset = np.logical_and(qtl_power['num_individuals'] == n, qtl_power['num_causal'] == m)
        color = colorcet.cm['inferno'](.9 * (n - 53) / (120 - 53))
        ax[i].plot(qtl_power.loc[subset, 'pve'], qtl_power.loc[subset, 'power'], marker='.', c=color, lw=1, ms=8, label=n)
        ax[i].set_title('{} causal'.format(m))
    ax[1].set_xlabel('Proportion of variance explained')
    ax[0].set_ylabel('Power at level 0.05')
    ax[-1].legend(title='# individuals', frameon=False, loc='center left', bbox_to_anchor=(1, .5))
    fig.tight_layout()
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[43]:
  [[file:figure/power.org/eqtl-power.png]]
  :END:

  The key insight is that the single cell experiment size determines the
  standard error of the estimator, which can be thought of as measurement
  error.

  \[ \hat\theta \sim N(\theta, \sigma^2) \]

  This is the same as changing effective PVE:

  \[ h^2_{\mathrm{eff}} = \frac{h^2}{1 + \sigma^2} \]

  We estimate the standard error as a function of the experiment size from the
  simulation.

* Dispersion-QTL discovery

  We assume dispersions are generated from \(m\) causal effects following a
  linear model:

  \[ \ln{\hat\phi} \sim N(\mathbf{X} \bm{\beta}, \sigma^2_e + \sigma^2) \]
