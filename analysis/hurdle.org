#+TITLE: Hurdle model estimation
#+SETUPFILE: setup.org

* Introduction

  The key idea of ~voom~ ([[http://genomebiology.com/2014/15/2/R29][Law et al 2014]]) is that the distribution of
  log-transformed counts per million is approximately Gaussian. Consider the
  expression of a single gene in individual \(i\), cell \(j\).

  \[ r_{ij} = \mbox{number of reads} \]

  Assuming \(r_{ij}\) follows the NB2 negative binomial model (Hilbe 2012):

  \[ E[r_{ij}] = \lambda_{ij} \]
  \[ V[r_{ij}] = \lambda_{ij} + \phi_{ij} \lambda_{ij}^2 \]

  By the definition of CPM:

  \[ y_{ij} = \log_2(r_{ij}) + \mathrm{const} \]

  By first order Taylor expansion:

  \[ E[y_{ij}] = \mu_{ij} \approx \log_2 \lambda_{ij} + \mathrm{const} \]

  By the delta method:

  \[ V[y_{ij}] = \sigma_{ij}^2 \approx V[r_{ij}] / \lambda_{ij}^2 = 1/\lambda_{ij} + \phi_{ij} \]

  We assume:

  \[ y_{ij} \approx N(\mu_{ij}, \sigma^2_{ij}) \]

  Now, we seek to write a hierarchical model for \(y\) in terms of the genotype
  of individual \(i\) to call mean and variance QTLs. Our idea is that the
  variance of the observations \(Y\) can be decomposed as follows:

  #+ATTR_HTML: :class table
  |            | Within individual                       | Between individual |
  |------------+-----------------------------------------+--------------------|
  | Observed   | \(\exp(-X_i \beta + u_i) + X_i \gamma\) | \(X_i \beta\)      |
  | Unobserved | \(\sigma^2\)                            | \(u_i\)            |

  In more detail: between individual variation is partially explained by
  /cis/-genotype, and partially explained by other sources. Within individual
  variation is partially explained by mean expression (as derived above),
  /cis/-genotype (what we hope to find), and other sources (/trans/-regulation,
  sampling variance, etc.)

  Accordingly, we have:

  \[ \mu_{ij} = X_i \beta + u_i - \mathrm{const} \]

  \[ \log \sigma^2_{ij} = \exp(-(X_i\beta + u_i)) + X_i \gamma + \sigma^2 \]

  We can estimate the posterior \(p(\beta, \gamma, u_i \mid \cdot)\) this model
  using a combination of black-box variational inference and variational EM.

  *TODO:* marginalize out \(u_i\)?

  *TODO:* prior specification on the correct scales for \(\beta, \gamma\)

  *TODO:* verify that Edward is maximizing ELBO w.r.t. \(\sigma^2\) even
  without a variational approximation
  
* Setup                                                            :noexport:

  #+BEGIN_SRC emacs-lisp
    (org-babel-lob-ingest "/home/aksarkar/projects/singlecell-qtl/analysis/sc-vs-bulk.org")
    (org-babel-lob-ingest "/home/aksarkar/projects/singlecell-qtl/analysis/qtl-mapping.org")
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(venv="scqtl") :dir /scratch/midway2/aksarkar/singlecell

  #+RESULTS:
  : Submitted batch job 41442539

  #+BEGIN_SRC ipython
    import edward as ed
    import functools
    import gzip
    import os.path
    import matplotlib.pyplot as plt
    import numpy as np
    import pandas as pd
    import pickle
    import tabix
    import tensorflow as tf
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  #+CALL: concordance-def()

  #+RESULTS:
  :RESULTS:
  :END:

  #+CALL: load-data-defs()

  #+RESULTS:
  :RESULTS:
  :END:

  #+CALL: load-data()

  #+RESULTS:
  :RESULTS:
  : ((20327, 2261), (34608, 15))
  :END:

  #+CALL: umi-qc()

  #+RESULTS:
  :RESULTS:
  : (15636, 1810)
  :END:

  #+CALL: onehot-qc()

  #+RESULTS:
  :RESULTS:
  :END:

  #+NAME: reset
  #+BEGIN_SRC ipython
    tf.reset_default_graph()
    ed.get_session().close()
  #+END_SRC

  #+RESULTS: reset
  :RESULTS:
  :END:

* Test case

  #+CALL: get-gene-info() :exports none

  #+RESULTS:
  :RESULTS:
  #+BEGIN_EXAMPLE
                    chr      start        end      name strand      source
    gene                                                                    
    ENSG00000000419  hs20   49551404   49575092      DPM1      -  H. sapiens
    ENSG00000000457   hs1  169818772  169863408     SCYL3      -  H. sapiens
    ENSG00000000460   hs1  169631245  169823221  C1orf112      +  H. sapiens
    ENSG00000000938   hs1   27938575   27961788       FGR      -  H. sapiens
    ENSG00000000971   hs1  196621008  196716634       CFH      +  H. sapiens
  #+END_EXAMPLE
  :END:

  #+BEGIN_SRC ipython
    gene_info.query('name == "ZSWIM7"')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  #+BEGIN_EXAMPLE
                    chr     start       end    name strand      source
    gene                                                                
    ENSG00000214941  hs17  15879874  15903031  ZSWIM7      -  H. sapiens
  #+END_EXAMPLE
  :END:

  #+BEGIN_SRC ipython
    with gzip.open('/project2/gilad/singlecell-qtl/bulk/genotypes.vcf.gz', 'rt') as f:
      header = next(f).split()
    vcf = tabix.open('/project2/gilad/singlecell-qtl/bulk/genotypes.vcf.gz')
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython
    def _extract_genotypes(row, vcf, header, window):
      if row['strand'] == '+':
        start = row['start'] - window
        end = row['start']
      else:
        start = row['end']
        end = row['end'] + window
      result = pd.DataFrame(list(vcf.query('chr{}'.format(row['chr'][2:]), start, end)), columns=header).iloc[:,9:].astype(np.float32)
      return result
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython
    genotypes = _extract_genotypes(gene_info.loc['ENSG00000214941'], vcf=vcf, header=header, window=int(1e6)).rename(columns=lambda x: 'NA{}'.format(x))[sorted(annotations_qc['chip_id'].unique())]
    genotypes = genotypes.T.transform(lambda x: x - x.mean()).fillna(0)
    genotypes.shape
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  : (21, 2506)
  :END:

  #+BEGIN_SRC ipython
    data = {'onehot': onehot,
            'genotypes': genotypes.values,
            'counts': umi_qc.loc['ENSG00000214941'].values.astype(np.float32).reshape(-1, 1),
            'normalizers': -np.log(umi_qc.agg(np.sum)).values.reshape(-1, 1)}
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython
    with open('test_data.pkl', 'wb') as f:
      pickle.dump(data, f)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython
    with open('test_data.pkl', 'rb') as f:
      data = pickle.load(f)

    data['log_cpm'] = np.log(data['counts'] + 1) + data['normalizers'] + 6 * np.log(10)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

* Model specification and inference

  #+CALL: reset()

  #+RESULTS:
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython
    m, n = data['onehot'].shape
    _, p = data['genotypes'].shape

    onehot = tf.placeholder(tf.float32, [m, n])
    genotypes = tf.placeholder(tf.float32, [n, 1])
    library_size = tf.placeholder(tf.float32, [m, 1])

    ind_bias = ed.models.Normal(loc=tf.zeros([n, 1]), scale=tf.Variable(tf.ones([n, 1])))
    cell_bias = library_size - 6 * tf.log(10.)
    rate_effect = ed.models.Normal(loc=tf.zeros([1, 1]), scale=0.1 * tf.ones([1, 1]))
    log_rate = tf.matmul(onehot, tf.matmul(genotypes, rate_effect) + ind_bias)
    mean = log_rate + cell_bias

    disp_effect = ed.models.Normal(loc=tf.zeros([1, 1]), scale=0.1 * tf.ones([1, 1]))
    disp = tf.matmul(onehot, tf.matmul(genotypes, disp_effect))
    var = tf.exp(-log_rate) + tf.exp(disp) + tf.exp(tf.Variable(tf.zeros([1])))

    log_cpm = ed.models.Normal(loc=mean, scale=tf.sqrt(var))

    q_ind_bias = ed.models.Normal(loc=tf.Variable(tf.zeros([n, 1])), scale=tf.Variable(tf.ones([n, 1])))
    q_rate_effect = ed.models.Normal(loc=tf.Variable(tf.random_normal([1, 1])), scale=tf.Variable(tf.random_normal([1, 1])))
    q_disp_effect = ed.models.Normal(loc=tf.Variable(tf.random_normal([1, 1])), scale=tf.Variable(tf.random_normal([1, 1])))

    inf = ed.ReparameterizationKLKLqp(
      latent_vars={
        rate_effect: q_rate_effect,
        ind_bias: q_ind_bias,
        disp_effect: q_disp_effect,
      },
      data={
        onehot: data['onehot'],
        genotypes: data['genotypes'][:,0:1],
        library_size: -data['normalizers'],
        log_cpm: data['log_cpm'],
      })
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  :END:

  #+BEGIN_SRC ipython
    inf.run(n_samples=10, optimizer=tf.train.AdamOptimizer(learning_rate=5e-2))
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  : 1000/1000 [100%] ██████████████████████████████ Elapsed: 6s | Loss: 2302.281
  :END:

  #+BEGIN_SRC ipython
    res = pd.DataFrame(
      np.hstack(ed.get_session().run([q_rate_effect.mean(), q_rate_effect.variance(), q_disp_effect.mean(), q_disp_effect.variance()])),
      columns=['rate_effect_mean', 'rate_effect_var', 'disp_effect_mean', 'disp_effect_var'])
    res
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  #+BEGIN_EXAMPLE
     rate_effect_mean  rate_effect_var  disp_effect_mean  disp_effect_var
    0          0.005864         0.001925         -0.040866         0.003422
  #+END_EXAMPLE
  :END:

  Plot the distribution of the data:

  #+BEGIN_SRC ipython :ipyfile figure/voom.org/data.png
    plt.clf()
    plt.gcf().set_size_inches(8, 6)
    plt.scatter(x=np.where(data['onehot'] == 1)[1] + np.random.normal(scale=0.1, size=m), y=data['log_cpm'], s=2)
    plt.xlabel('Individual')
    plt.ylabel('$\log_2(CPM + 1)$')
    plt.gca().set_xticks([])
    plt.gcf()
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  [[file:figure/voom.org/data.png]]
  :END:

  Plot a posterior predictive draw.

  #+BEGIN_SRC ipython :ipyfile figure/voom.org/post-pred.png
    post_pred = ed.get_session().run(
      ed.copy(log_cpm, inf.latent_vars),
      {
        onehot: data['onehot'],
        genotypes: data['genotypes'][:,0:1],
        library_size: -data['normalizers'],
        log_cpm: data['log_cpm'],
      })
    est_bias = ed.get_session().run(q_ind_bias.mean()).ravel()

    plt.clf()
    plt.gcf().set_size_inches(8, 6)
    plt.scatter(x=np.where(data['onehot'] == 1)[1] + np.random.normal(scale=0.1, size=m), y=post_pred, s=2)
    plt.scatter(x=np.arange(n), y=est_bias, c='red')
    plt.xlabel('Individual')
    plt.ylabel('$\log_2(CPM + 1)$')
    plt.gca().set_xticks([])
    plt.gcf()
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  [[file:figure/voom.org/post-pred.png]]
  :END:

* Next steps

  The key idea of ~mast~ ([[https://dx.doi.org/10.1186/s13059-015-0844-5][Finak et al 2015]]) is to model non-zero \(R\) using a
  Gaussian distribution, and model zero \(R\) using logistic regression. The
  key distinction between this approach and the [[file:zinb.org][zero-inflated
  negative binomial model]] is that zeroes are assumed to arise from only one
  process.

  This naturally suggests a Bayesian model which simultaneously calls mean and
  variance QTLs based on the likelihood:

  \[ Y \mid Y = 0 \sim \mathrm{Bernoulli}(1 - \mathrm{sigmoid}(AX\theta_m + \delta)) \]

  \[ Y \mid Y > 0 \sim N(AX\theta_m + \delta, \exp(-AX\theta_m - \delta) +
  \exp(AX\theta_v) + \sigma^2) \]

  where \(\delta\) is a known constant that depends on library size, \(A\) maps
  from cells to individuals, and \(X\) is the genotype matrix.

  The key issues are:

  1. *Do we need to actually fit the dropout model?* ~mast~ conditions on the
     observed \(Y = 0\), not on a latent \(Z = 0\), which means we could simply
     do the same and ignore zeros.

     If we did so, then mean/variance QTL effect size estimation will be less
     robust for genes with high dropout. This might not be a problem depending
     on the stringency of gene filtering.

  2. *For a single gene, do we need to worry about mean QTLs in LD with
     variance QTLs?* We previously [[https://github.com/YPARK/fqtl][built multivariate mean/variance QTL models]]
     which could account for LD, and could share information between the mean
     and variance models.

     The fundamental problem is that if we assume that the mean and dispersion
     both have genetic components, then the mean is no longer independent of
     the dispersion.

     This actually could be derived without using the fact that both depend on
     the same genotypes if we use second-order Taylor expansion:

     \[ \mu \approx \log_2 \lambda + \frac{V[R]}{2 \lambda^2} \]

  3. *Do we need to share parameters between genes?* ~mast~ assumes genes are
     conditionally independent. But this is no longer true when nearby genes
     can be driven by overlapping (or correlated) /cis/-genotypes.

     We previously developed multiresponse QTL models which learned the target
     genes of causal variants, allowing the true target gene to explain away
     nearby correlated genes ([[https://www.biorxiv.org/content/early/2017/11/14/219428][Park et al 2017]]).

