<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2018-01-16 Tue 10:30 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Hurdle model estimation</title>
<meta name="generator" content="Org mode">
<meta name="author" content="Abhishek Sarkar">
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<link rel="stylesheet" type="text/css" href="https://www.pirilampo.org/styles/readtheorg/css/htmlize.css"/>
<style type="text/css">body {width: 60em; margin:auto} pre.src {overflow:auto}</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2017 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Hurdle model estimation</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org6b5d7d4">Model specification and inference</a></li>
</ul>
</div>
</div>
<div id="outline-container-org6b5d7d4" class="outline-2">
<h2 id="org6b5d7d4">Model specification and inference</h2>
<div class="outline-text-2" id="text-org6b5d7d4">
<p>
We specify the model in Edward. We assume a fully factored variational
approximation \(q(\beta_\lambda)q(\beta_\phi)q(u^\lambda)q(u^\phi)\).
</p>

<p>
Special care needs to be taken with the prior \(p(u^\phi)\) because the
implied variance is too large if \(u^\phi = 0\).
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="orge613a81"><span class="org-variable-name">nonzero_cpm</span> = data[<span class="org-string">'log_cpm'</span>].ravel() &gt; 0
<span class="org-variable-name">q</span> = nonzero_cpm.<span class="org-builtin">sum</span>()
<span class="org-variable-name">m</span>, <span class="org-variable-name">n</span> = data[<span class="org-string">'onehot'</span>].shape
<span class="org-variable-name">_</span>, <span class="org-variable-name">p</span> = data[<span class="org-string">'genotypes'</span>].shape

<span class="org-variable-name">onehot</span> = tf.placeholder(tf.float32, [q, n])
<span class="org-variable-name">genotypes</span> = tf.placeholder(tf.float32, [n, p])
<span class="org-variable-name">cell_bias</span> = tf.placeholder(tf.float32, [q, 1])

<span class="org-variable-name">rate_bias_scale</span> = tf.exp(tf.Variable(tf.ones([1])))
<span class="org-variable-name">rate_bias</span> = ed.models.Normal(loc=tf.zeros([n, 1]), scale=rate_bias_scale)

<span class="org-variable-name">rate_effect_scale</span> = tf.exp(tf.Variable(tf.ones([1])))
<span class="org-variable-name">rate_effect</span> = ed.models.Normal(loc=tf.zeros([p, 1]), scale=rate_effect_scale)

<span class="org-variable-name">log_rate</span> = tf.matmul(onehot, tf.matmul(genotypes, rate_effect) + rate_bias)
<span class="org-variable-name">mean</span> = log_rate + cell_bias

<span class="org-variable-name">disp_bias_scale</span> = tf.exp(tf.Variable(tf.ones([1])))
<span class="org-variable-name">disp_bias</span> = ed.models.Normal(loc=tf.fill([n, 1], -10.), scale=disp_bias_scale)

<span class="org-variable-name">disp_effect_scale</span> = tf.exp(tf.Variable(tf.ones([1])))
<span class="org-variable-name">disp_effect</span> = ed.models.Normal(loc=tf.zeros([p, 1]), scale=disp_effect_scale)

<span class="org-variable-name">disp</span> = tf.matmul(onehot, tf.matmul(genotypes, disp_effect) + disp_bias)
<span class="org-variable-name">resid_var_scale</span> = tf.exp(tf.Variable(tf.constant(data[<span class="org-string">'log_cpm'</span>][nonzero_cpm].var())))
<span class="org-variable-name">var</span> = tf.exp(-log_rate) + tf.exp(disp) + resid_var_scale

<span class="org-variable-name">log_cpm</span> = ed.models.Normal(loc=mean, scale=tf.sqrt(var))

<span class="org-variable-name">q_rate_bias</span> = ed.models.NormalWithSoftplusScale(
  loc=tf.Variable(tf.random_normal([n, 1])),
  scale=tf.Variable(tf.ones([n, 1])))
<span class="org-variable-name">q_disp_bias</span> = ed.models.NormalWithSoftplusScale(
  loc=tf.Variable(tf.random_normal([n, 1], mean=-10)),
  scale=tf.Variable(tf.ones([n, 1])))

<span class="org-variable-name">q_rate_effect</span> = ed.models.NormalWithSoftplusScale(
  loc=tf.Variable(tf.random_normal([p, 1], stddev=0.1)),
  scale=tf.Variable(tf.fill([p, 1], -8.)))
<span class="org-variable-name">q_disp_effect</span> = ed.models.NormalWithSoftplusScale(
  loc=tf.Variable(tf.random_normal([p, 1], stddev=0.1)),
  scale=tf.Variable(tf.fill([p, 1], -8.)))
</pre>
</div>

<p>
We optimize the evidence lower bound with respect to the variational parameters
and model hyperparameters (scales) simultaneously using the
reparameterization gradient and gradient descent.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="orga8ccf22"><span class="org-variable-name">inf</span> = ed.ReparameterizationKLKLqp(
  latent_vars={
    rate_effect: q_rate_effect,
    rate_bias: q_rate_bias,
    disp_effect: q_disp_effect,
    disp_bias: q_disp_bias,
  },
  data={
    onehot: data[<span class="org-string">'onehot'</span>][nonzero_cpm],
    genotypes: data[<span class="org-string">'genotypes'</span>],
    cell_bias: data[<span class="org-string">'normalizers'</span>][nonzero_cpm],
    log_cpm: data[<span class="org-string">'log_cpm'</span>][nonzero_cpm],
  })
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">inf.run(n_samples=10, n_print=1000, optimizer=tf.train.AdamOptimizer(learning_rate=5e-2))
</pre>
</div>

<pre class="example">
1000/1000 [100%] ██████████████████████████████ Elapsed: 6s | Loss: 2314.966

</pre>

<p>
Tabulate the estimated hyperparameters:
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org2d1671d">pd.DataFrame(
  ed.get_session().run(
    [resid_var_scale,
     rate_effect_scale,
     rate_bias_scale,
     disp_effect_scale,
     disp_bias_scale,
    ]),
  index=[<span class="org-string">'resid_var_scale'</span>,
         <span class="org-string">'rate_effect_scale'</span>,
         <span class="org-string">'rate_bias_scale'</span>,
         <span class="org-string">'disp_effect_scale'</span>,
         <span class="org-string">'disp_bias_scale'</span>])
</pre>
</div>

<pre class="example">
                           0
resid_var_scale       0.831836
rate_effect_scale    [1.79292]
rate_bias_scale     [0.944154]
disp_effect_scale  [0.0327109]
disp_bias_scale      [1.88607]
</pre>

<p>
Compute posterior 95% credible intervals for the effect sizes:
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org0066e7c"><span class="org-variable-name">res</span> = pd.DataFrame(np.hstack(ed.get_session().run(
  [q_rate_effect.mean(),
   1.96 * tf.sqrt(q_rate_effect.variance()),
   q_disp_effect.mean(),
   1.96 * tf.sqrt(q_disp_effect.variance())])),
  columns=[<span class="org-string">'rate_effect_mean'</span>, <span class="org-string">'rate_effect_ci'</span>, <span class="org-string">'disp_effect_mean'</span>, <span class="org-string">'disp_effect_ci'</span>])
res
</pre>
</div>

<pre class="example">
 rate_effect_mean  rate_effect_ci  disp_effect_mean  disp_effect_ci
0          1.794225        0.075665         -0.000046         0.06413
</pre>

<p>
Estimate posterior 95% credible intervals for the bias terms:
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">res</span> = pd.DataFrame(np.hstack(ed.get_session().run(
  [q_rate_bias.mean(),
   1.96 * tf.sqrt(q_rate_bias.variance()),
   q_disp_bias.mean(),
   1.96 * tf.sqrt(q_disp_bias.variance())]
)))
plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 1)
ax[0].errorbar(x=res.index, y=res[0], yerr=res[1], fmt=<span class="org-string">'o'</span>)
ax[0].set_xticks([])
ax[0].set_xlabel(<span class="org-string">''</span>)
ax[0].set_ylabel(<span class="org-string">'Rate bias'</span>)
ax[1].errorbar(x=res.index, y=res[2], yerr=res[3], fmt=<span class="org-string">'o'</span>)
ax[1].set_xticks([])
ax[1].set_xlabel(<span class="org-string">'Individual'</span>)
ax[1].set_ylabel(<span class="org-string">'Dispersion bias'</span>)
plt.gcf()
</pre>
</div>


<div class="figure">
<p><img src="figure/hurdle.org/bias.png" alt="bias.png">
</p>
</div>

<p>
Plot a posterior predictive draw, and the real data means and twice standard
deviations.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">post_pred</span> = ed.get_session().run(
  ed.copy(log_cpm, inf.latent_vars),
  {
    onehot: data[<span class="org-string">'onehot'</span>][nonzero_cpm],
    genotypes: data[<span class="org-string">'genotypes'</span>][:,0:1],
    cell_bias: data[<span class="org-string">'normalizers'</span>][nonzero_cpm],
    log_cpm: data[<span class="org-string">'log_cpm'</span>][nonzero_cpm],
  })

plt.clf()
plt.gcf().set_size_inches(8, 6)
plt.scatter(x=np.where(data[<span class="org-string">'onehot'</span>][nonzero_cpm] == 1)[1] + np.random.normal(scale=0.1, size=q), y=post_pred, s=2)
plt.errorbar(x=np.arange(n), y=onehot_cpm.mean(axis=0), yerr=2 * onehot_cpm.std(axis=0), fmt=<span class="org-string">'o'</span>, c=<span class="org-string">'red'</span>)
plt.xlabel(<span class="org-string">'Individual'</span>)
plt.ylabel(<span class="org-string">'$\log_2(CPM + 1)$'</span>)
plt.gca().set_xticks([])
plt.gcf()
</pre>
</div>


<div class="figure">
<p><img src="figure/hurdle.org/post-pred.png" alt="post-pred.png">
</p>
</div>

<p>
Investigate the terms of the variance model to understand why the posterior
predictive distribution has larger variance than the original data. Compare
the sample variance of non-zero CPM between cells within each individual to
the estimated variance (plugging in the estimated posterior means into the
model).
</p>

<div class="org-src-container">
<pre class="src src-ipython">pd.DataFrame(np.hstack([
  onehot_cpm.var(axis=0).filled().reshape(-1, 1),
  ed.get_session().run(tf.exp(-tf.matmul(genotypes, q_rate_effect.mean()) - q_rate_bias.mean()), {onehot: data[<span class="org-string">'onehot'</span>][nonzero_cpm], genotypes: data[<span class="org-string">'genotypes'</span>], cell_bias: data[<span class="org-string">'normalizers'</span>][nonzero_cpm]}),
  ed.get_session().run(tf.exp(tf.matmul(genotypes, q_disp_effect.mean()) + q_disp_bias.mean()), {onehot: data[<span class="org-string">'onehot'</span>][nonzero_cpm], genotypes: data[<span class="org-string">'genotypes'</span>], cell_bias: data[<span class="org-string">'normalizers'</span>][nonzero_cpm]})
]), columns=[<span class="org-string">'sample_var'</span>, <span class="org-string">'mean_component'</span>, <span class="org-string">'disp_component'</span>])
</pre>
</div>

<pre class="example">
  sample_var  mean_component  disp_component
0     0.871253        0.303846        0.000045
1     0.685687        0.278786        0.000045
2     0.832976        0.174248        0.000046
3     0.700838        0.196059        0.000044
4     0.814616        0.268586        0.000044
5     0.691467        0.330452        0.000044
6     0.783659        0.194654        0.000046
7     0.802240        0.146926        0.000047
8     0.834025        0.244478        0.000046
9     0.772049        0.241288        0.000045
10    0.473087        0.139420        0.000046
11    0.849796        0.283829        0.000045
12    0.866909        0.147805        0.000046
13    1.008157        0.181169        0.000045
14    0.534548        0.148885        0.000045
15    0.577289        0.145060        0.000046
16    0.592843        0.178472        0.000045
17    0.868248        0.243828        0.000045
18    0.643367        0.188713        0.000046
19    0.610603        0.143450        0.000045
20    0.561710        0.255773        0.000045
</pre>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Abhishek Sarkar</p>
<p class="date">Created: 2018-01-16 Tue 10:30</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
